C:\Users\dtrizna\Code\Synapse\Linux>python3 adversarial_poisoning_pollution.py
[!] Script start time: Sun Dec  3 15:11:46 2023
Python implementation: CPython
Python version       : 3.9.13
IPython version      : 8.11.0

torch    : 2.0.1+cu117
lightning: 1.8.6
sklearn  : 0.0.post1

Global seed set to 0
[*] Poisoning train set... Ratio: 0.000% | Poisoned samples: 0
[!] Sizes of train and test sets: 533014, 470129
[*] Working on 'cnn' model poisoned training...
[!] Scores already calculated for 'cnn_poison_samples_0'! Skipping...
[*] Working on 'mlp_onehot' model poisoned training...
[!] Scores already calculated for 'mlp_onehot_poison_samples_0'! Skipping...
[*] Working on 'xgb_onehot' model poisoned training...
[!] Scores already calculated for 'xgb_onehot_poison_samples_0'! Skipping...
[*] Poisoning train set... Ratio: 0.001% | Poisoned samples: 2
[!] Sizes of train and test sets: 533016, 470129
[*] Working on 'cnn' model poisoned training...
[!] Scores already calculated for 'cnn_poison_samples_2'! Skipping...
[*] Working on 'mlp_onehot' model poisoned training...
[!] Scores already calculated for 'mlp_onehot_poison_samples_2'! Skipping...
[*] Working on 'xgb_onehot' model poisoned training...
[!] Loading One-Hot encoder from 'C:\Users\dtrizna\Code\Synapse\Linux\logs_adversarial_poisoning_pollution\seed_0_lim_None\onehot_vocab_4096_poisoned_samples_2_ratio_0.001.pkl'...    
[!] Training original model 'xgb_onehot_poison_samples_2' started: Sun Dec  3 15:13:08 2023
[*] Training xgb_onehot_poison_samples_2 model...
[!] xgb_onehot_poison_samples_2 model scores: tpr=1.0000, f1=0.9999, acc=0.9999, auc=1.0000
[!] Training of 'xgb_onehot_poison_samples_2' ended:  Sun Dec  3 15:14:35 2023  | Took: 87.30 seconds
[*] Testing 'xgb_onehot_poison_samples_2' model...
[!] Scores for 'xgb_onehot_poison_samples_2' model (): f1=0.9999, acc=0.9999, tpr=1.0000
               misclassified=42: malicious=41 | benign=1
[*] Poisoning train set... Ratio: 0.003% | Poisoned samples: 7
[!] Sizes of train and test sets: 533021, 470129
[*] Working on 'cnn' model poisoned training...
[!] Scores already calculated for 'cnn_poison_samples_7'! Skipping...
[*] Working on 'mlp_onehot' model poisoned training...
[!] Scores already calculated for 'mlp_onehot_poison_samples_7'! Skipping...
[*] Working on 'xgb_onehot' model poisoned training...
[!] Loading One-Hot encoder from 'C:\Users\dtrizna\Code\Synapse\Linux\logs_adversarial_poisoning_pollution\seed_0_lim_None\onehot_vocab_4096_poisoned_samples_7_ratio_0.003.pkl'...    
[!] Training original model 'xgb_onehot_poison_samples_7' started: Sun Dec  3 15:15:49 2023
[*] Training xgb_onehot_poison_samples_7 model...
[!] xgb_onehot_poison_samples_7 model scores: tpr=1.0000, f1=1.0000, acc=1.0000, auc=1.0000
[!] Training of 'xgb_onehot_poison_samples_7' ended:  Sun Dec  3 15:17:21 2023  | Took: 91.70 seconds
[*] Testing 'xgb_onehot_poison_samples_7' model...
[!] Scores for 'xgb_onehot_poison_samples_7' model (): f1=1.0000, acc=1.0000, tpr=1.0000
               misclassified=8: malicious=8 | benign=0
[*] Poisoning train set... Ratio: 0.010% | Poisoned samples: 26
[!] Sizes of train and test sets: 533040, 470129
[*] Working on 'cnn' model poisoned training...
[!] Scores already calculated for 'cnn_poison_samples_26'! Skipping...
[*] Working on 'mlp_onehot' model poisoned training...
[!] Scores already calculated for 'mlp_onehot_poison_samples_26'! Skipping...
[*] Working on 'xgb_onehot' model poisoned training...
[!] Loading One-Hot encoder from 'C:\Users\dtrizna\Code\Synapse\Linux\logs_adversarial_poisoning_pollution\seed_0_lim_None\onehot_vocab_4096_poisoned_samples_26_ratio_0.01.pkl'...    
[!] Training original model 'xgb_onehot_poison_samples_26' started: Sun Dec  3 15:18:39 2023
[*] Training xgb_onehot_poison_samples_26 model...
[!] xgb_onehot_poison_samples_26 model scores: tpr=0.9992, f1=0.9981, acc=0.9981, auc=1.0000
[!] Training of 'xgb_onehot_poison_samples_26' ended:  Sun Dec  3 15:20:21 2023  | Took: 101.98 seconds
[*] Testing 'xgb_onehot_poison_samples_26' model...
[!] Scores for 'xgb_onehot_poison_samples_26' model (): f1=0.9981, acc=0.9981, tpr=0.9992
               misclassified=882: malicious=871 | benign=11
[*] Poisoning train set... Ratio: 0.030% | Poisoned samples: 79
[!] Sizes of train and test sets: 533093, 470129
[*] Working on 'cnn' model poisoned training...
[!] Scores already calculated for 'cnn_poison_samples_79'! Skipping...
[*] Working on 'mlp_onehot' model poisoned training...
[!] Scores already calculated for 'mlp_onehot_poison_samples_79'! Skipping...
[*] Working on 'xgb_onehot' model poisoned training...
[!] Loading One-Hot encoder from 'C:\Users\dtrizna\Code\Synapse\Linux\logs_adversarial_poisoning_pollution\seed_0_lim_None\onehot_vocab_4096_poisoned_samples_79_ratio_0.03.pkl'...    
[!] Training original model 'xgb_onehot_poison_samples_79' started: Sun Dec  3 15:21:35 2023
[*] Training xgb_onehot_poison_samples_79 model...
[!] xgb_onehot_poison_samples_79 model scores: tpr=1.0000, f1=0.9992, acc=0.9992, auc=1.0000
[!] Training of 'xgb_onehot_poison_samples_79' ended:  Sun Dec  3 15:23:12 2023  | Took: 96.98 seconds
[*] Testing 'xgb_onehot_poison_samples_79' model...
[!] Scores for 'xgb_onehot_poison_samples_79' model (): f1=0.9992, acc=0.9992, tpr=1.0000
               misclassified=384: malicious=371 | benign=13
[*] Poisoning train set... Ratio: 0.100% | Poisoned samples: 266
[!] Sizes of train and test sets: 533280, 470129
[*] Working on 'cnn' model poisoned training...
[!] Scores already calculated for 'cnn_poison_samples_266'! Skipping...
[*] Working on 'mlp_onehot' model poisoned training...
[!] Scores already calculated for 'mlp_onehot_poison_samples_266'! Skipping...
[*] Working on 'xgb_onehot' model poisoned training...
[!] Loading One-Hot encoder from 'C:\Users\dtrizna\Code\Synapse\Linux\logs_adversarial_poisoning_pollution\seed_0_lim_None\onehot_vocab_4096_poisoned_samples_266_ratio_0.1.pkl'...    
[!] Training original model 'xgb_onehot_poison_samples_266' started: Sun Dec  3 15:24:26 2023
[*] Training xgb_onehot_poison_samples_266 model...
[!] xgb_onehot_poison_samples_266 model scores: tpr=1.0000, f1=1.0000, acc=1.0000, auc=1.0000
[!] Training of 'xgb_onehot_poison_samples_266' ended:  Sun Dec  3 15:26:02 2023  | Took: 96.64 seconds
[*] Testing 'xgb_onehot_poison_samples_266' model...
[!] Scores for 'xgb_onehot_poison_samples_266' model (): f1=1.0000, acc=1.0000, tpr=1.0000
               misclassified=12: malicious=0 | benign=12
[*] Poisoning train set... Ratio: 0.300% | Poisoned samples: 799
[!] Sizes of train and test sets: 533813, 470129
[*] Working on 'cnn' model poisoned training...
[!] Scores already calculated for 'cnn_poison_samples_799'! Skipping...
[*] Working on 'mlp_onehot' model poisoned training...
[!] Scores already calculated for 'mlp_onehot_poison_samples_799'! Skipping...
[*] Working on 'xgb_onehot' model poisoned training...
[!] Loading One-Hot encoder from 'C:\Users\dtrizna\Code\Synapse\Linux\logs_adversarial_poisoning_pollution\seed_0_lim_None\onehot_vocab_4096_poisoned_samples_799_ratio_0.3.pkl'...    
[!] Training original model 'xgb_onehot_poison_samples_799' started: Sun Dec  3 15:27:15 2023
[*] Training xgb_onehot_poison_samples_799 model...
[!] xgb_onehot_poison_samples_799 model scores: tpr=1.0000, f1=1.0000, acc=1.0000, auc=1.0000
[!] Training of 'xgb_onehot_poison_samples_799' ended:  Sun Dec  3 15:28:52 2023  | Took: 96.58 seconds
[*] Testing 'xgb_onehot_poison_samples_799' model...
[!] Scores for 'xgb_onehot_poison_samples_799' model (): f1=1.0000, acc=1.0000, tpr=1.0000
               misclassified=8: malicious=3 | benign=5
[*] Poisoning train set... Ratio: 1.000% | Poisoned samples: 2665
[!] Sizes of train and test sets: 535679, 470129
[*] Working on 'cnn' model poisoned training...
[!] Scores already calculated for 'cnn_poison_samples_2665'! Skipping...
[*] Working on 'mlp_onehot' model poisoned training...
[!] Scores already calculated for 'mlp_onehot_poison_samples_2665'! Skipping...
[*] Working on 'xgb_onehot' model poisoned training...
[!] Loading One-Hot encoder from 'C:\Users\dtrizna\Code\Synapse\Linux\logs_adversarial_poisoning_pollution\seed_0_lim_None\onehot_vocab_4096_poisoned_samples_2665_ratio_1.pkl'...     
[!] Training original model 'xgb_onehot_poison_samples_2665' started: Sun Dec  3 15:30:05 2023
[*] Training xgb_onehot_poison_samples_2665 model...
[!] xgb_onehot_poison_samples_2665 model scores: tpr=1.0000, f1=0.9999, acc=0.9999, auc=1.0000
[!] Training of 'xgb_onehot_poison_samples_2665' ended:  Sun Dec  3 15:31:42 2023  | Took: 97.25 seconds
[*] Testing 'xgb_onehot_poison_samples_2665' model...
[!] Scores for 'xgb_onehot_poison_samples_2665' model (): f1=0.9999, acc=0.9999, tpr=1.0000
               misclassified=68: malicious=66 | benign=2
[*] Poisoning train set... Ratio: 3.000% | Poisoned samples: 7995
[!] Sizes of train and test sets: 541009, 470129
[*] Working on 'cnn' model poisoned training...
[!] Scores already calculated for 'cnn_poison_samples_7995'! Skipping...
[*] Working on 'mlp_onehot' model poisoned training...
[!] Scores already calculated for 'mlp_onehot_poison_samples_7995'! Skipping...
[*] Working on 'xgb_onehot' model poisoned training...
[!] Loading One-Hot encoder from 'C:\Users\dtrizna\Code\Synapse\Linux\logs_adversarial_poisoning_pollution\seed_0_lim_None\onehot_vocab_4096_poisoned_samples_7995_ratio_3.pkl'...     
[!] Training original model 'xgb_onehot_poison_samples_7995' started: Sun Dec  3 15:32:56 2023
[*] Training xgb_onehot_poison_samples_7995 model...
[!] xgb_onehot_poison_samples_7995 model scores: tpr=0.9933, f1=0.9352, acc=0.9392, auc=1.0000
[!] Training of 'xgb_onehot_poison_samples_7995' ended:  Sun Dec  3 15:34:32 2023  | Took: 96.11 seconds
[*] Testing 'xgb_onehot_poison_samples_7995' model...
[!] Scores for 'xgb_onehot_poison_samples_7995' model (): f1=0.9352, acc=0.9392, tpr=0.9933
               misclassified=28593: malicious=28587 | benign=6
[!] Script end time: Sun Dec  3 15:34:33 2023
[!] Script start time: Sun Dec  3 15:34:34 2023
Python implementation: CPython
Python version       : 3.9.13
IPython version      : 8.11.0

torch    : 2.0.1+cu117
lightning: 1.8.6
sklearn  : 0.0.post1

Global seed set to 33
[*] Poisoning train set... Ratio: 0.000% | Poisoned samples: 0
[!] Sizes of train and test sets: 533014, 470129
[*] Working on 'cnn' model poisoned training...
[!] Scores already calculated for 'cnn_poison_samples_0'! Skipping...
[*] Working on 'mlp_onehot' model poisoned training...
[!] Scores already calculated for 'mlp_onehot_poison_samples_0'! Skipping...
[*] Working on 'xgb_onehot' model poisoned training...
[!] Loading One-Hot encoder from 'C:\Users\dtrizna\Code\Synapse\Linux\logs_adversarial_poisoning_pollution\seed_33_lim_None\onehot_vocab_4096_poisoned_samples_0_ratio_0.pkl'...       
[!] Training original model 'xgb_onehot_poison_samples_0' started: Sun Dec  3 15:35:46 2023
[*] Training xgb_onehot_poison_samples_0 model...
[!] xgb_onehot_poison_samples_0 model scores: tpr=0.9994, f1=0.9997, acc=0.9997, auc=1.0000
[!] Training of 'xgb_onehot_poison_samples_0' ended:  Sun Dec  3 15:37:13 2023  | Took: 87.24 seconds
[*] Testing 'xgb_onehot_poison_samples_0' model...
[!] Scores for 'xgb_onehot_poison_samples_0' model (): f1=0.9997, acc=0.9997, tpr=0.9994
               misclassified=161: malicious=135 | benign=26
[*] Poisoning train set... Ratio: 0.001% | Poisoned samples: 2
[!] Sizes of train and test sets: 533016, 470129
[*] Working on 'cnn' model poisoned training...
[!] Scores already calculated for 'cnn_poison_samples_2'! Skipping...
[*] Working on 'mlp_onehot' model poisoned training...
[!] Scores already calculated for 'mlp_onehot_poison_samples_2'! Skipping...
[*] Working on 'xgb_onehot' model poisoned training...
[!] Loading One-Hot encoder from 'C:\Users\dtrizna\Code\Synapse\Linux\logs_adversarial_poisoning_pollution\seed_33_lim_None\onehot_vocab_4096_poisoned_samples_2_ratio_0.001.pkl'...   
[!] Training original model 'xgb_onehot_poison_samples_2' started: Sun Dec  3 15:38:27 2023
[*] Training xgb_onehot_poison_samples_2 model...
[!] xgb_onehot_poison_samples_2 model scores: tpr=1.0000, f1=1.0000, acc=1.0000, auc=1.0000
[!] Training of 'xgb_onehot_poison_samples_2' ended:  Sun Dec  3 15:39:54 2023  | Took: 86.69 seconds
[*] Testing 'xgb_onehot_poison_samples_2' model...
[!] Scores for 'xgb_onehot_poison_samples_2' model (): f1=1.0000, acc=1.0000, tpr=1.0000
               misclassified=3: malicious=0 | benign=3
[*] Poisoning train set... Ratio: 0.003% | Poisoned samples: 7
[!] Sizes of train and test sets: 533021, 470129
[*] Working on 'cnn' model poisoned training...
[!] Scores already calculated for 'cnn_poison_samples_7'! Skipping...
[*] Working on 'mlp_onehot' model poisoned training...
[!] Scores already calculated for 'mlp_onehot_poison_samples_7'! Skipping...
[*] Working on 'xgb_onehot' model poisoned training...
[!] Loading One-Hot encoder from 'C:\Users\dtrizna\Code\Synapse\Linux\logs_adversarial_poisoning_pollution\seed_33_lim_None\onehot_vocab_4096_poisoned_samples_7_ratio_0.003.pkl'...   
[!] Training original model 'xgb_onehot_poison_samples_7' started: Sun Dec  3 15:41:06 2023
[*] Training xgb_onehot_poison_samples_7 model...
[!] xgb_onehot_poison_samples_7 model scores: tpr=1.0000, f1=0.9994, acc=0.9994, auc=1.0000
[!] Training of 'xgb_onehot_poison_samples_7' ended:  Sun Dec  3 15:42:36 2023  | Took: 90.22 seconds
[*] Testing 'xgb_onehot_poison_samples_7' model...
[!] Scores for 'xgb_onehot_poison_samples_7' model (): f1=0.9994, acc=0.9994, tpr=1.0000
               misclassified=293: malicious=292 | benign=1
[*] Poisoning train set... Ratio: 0.010% | Poisoned samples: 26
[!] Sizes of train and test sets: 533040, 470129
[*] Working on 'cnn' model poisoned training...
[!] Scores already calculated for 'cnn_poison_samples_26'! Skipping...
[*] Working on 'mlp_onehot' model poisoned training...
[!] Scores already calculated for 'mlp_onehot_poison_samples_26'! Skipping...
[*] Working on 'xgb_onehot' model poisoned training...
[!] Loading One-Hot encoder from 'C:\Users\dtrizna\Code\Synapse\Linux\logs_adversarial_poisoning_pollution\seed_33_lim_None\onehot_vocab_4096_poisoned_samples_26_ratio_0.01.pkl'...   
[!] Training original model 'xgb_onehot_poison_samples_26' started: Sun Dec  3 15:43:49 2023
[*] Training xgb_onehot_poison_samples_26 model...
[!] xgb_onehot_poison_samples_26 model scores: tpr=0.9956, f1=0.9978, acc=0.9978, auc=1.0000
[!] Training of 'xgb_onehot_poison_samples_26' ended:  Sun Dec  3 15:45:25 2023  | Took: 95.52 seconds
[*] Testing 'xgb_onehot_poison_samples_26' model...
[!] Scores for 'xgb_onehot_poison_samples_26' model (): f1=0.9978, acc=0.9978, tpr=0.9956
               misclassified=1022: malicious=998 | benign=24
[*] Poisoning train set... Ratio: 0.030% | Poisoned samples: 79
[!] Sizes of train and test sets: 533093, 470129
[*] Working on 'cnn' model poisoned training...
[!] Scores already calculated for 'cnn_poison_samples_79'! Skipping...
[*] Working on 'mlp_onehot' model poisoned training...
[!] Scores already calculated for 'mlp_onehot_poison_samples_79'! Skipping...
[*] Working on 'xgb_onehot' model poisoned training...
[!] Loading One-Hot encoder from 'C:\Users\dtrizna\Code\Synapse\Linux\logs_adversarial_poisoning_pollution\seed_33_lim_None\onehot_vocab_4096_poisoned_samples_79_ratio_0.03.pkl'...   
[!] Training original model 'xgb_onehot_poison_samples_79' started: Sun Dec  3 15:46:44 2023
[*] Training xgb_onehot_poison_samples_79 model...
[!] xgb_onehot_poison_samples_79 model scores: tpr=1.0000, f1=0.9988, acc=0.9988, auc=1.0000
[!] Training of 'xgb_onehot_poison_samples_79' ended:  Sun Dec  3 15:48:21 2023  | Took: 97.75 seconds
[*] Testing 'xgb_onehot_poison_samples_79' model...
[!] Scores for 'xgb_onehot_poison_samples_79' model (): f1=0.9988, acc=0.9988, tpr=1.0000
               misclassified=561: malicious=560 | benign=1
[*] Poisoning train set... Ratio: 0.100% | Poisoned samples: 266
[!] Sizes of train and test sets: 533280, 470129
[*] Working on 'cnn' model poisoned training...
[!] Scores already calculated for 'cnn_poison_samples_266'! Skipping...
[*] Working on 'mlp_onehot' model poisoned training...
[!] Scores already calculated for 'mlp_onehot_poison_samples_266'! Skipping...
[*] Working on 'xgb_onehot' model poisoned training...
[!] Loading One-Hot encoder from 'C:\Users\dtrizna\Code\Synapse\Linux\logs_adversarial_poisoning_pollution\seed_33_lim_None\onehot_vocab_4096_poisoned_samples_266_ratio_0.1.pkl'...   
[!] Training original model 'xgb_onehot_poison_samples_266' started: Sun Dec  3 15:49:34 2023
[*] Training xgb_onehot_poison_samples_266 model...
[!] xgb_onehot_poison_samples_266 model scores: tpr=1.0000, f1=0.9999, acc=0.9999, auc=1.0000
[!] Training of 'xgb_onehot_poison_samples_266' ended:  Sun Dec  3 15:51:10 2023  | Took: 95.95 seconds
[*] Testing 'xgb_onehot_poison_samples_266' model...
[!] Scores for 'xgb_onehot_poison_samples_266' model (): f1=0.9999, acc=0.9999, tpr=1.0000
               misclassified=25: malicious=0 | benign=25
[*] Poisoning train set... Ratio: 0.300% | Poisoned samples: 799
[!] Sizes of train and test sets: 533813, 470129
[*] Working on 'cnn' model poisoned training...
[!] Scores already calculated for 'cnn_poison_samples_799'! Skipping...
[*] Working on 'mlp_onehot' model poisoned training...
[!] Scores already calculated for 'mlp_onehot_poison_samples_799'! Skipping...
[*] Working on 'xgb_onehot' model poisoned training...
[!] Loading One-Hot encoder from 'C:\Users\dtrizna\Code\Synapse\Linux\logs_adversarial_poisoning_pollution\seed_33_lim_None\onehot_vocab_4096_poisoned_samples_799_ratio_0.3.pkl'...   
[!] Training original model 'xgb_onehot_poison_samples_799' started: Sun Dec  3 15:52:23 2023
[*] Training xgb_onehot_poison_samples_799 model...
[!] xgb_onehot_poison_samples_799 model scores: tpr=1.0000, f1=1.0000, acc=1.0000, auc=1.0000
[!] Training of 'xgb_onehot_poison_samples_799' ended:  Sun Dec  3 15:54:00 2023  | Took: 96.99 seconds
[*] Testing 'xgb_onehot_poison_samples_799' model...
[!] Scores for 'xgb_onehot_poison_samples_799' model (): f1=1.0000, acc=1.0000, tpr=1.0000
               misclassified=12: malicious=2 | benign=10
[*] Poisoning train set... Ratio: 1.000% | Poisoned samples: 2665
[!] Sizes of train and test sets: 535679, 470129
[*] Working on 'cnn' model poisoned training...
[!] Scores already calculated for 'cnn_poison_samples_2665'! Skipping...
[*] Working on 'mlp_onehot' model poisoned training...
[!] Scores already calculated for 'mlp_onehot_poison_samples_2665'! Skipping...
[*] Working on 'xgb_onehot' model poisoned training...
[!] Loading One-Hot encoder from 'C:\Users\dtrizna\Code\Synapse\Linux\logs_adversarial_poisoning_pollution\seed_33_lim_None\onehot_vocab_4096_poisoned_samples_2665_ratio_1.pkl'...    
[!] Training original model 'xgb_onehot_poison_samples_2665' started: Sun Dec  3 15:55:13 2023
[*] Training xgb_onehot_poison_samples_2665 model...
[!] xgb_onehot_poison_samples_2665 model scores: tpr=0.9999, f1=0.9946, acc=0.9946, auc=1.0000
[!] Training of 'xgb_onehot_poison_samples_2665' ended:  Sun Dec  3 15:56:47 2023  | Took: 94.27 seconds
[*] Testing 'xgb_onehot_poison_samples_2665' model...
[!] Scores for 'xgb_onehot_poison_samples_2665' model (): f1=0.9946, acc=0.9946, tpr=0.9999
               misclassified=2523: malicious=2518 | benign=5
[*] Poisoning train set... Ratio: 3.000% | Poisoned samples: 7995
[!] Sizes of train and test sets: 541009, 470129
[*] Working on 'cnn' model poisoned training...
[!] Scores already calculated for 'cnn_poison_samples_7995'! Skipping...
[*] Working on 'mlp_onehot' model poisoned training...
[!] Scores already calculated for 'mlp_onehot_poison_samples_7995'! Skipping...
[*] Working on 'xgb_onehot' model poisoned training...
[!] Loading One-Hot encoder from 'C:\Users\dtrizna\Code\Synapse\Linux\logs_adversarial_poisoning_pollution\seed_33_lim_None\onehot_vocab_4096_poisoned_samples_7995_ratio_3.pkl'...    
[!] Training original model 'xgb_onehot_poison_samples_7995' started: Sun Dec  3 15:58:00 2023
[*] Training xgb_onehot_poison_samples_7995 model...
[!] xgb_onehot_poison_samples_7995 model scores: tpr=0.9698, f1=0.9907, acc=0.9908, auc=1.0000
[!] Training of 'xgb_onehot_poison_samples_7995' ended:  Sun Dec  3 15:59:36 2023  | Took: 95.42 seconds
[*] Testing 'xgb_onehot_poison_samples_7995' model...
[!] Scores for 'xgb_onehot_poison_samples_7995' model (): f1=0.9907, acc=0.9908, tpr=0.9698
               misclassified=4345: malicious=4272 | benign=73
[!] Script end time: Sun Dec  3 15:59:37 2023
[!] Script start time: Sun Dec  3 15:59:37 2023
Python implementation: CPython
Python version       : 3.9.13
IPython version      : 8.11.0

torch    : 2.0.1+cu117
lightning: 1.8.6
sklearn  : 0.0.post1

Global seed set to 42
[*] Poisoning train set... Ratio: 0.000% | Poisoned samples: 0
[!] Sizes of train and test sets: 533014, 470129
[*] Working on 'cnn' model poisoned training...
[!] Scores already calculated for 'cnn_poison_samples_0'! Skipping...
[*] Working on 'mlp_onehot' model poisoned training...
[!] Scores already calculated for 'mlp_onehot_poison_samples_0'! Skipping...
[*] Working on 'xgb_onehot' model poisoned training...
[!] Loading One-Hot encoder from 'C:\Users\dtrizna\Code\Synapse\Linux\logs_adversarial_poisoning_pollution\seed_42_lim_None\onehot_vocab_4096_poisoned_samples_0_ratio_0.pkl'...       
[!] Training original model 'xgb_onehot_poison_samples_0' started: Sun Dec  3 16:00:49 2023
[*] Training xgb_onehot_poison_samples_0 model...
[!] xgb_onehot_poison_samples_0 model scores: tpr=0.9994, f1=0.9997, acc=0.9997, auc=1.0000
[!] Training of 'xgb_onehot_poison_samples_0' ended:  Sun Dec  3 16:02:13 2023  | Took: 84.52 seconds
[*] Testing 'xgb_onehot_poison_samples_0' model...
[!] Scores for 'xgb_onehot_poison_samples_0' model (): f1=0.9997, acc=0.9997, tpr=0.9994
               misclassified=161: malicious=135 | benign=26
[*] Poisoning train set... Ratio: 0.001% | Poisoned samples: 2
[!] Sizes of train and test sets: 533016, 470129
[*] Working on 'cnn' model poisoned training...
[!] Scores already calculated for 'cnn_poison_samples_2'! Skipping...
[*] Working on 'mlp_onehot' model poisoned training...
[!] Scores already calculated for 'mlp_onehot_poison_samples_2'! Skipping...
[*] Working on 'xgb_onehot' model poisoned training...
[!] Loading One-Hot encoder from 'C:\Users\dtrizna\Code\Synapse\Linux\logs_adversarial_poisoning_pollution\seed_42_lim_None\onehot_vocab_4096_poisoned_samples_2_ratio_0.001.pkl'...   
[!] Training original model 'xgb_onehot_poison_samples_2' started: Sun Dec  3 16:03:27 2023
[*] Training xgb_onehot_poison_samples_2 model...
[!] xgb_onehot_poison_samples_2 model scores: tpr=0.9996, f1=0.9998, acc=0.9998, auc=1.0000
[!] Training of 'xgb_onehot_poison_samples_2' ended:  Sun Dec  3 16:04:53 2023  | Took: 85.98 seconds
[*] Testing 'xgb_onehot_poison_samples_2' model...
[!] Scores for 'xgb_onehot_poison_samples_2' model (): f1=0.9998, acc=0.9998, tpr=0.9996
               misclassified=104: malicious=91 | benign=13
[*] Poisoning train set... Ratio: 0.003% | Poisoned samples: 7
[!] Sizes of train and test sets: 533021, 470129
[*] Working on 'cnn' model poisoned training...
[!] Scores already calculated for 'cnn_poison_samples_7'! Skipping...
[*] Working on 'mlp_onehot' model poisoned training...
[!] Scores already calculated for 'mlp_onehot_poison_samples_7'! Skipping...
[*] Working on 'xgb_onehot' model poisoned training...
[!] Loading One-Hot encoder from 'C:\Users\dtrizna\Code\Synapse\Linux\logs_adversarial_poisoning_pollution\seed_42_lim_None\onehot_vocab_4096_poisoned_samples_7_ratio_0.003.pkl'...   
[!] Training original model 'xgb_onehot_poison_samples_7' started: Sun Dec  3 16:06:07 2023
[*] Training xgb_onehot_poison_samples_7 model...
[!] xgb_onehot_poison_samples_7 model scores: tpr=0.9998, f1=0.9994, acc=0.9994, auc=1.0000
[!] Training of 'xgb_onehot_poison_samples_7' ended:  Sun Dec  3 16:07:36 2023  | Took: 89.53 seconds
[*] Testing 'xgb_onehot_poison_samples_7' model...
[!] Scores for 'xgb_onehot_poison_samples_7' model (): f1=0.9994, acc=0.9994, tpr=0.9998
               misclassified=298: malicious=295 | benign=3
[*] Poisoning train set... Ratio: 0.010% | Poisoned samples: 26
[!] Sizes of train and test sets: 533040, 470129
[*] Working on 'cnn' model poisoned training...
[!] Scores already calculated for 'cnn_poison_samples_26'! Skipping...
[*] Working on 'mlp_onehot' model poisoned training...
[!] Scores already calculated for 'mlp_onehot_poison_samples_26'! Skipping...
[*] Working on 'xgb_onehot' model poisoned training...
[!] Loading One-Hot encoder from 'C:\Users\dtrizna\Code\Synapse\Linux\logs_adversarial_poisoning_pollution\seed_42_lim_None\onehot_vocab_4096_poisoned_samples_26_ratio_0.01.pkl'...   
[!] Training original model 'xgb_onehot_poison_samples_26' started: Sun Dec  3 16:08:48 2023
[*] Training xgb_onehot_poison_samples_26 model...
[!] xgb_onehot_poison_samples_26 model scores: tpr=0.9998, f1=0.9995, acc=0.9995, auc=1.0000
[!] Training of 'xgb_onehot_poison_samples_26' ended:  Sun Dec  3 16:10:23 2023  | Took: 94.49 seconds
[*] Testing 'xgb_onehot_poison_samples_26' model...
[!] Scores for 'xgb_onehot_poison_samples_26' model (): f1=0.9995, acc=0.9995, tpr=0.9998
               misclassified=257: malicious=245 | benign=12
[*] Poisoning train set... Ratio: 0.030% | Poisoned samples: 79
[!] Sizes of train and test sets: 533093, 470129
[*] Working on 'cnn' model poisoned training...
[!] Scores already calculated for 'cnn_poison_samples_79'! Skipping...
[*] Working on 'mlp_onehot' model poisoned training...
[!] Scores already calculated for 'mlp_onehot_poison_samples_79'! Skipping...
[*] Working on 'xgb_onehot' model poisoned training...
[!] Loading One-Hot encoder from 'C:\Users\dtrizna\Code\Synapse\Linux\logs_adversarial_poisoning_pollution\seed_42_lim_None\onehot_vocab_4096_poisoned_samples_79_ratio_0.03.pkl'...   
[!] Training original model 'xgb_onehot_poison_samples_79' started: Sun Dec  3 16:11:37 2023
[*] Training xgb_onehot_poison_samples_79 model...
[!] xgb_onehot_poison_samples_79 model scores: tpr=1.0000, f1=0.9996, acc=0.9996, auc=1.0000
[!] Training of 'xgb_onehot_poison_samples_79' ended:  Sun Dec  3 16:13:12 2023  | Took: 94.97 seconds
[*] Testing 'xgb_onehot_poison_samples_79' model...
[!] Scores for 'xgb_onehot_poison_samples_79' model (): f1=0.9996, acc=0.9996, tpr=1.0000
               misclassified=184: malicious=172 | benign=12
[*] Poisoning train set... Ratio: 0.100% | Poisoned samples: 266
[!] Sizes of train and test sets: 533280, 470129
[*] Working on 'cnn' model poisoned training...
[!] Scores already calculated for 'cnn_poison_samples_266'! Skipping...
[*] Working on 'mlp_onehot' model poisoned training...
[!] Scores already calculated for 'mlp_onehot_poison_samples_266'! Skipping...
[*] Working on 'xgb_onehot' model poisoned training...
[!] Loading One-Hot encoder from 'C:\Users\dtrizna\Code\Synapse\Linux\logs_adversarial_poisoning_pollution\seed_42_lim_None\onehot_vocab_4096_poisoned_samples_266_ratio_0.1.pkl'...   
[!] Training original model 'xgb_onehot_poison_samples_266' started: Sun Dec  3 16:14:23 2023
[*] Training xgb_onehot_poison_samples_266 model...
[!] xgb_onehot_poison_samples_266 model scores: tpr=1.0000, f1=1.0000, acc=1.0000, auc=1.0000
[!] Training of 'xgb_onehot_poison_samples_266' ended:  Sun Dec  3 16:15:58 2023  | Took: 95.28 seconds
[*] Testing 'xgb_onehot_poison_samples_266' model...
[!] Scores for 'xgb_onehot_poison_samples_266' model (): f1=1.0000, acc=1.0000, tpr=1.0000
               misclassified=13: malicious=0 | benign=13
[*] Poisoning train set... Ratio: 0.300% | Poisoned samples: 799
[!] Sizes of train and test sets: 533813, 470129
[*] Working on 'cnn' model poisoned training...
[!] Scores already calculated for 'cnn_poison_samples_799'! Skipping...
[*] Working on 'mlp_onehot' model poisoned training...
[!] Scores already calculated for 'mlp_onehot_poison_samples_799'! Skipping...
[*] Working on 'xgb_onehot' model poisoned training...
[!] Loading One-Hot encoder from 'C:\Users\dtrizna\Code\Synapse\Linux\logs_adversarial_poisoning_pollution\seed_42_lim_None\onehot_vocab_4096_poisoned_samples_799_ratio_0.3.pkl'...   
[!] Training original model 'xgb_onehot_poison_samples_799' started: Sun Dec  3 16:17:10 2023
[*] Training xgb_onehot_poison_samples_799 model...
[!] xgb_onehot_poison_samples_799 model scores: tpr=1.0000, f1=1.0000, acc=1.0000, auc=1.0000
[!] Training of 'xgb_onehot_poison_samples_799' ended:  Sun Dec  3 16:18:46 2023  | Took: 96.63 seconds
[*] Testing 'xgb_onehot_poison_samples_799' model...
[!] Scores for 'xgb_onehot_poison_samples_799' model (): f1=1.0000, acc=1.0000, tpr=1.0000
               misclassified=13: malicious=0 | benign=13
[*] Poisoning train set... Ratio: 1.000% | Poisoned samples: 2665
[!] Sizes of train and test sets: 535679, 470129
[*] Working on 'cnn' model poisoned training...
[!] Scores already calculated for 'cnn_poison_samples_2665'! Skipping...
[*] Working on 'mlp_onehot' model poisoned training...
[!] Scores already calculated for 'mlp_onehot_poison_samples_2665'! Skipping...
[*] Working on 'xgb_onehot' model poisoned training...
[!] Loading One-Hot encoder from 'C:\Users\dtrizna\Code\Synapse\Linux\logs_adversarial_poisoning_pollution\seed_42_lim_None\onehot_vocab_4096_poisoned_samples_2665_ratio_1.pkl'...    
[!] Training original model 'xgb_onehot_poison_samples_2665' started: Sun Dec  3 16:19:58 2023
[*] Training xgb_onehot_poison_samples_2665 model...
[!] xgb_onehot_poison_samples_2665 model scores: tpr=1.0000, f1=0.9957, acc=0.9957, auc=1.0000
[!] Training of 'xgb_onehot_poison_samples_2665' ended:  Sun Dec  3 16:21:30 2023  | Took: 92.16 seconds
[*] Testing 'xgb_onehot_poison_samples_2665' model...
[!] Scores for 'xgb_onehot_poison_samples_2665' model (): f1=0.9957, acc=0.9957, tpr=1.0000
               misclassified=2017: malicious=2012 | benign=5
[*] Poisoning train set... Ratio: 3.000% | Poisoned samples: 7995
[!] Sizes of train and test sets: 541009, 470129
[*] Working on 'cnn' model poisoned training...
[!] Scores already calculated for 'cnn_poison_samples_7995'! Skipping...
[*] Working on 'mlp_onehot' model poisoned training...
[!] Scores already calculated for 'mlp_onehot_poison_samples_7995'! Skipping...
[*] Working on 'xgb_onehot' model poisoned training...
[!] Loading One-Hot encoder from 'C:\Users\dtrizna\Code\Synapse\Linux\logs_adversarial_poisoning_pollution\seed_42_lim_None\onehot_vocab_4096_poisoned_samples_7995_ratio_3.pkl'...    
[!] Training original model 'xgb_onehot_poison_samples_7995' started: Sun Dec  3 16:22:40 2023
[*] Training xgb_onehot_poison_samples_7995 model...
[!] xgb_onehot_poison_samples_7995 model scores: tpr=0.9384, f1=0.8968, acc=0.9065, auc=1.0000
[!] Training of 'xgb_onehot_poison_samples_7995' ended:  Sun Dec  3 16:24:12 2023  | Took: 91.83 seconds
[*] Testing 'xgb_onehot_poison_samples_7995' model...
[!] Scores for 'xgb_onehot_poison_samples_7995' model (): f1=0.8968, acc=0.9065, tpr=0.9384
               misclassified=43969: malicious=43965 | benign=4
[!] Script end time: Sun Dec  3 16:24:13 2023