{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sizes of train and test sets: 533014, 470129\n",
      "[*] Loading predictions...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "from src.data_utils import load_data\n",
    "\n",
    "SEED = 33\n",
    "VOCAB_SIZE = 4096\n",
    "EMBEDDED_DIM = 64\n",
    "MAX_LEN = 128\n",
    "BATCH_SIZE = 1024\n",
    "DROPOUT = 0.5\n",
    "LIMIT = None\n",
    "DATALOADER_WORKERS = 4\n",
    "\n",
    "\n",
    "# ===========================================\n",
    "# LOADING DATA\n",
    "# ===========================================\n",
    "\n",
    "ROOT = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "X_train_cmds, y_train, X_test_cmds, y_test, *_ = load_data(SEED, LIMIT)\n",
    "print(f\"Sizes of train and test sets: {len(X_train_cmds)}, {len(X_test_cmds)}\")\n",
    "\n",
    "LOGS_FOLDER = \"logs_models\"\n",
    "y_preds_pickle = os.path.join(LOGS_FOLDER, \"y_preds.pkl\")\n",
    "if os.path.exists(y_preds_pickle):\n",
    "    print(\"[*] Loading predictions...\")\n",
    "    with open(y_preds_pickle, \"rb\") as f:\n",
    "        y_preds = pickle.load(f)\n",
    "else:\n",
    "    y_preds = {}\n",
    "\n",
    "    from watermark import watermark\n",
    "\n",
    "    print(watermark(packages=\"torch,lightning,sklearn\", python=True))\n",
    "    print(f\"[!] Script start time: {time.ctime()}\")\n",
    "\n",
    "    # encoders\n",
    "    from sklearn.feature_extraction.text import HashingVectorizer\n",
    "\n",
    "    # tokenizers\n",
    "    from nltk.tokenize import wordpunct_tokenize, WhitespaceTokenizer\n",
    "    whitespace_tokenize = WhitespaceTokenizer().tokenize\n",
    "\n",
    "    # modeling\n",
    "    import lightning as L\n",
    "    from lightning.pytorch.loggers import CSVLogger, TensorBoardLogger\n",
    "    from lightning.pytorch.callbacks import ModelCheckpoint, EarlyStopping\n",
    "    from lightning.fabric.utilities.seed import seed_everything\n",
    "\n",
    "    # import random forest, xgboost, and logistic regression\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from xgboost import XGBClassifier\n",
    "\n",
    "    from src.models import *\n",
    "    from src.lit_utils import LitProgressBar\n",
    "    from src.preprocessors import CommandTokenizer, OneHotCustomVectorizer\n",
    "    from src.data_utils import create_dataloader\n",
    "\n",
    "    from typing import List\n",
    "    from torch.utils.data import DataLoader\n",
    "\n",
    "    def sigmoid(x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def get_tpr_at_fpr(predicted_logits, true_labels, fprNeeded=1e-4):\n",
    "        if isinstance(predicted_logits, torch.Tensor):\n",
    "            predicted_probs = torch.sigmoid(predicted_logits).cpu().detach().numpy()\n",
    "        else:\n",
    "            predicted_probs = sigmoid(predicted_logits)\n",
    "        \n",
    "        if isinstance(true_labels, torch.Tensor):\n",
    "            true_labels = true_labels.cpu().detach().numpy()\n",
    "        \n",
    "        fpr, tpr, thresholds = roc_curve(true_labels, predicted_probs)\n",
    "        if all(np.isnan(fpr)):\n",
    "            return np.nan#, np.nan\n",
    "        else:\n",
    "            tpr_at_fpr = tpr[fpr <= fprNeeded][-1]\n",
    "            #threshold_at_fpr = thresholds[fpr <= fprNeeded][-1]\n",
    "            return tpr_at_fpr#, threshold_at_fpr\n",
    "\n",
    "\n",
    "    def commands_to_loader(cmd: List[str], tokenizer: CommandTokenizer, y: np.ndarray = None) -> DataLoader:\n",
    "        \"\"\"Convert a list of commands to a DataLoader.\"\"\"\n",
    "        tokens = tokenizer.tokenize(cmd)\n",
    "        ints = tokenizer.encode(tokens)\n",
    "        padded = tokenizer.pad(ints, MAX_LEN)\n",
    "        if y is None:\n",
    "            loader = create_dataloader(padded, batch_size=BATCH_SIZE, workers=DATALOADER_WORKERS)\n",
    "        else:\n",
    "            loader = create_dataloader(padded, y, batch_size=BATCH_SIZE, workers=DATALOADER_WORKERS)\n",
    "        return loader\n",
    "\n",
    "\n",
    "    def configure_trainer():\n",
    "        \"\"\"Configure the PyTorch Lightning Trainer.\"\"\"\n",
    "\n",
    "        trainer = L.Trainer(\n",
    "            num_sanity_val_steps=0,\n",
    "            max_epochs=1,\n",
    "            accelerator=\"gpu\",\n",
    "            devices=1,\n",
    "            callbacks=[LitProgressBar()],\n",
    "            logger=TensorBoardLogger(\"logs_temp_results_roc_ablation_models\", name=\"my_model\"),\n",
    "            val_check_interval=0.5,\n",
    "            log_every_n_steps=10,\n",
    "        )\n",
    "        return trainer\n",
    "\n",
    "\n",
    "    def load_lit_model(model_file, pytorch_model, name, log_folder):\n",
    "        lightning_model = PyTorchLightningModel.load_from_checkpoint(checkpoint_path=model_file, model=pytorch_model)\n",
    "        trainer = configure_trainer()\n",
    "        return trainer, lightning_model\n",
    "\n",
    "    seed_everything(SEED)\n",
    "    TOKENIZER = wordpunct_tokenize\n",
    "\n",
    "    # =============================================\n",
    "    # PREPING DATA\n",
    "    # =============================================\n",
    "    tokenizer = CommandTokenizer(tokenizer_fn=TOKENIZER, vocab_size=VOCAB_SIZE)\n",
    "\n",
    "    # ========== EMBEDDING ==========\n",
    "    vocab_file = os.path.join(LOGS_FOLDER, f\"wordpunct_vocab_{VOCAB_SIZE}.json\")\n",
    "    if os.path.exists(vocab_file):\n",
    "        print(\"[*] Loading vocab...\")\n",
    "        tokenizer.load_vocab(vocab_file)\n",
    "    else:\n",
    "        print(\"[*] Building vocab and encoding...\")\n",
    "        X_train_tokens = tokenizer.tokenize(X_train_cmds)\n",
    "        tokenizer.build_vocab(X_train_tokens)\n",
    "        tokenizer.dump_vocab(vocab_file)\n",
    "\n",
    "    # creating dataloaders\n",
    "    # X_train_loader = commands_to_loader(X_train_cmds, tokenizer, y_train)\n",
    "    X_test_loader = commands_to_loader(X_test_cmds, tokenizer, y_test)\n",
    "\n",
    "    # ========== MIN-HASH TABULAR ENCODING ==========\n",
    "    minhash_vectorizer_file = os.path.join(LOGS_FOLDER, f\"minhash_vectorizer_{VOCAB_SIZE}.pkl\")\n",
    "    if os.path.exists(minhash_vectorizer_file):\n",
    "        print(\"[*] Loading MinHash vectorizer...\")\n",
    "        minhash = pickle.load(open(minhash_vectorizer_file, \"rb\"))\n",
    "    else:\n",
    "        minhash = HashingVectorizer(n_features=VOCAB_SIZE, tokenizer=TOKENIZER, token_pattern=None)\n",
    "        print(\"[*] Fitting MinHash encoder...\")\n",
    "        minhash.fit(X_train_cmds)\n",
    "        \n",
    "        with open(minhash_vectorizer_file, \"wb\") as f:\n",
    "            pickle.dump(minhash, f)\n",
    "\n",
    "    # X_train_minhash = minhash.transform(X_train_cmds)\n",
    "    X_test_minhash = minhash.transform(X_test_cmds)\n",
    "\n",
    "    # ========== ONE-HOT TABULAR ENCODING ===========\n",
    "    oh_vectorizer_file = os.path.join(LOGS_FOLDER, f\"onehot_vectorizer_{VOCAB_SIZE}.pkl\")\n",
    "    if os.path.exists(oh_vectorizer_file):\n",
    "        print(\"[*] Loading One-Hot vectorizer...\")\n",
    "        oh = pickle.load(open(oh_vectorizer_file, \"rb\"))\n",
    "    else:\n",
    "        oh = OneHotCustomVectorizer(tokenizer=TOKENIZER, max_features=VOCAB_SIZE)\n",
    "        print(\"[*] Fitting One-Hot encoder...\")\n",
    "        oh.fit(X_train_cmds)\n",
    "\n",
    "        with open(oh_vectorizer_file, \"wb\") as f:\n",
    "            pickle.dump(oh, f)\n",
    "\n",
    "    # X_train_onehot = oh.transform(X_train_cmds)\n",
    "    X_test_onehot = oh.transform(X_test_cmds)\n",
    "\n",
    "    # =============================================\n",
    "    # DEFINING MODELS\n",
    "    # =============================================\n",
    "    print(f\"[*] Defining models...\")\n",
    "\n",
    "    # sequence models\n",
    "    mlp_seq_model = SimpleMLPWithEmbedding(vocab_size=VOCAB_SIZE, embedding_dim=EMBEDDED_DIM, output_dim=1, hidden_dim=[256, 64, 32], use_positional_encoding=False, max_len=MAX_LEN, dropout=DROPOUT) # 297 K params\n",
    "    cnn_model = CNN1DGroupedModel(vocab_size=VOCAB_SIZE, embed_dim=EMBEDDED_DIM, num_channels=32, kernel_sizes=[2, 3, 4, 5], mlp_hidden_dims=[64, 32], output_dim=1, dropout=DROPOUT) # 301 K params\n",
    "    lstm_model = BiLSTMModel(vocab_size=VOCAB_SIZE, embed_dim=EMBEDDED_DIM, hidden_dim=32, mlp_hidden_dims=[64, 32], output_dim=1, dropout=DROPOUT) # 318 K params\n",
    "    cnn_lstm_model = CNN1D_BiLSTM_Model(vocab_size=VOCAB_SIZE, embed_dim=EMBEDDED_DIM, num_channels=32, kernel_size=3, lstm_hidden_dim=32, mlp_hidden_dims=[64, 32], output_dim=1, dropout=DROPOUT) # 316 K params\n",
    "    mean_transformer_model = MeanTransformerEncoder(vocab_size=VOCAB_SIZE, d_model=EMBEDDED_DIM, nhead=4, num_layers=2, dim_feedforward=128, max_len=MAX_LEN, dropout=DROPOUT, mlp_hidden_dims=[64,32], output_dim=1) # 335 K params\n",
    "    cls_transformer_model = CLSTransformerEncoder(vocab_size=VOCAB_SIZE, d_model=EMBEDDED_DIM, nhead=4, num_layers=2, dim_feedforward=128, max_len=MAX_LEN, dropout=DROPOUT, mlp_hidden_dims=[64,32], output_dim=1) #  335 K params\n",
    "    attpool_transformer_model = AttentionPoolingTransformerEncoder(vocab_size=VOCAB_SIZE, d_model=EMBEDDED_DIM, nhead=4, num_layers=2, dim_feedforward=128, max_len=MAX_LEN, dropout=DROPOUT, mlp_hidden_dims=[64,32], output_dim=1) #  335 K params\n",
    "    neurlux = NeurLuxModel(vocab_size=VOCAB_SIZE, embed_dim=EMBEDDED_DIM, max_len=MAX_LEN, hidden_dim=32, output_dim=1, dropout=DROPOUT) # 402 K params\n",
    "\n",
    "    # tabular models\n",
    "    rf_model_minhash = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=SEED)\n",
    "    xgb_model_minhash = XGBClassifier(n_estimators=100, max_depth=10, random_state=SEED)\n",
    "    log_reg_minhash = LogisticRegression(random_state=SEED)\n",
    "    mlp_tab_model_minhash = SimpleMLP(input_dim=VOCAB_SIZE, output_dim=1, hidden_dim=[64, 32], dropout=DROPOUT) # 264 K params\n",
    "    rf_model_onehot = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=SEED)\n",
    "    xgb_model_onehot = XGBClassifier(n_estimators=100, max_depth=10, random_state=SEED)\n",
    "    log_reg_onehot = LogisticRegression(random_state=SEED)\n",
    "    mlp_tab_model_onehot = SimpleMLP(input_dim=VOCAB_SIZE, output_dim=1, hidden_dim=[64, 32], dropout=DROPOUT) # 264 K params\n",
    "\n",
    "    models = {\n",
    "        \"_tabular_mlp_minhash\": mlp_tab_model_minhash,\n",
    "        \"_tabular_rf_minhash\": rf_model_minhash,\n",
    "        \"_tabular_xgb_minhash\": xgb_model_minhash,\n",
    "        \"_tabular_log_reg_minhash\": log_reg_minhash,\n",
    "        \"_tabular_mlp_onehot\": mlp_tab_model_onehot,\n",
    "        \"_tabular_rf_onehot\": rf_model_onehot,\n",
    "        \"_tabular_xgb_onehot\": xgb_model_onehot,\n",
    "        \"_tabular_log_reg_onehot\": log_reg_onehot,\n",
    "        \"mlp_seq\": mlp_seq_model,\n",
    "        \"attpool_transformer\": attpool_transformer_model,\n",
    "        \"cls_transformer\": cls_transformer_model,\n",
    "        \"mean_transformer\": mean_transformer_model,\n",
    "        \"neurlux\": neurlux,\n",
    "        \"cnn\": cnn_model,\n",
    "        \"lstm\": lstm_model,\n",
    "        \"cnn_lstm\": cnn_lstm_model,\n",
    "    }\n",
    "\n",
    "    for name, model in models.items():\n",
    "        if name in y_preds:\n",
    "            print(f\"[*] Model {name} already predicted\")\n",
    "            continue\n",
    "\n",
    "        if name.startswith(\"_tabular\") and \"mlp\" not in name:\n",
    "            \n",
    "            model_file = os.path.join(LOGS_FOLDER, name, \"model.pkl\")\n",
    "            print(f\"[*] Loading {name} from {model_file}...\")\n",
    "            with open(model_file, \"rb\") as f:\n",
    "                model = pickle.load(f)\n",
    "            \n",
    "            preprocessor = name.split(\"_\")[-1]\n",
    "            assert preprocessor in [\"onehot\", \"minhash\"]\n",
    "\n",
    "            if preprocessor == \"onehot\":\n",
    "                # x_train = X_train_onehot\n",
    "                x_test = X_test_onehot\n",
    "            \n",
    "            elif preprocessor == \"minhash\":\n",
    "                # x_train = X_train_minhash\n",
    "                x_test = X_test_minhash\n",
    "\n",
    "            print(f\"[*] Predicting with {name}...\")\n",
    "            y_test_preds = model.predict_proba(x_test)[:,1]\n",
    "            y_preds[name] = y_test_preds\n",
    "        \n",
    "        else:    \n",
    "            if \"tabular\" in name:\n",
    "                preprocessor = name.split(\"_\")[-1]\n",
    "                assert preprocessor in [\"onehot\", \"minhash\"]\n",
    "\n",
    "                if preprocessor == \"onehot\":\n",
    "                    # x_train = X_train_onehot\n",
    "                    x_test = X_test_onehot\n",
    "                \n",
    "                elif preprocessor == \"minhash\":\n",
    "                    # x_train = X_train_minhash\n",
    "                    x_test = X_test_minhash\n",
    "\n",
    "                # train_loader = create_dataloader(x_train, y_train, batch_size=BATCH_SIZE, workers=DATALOADER_WORKERS)\n",
    "                test_loader = create_dataloader(x_test, y_test, batch_size=BATCH_SIZE, workers=DATALOADER_WORKERS)\n",
    "            \n",
    "            else:\n",
    "                # train_loader = X_train_loader\n",
    "                test_loader = X_test_loader\n",
    "            \n",
    "            chkp_folder = os.path.join(LOGS_FOLDER, f\"{name}_csv\", \"version_0\", \"checkpoints\")\n",
    "            if not os.path.exists(chkp_folder):\n",
    "                print(f\"Model {name} not trained yet\")\n",
    "\n",
    "            best_model = [x for x in os.listdir(os.path.join(LOGS_FOLDER, f\"{name}_csv\", \"version_0\", \"checkpoints\")) if x.startswith(\"epoch\")][0]\n",
    "            best_model = os.path.join(chkp_folder, best_model)\n",
    "            print(\"Best model: \", best_model)\n",
    "            trainer, lightning_model = load_lit_model(best_model, model, name, LOGS_FOLDER)\n",
    "            print(f\"[*] Predicting with {name}...\")\n",
    "            y_pred_proba = trainer.predict(lightning_model, test_loader, return_predictions=True)\n",
    "            if isinstance(y_pred_proba, list):\n",
    "                y_pred_proba = np.vstack(y_pred_proba).squeeze()\n",
    "\n",
    "            y_preds[name] = y_pred_proba\n",
    "\n",
    "    with open(y_preds_pickle, \"wb\") as f:\n",
    "        pickle.dump(y_preds, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbYAAAEtCAYAAABkqEXwAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAABSmUlEQVR4nO29eXwb13n3+zsgwU0Lh6A2y1IkDSXHduzEBsg4dlpHscEoidNmKSg3S5vmTQT0bdq3vm4vcZXeVmo/ahWgbW7e26YuoLpvtjaRgKbtbZMmBuSo6tvGCUk4dpw4joOhZDuSbJHgaONOnPvHLBwAg5WDheDz9YcW58xZnplDnAfPc55zDuOcgyAIgiCaBVu9BSAIgiAIKyHFRhAEQTQVrfUWgGhOGGNOAKcBxAFIACYBPKzePgmgF4AIwA3AxTmX6iFnNWCMDQM4DCAFIGS41QcgxDlPFCgnq+UAwME5D5fQVi+U9ysDSHHOo4wxD4A451yu/EkIYnVCio2oFg4AfuPAzBjrAwDOedCQNgxAqLQRxphQ7cG73DY450HG2AAAyfisal1jjLHjnPOoIU0EEABwyNgOY0xkjEWy0w1lQlAUpfF9CowxLwA/AFcZj0kQTQO5IolqIRSzNlTCUCy3Sjm4grLVbmPSJO04gBNZaTEoXwJkY6JqxYYAREzqiQAIGBWkWkYGcAore6cEsaohxUbUFQusrUEr5KhhGzIAgTEmALrFmsjniuWcxwE4VNciDGVS6j2zMjKULwwEsSYhxUZUC9NB14K8OoyxAFbgxqxTG4PInPvyARgpUmZUzafhg7kVZyRWkXQE0QTQHBtRFcqck5KBZesFiiLRAyfUOSPNohGgzN+l1N9FtRwAhAu1a1aPoY2ctlUrqaw2CrQtAPBCcdEaLUBRbbcQY8h0h4pQlF1esl2UBeTyIitYRQ38OQHFKhw05PNDcX8a84xCUbIiFKUdU/PJAIY0S5QxFlPz+DRLs5z+LtGtTRAASLERDYIaJHFcixhkjAVUxeKAYuFoA6QA4LA6uEoAxOwAjTz1e83qKdS2Gl1YchsmDDDG3FCVI5ToRb9BJm0eLJVbNANNiRvLrBjVGk1qSlANVvGq7/YQlIAWAICa5jJcJxhjfjVPAIqCE9R8QG6kawgGS7Xc/rbqmYm1AbkiibqjDtbOrDD4k1h2v+luOHVgPFlhUzn1lND2ShjhnMc551FVMZ6EYn1pMmgDfzFlJUKxgMAtWhahWZBZlpAHypKEfMhZ1ykoykzinMua8lfrzAm4MSi1WvU3sUYhi41oBNwAZNW60RCgWEphxliEMcahzMVFKnFL5atHteRM2670YQrIkGCMORhjbkPgh1RCW33IdD1KAPpRwIXJGBOLKEE3lt19mnyVWKX52jhlsP4EZCrFqvc3sbYhxUY0AgKUNV/ZQSRRdQ3ZkDo49gPwM8ZcnPMci6rQYJ6vHgDJfG3nqaeYwihGCpmKLARlbqqQUnHD4MJUywyhcOSjE/mVjpXIedJDUObgwgDcWXN+Aizob4LIB7kiiUYggfxWy2FAcUmpbr3BAnmdBdrIV0+htsttoxRkGNx9qpUkqsEYOajzTrJRMahlHPnKlIjpc2vLEFQ5HVm3BZSI6mYU8swJWtXfBGEKKTailmQPlAD0tVqp7IFadRPq/xqQDP8aBz25UONm9RRru9w2sug1SRuFqhwZY0514B8EEMhWAqpMPgAPmtQzpJZxZ99QXYAFoyJVq/OUyTvR6tMDVgyIJmnZ10YCUCImMyyzFfQ3QZQEo2NriGqjDr5OLEe3HYeyKDmelS9jr0Q1KlELCdcQYFjQbCxTaDAvpx6tbTO5SgmjV6MNNSU1kr3lFRQX3ck87RgH8aLRmIZlCMBygEnJc1KGZ5OgBIKYPbeE5XlHHxS3qASlP91Q+jNnGYT6rIF8bsRK+psgSoEUG0EQBNFUkCuSIAiCaCpIsREEQRBNBSk2giAIoqkgxUYQBEE0FTVfoP3QQw/xgYEBS+o6d+4cdu/eXZUypeQrlCffPbP07LSFhQWcP38ee/fuLSpntajk3VpZl1X9VEkf5bvXzP1UzT4qJa9Vn6Xs9Gbqo0rrWi1j3p/8yZ98g3P+UFFBS4FzXtOft73tbdwqjhw5UrUypeQrlCffPbP07LTp6Wn+qU99qmj71aSSd2tlXVb1UyV9lO9eM/dTNfuolLxWfZay05upjyqta7WMeQDOcIv0TM1dkVZ9cwGA/fv3V61MKfkK5cl3zyy9kueoNlbKVM9+qqSP8t1r5n6qZh+Vkteqz1IpbdWaZvksFcvTSGNezdexHT16lB89erSmba42ZmZmcPbsWRw4cKDeohAFoH5qfKiPVgczMzPo6ur6Auf816yor+YW27lz53D06FGcOXOm1k2vKu6///56i0CUAPVT40N91PicPXvW0vpqHjyye/dukMVGEARBaKhfPs5ZVR+F+xMEQRBNBSk2giAIoqkgxUYQBEE0FaTYCIIgiKaCFBtBEATRVJBiIwiCIJoKUmwEQRBEU0ELtAmCIIi6oi7Q3m1VfbRAmyAIgqgrtECbIAiCIApAio3IYX5+HjMzM/UWgyAIoiJMXZGMMQHAQQCDnPOhUipijHkBpNRLkXMetETCAjz11FOYnZ2tdjM1Z2FhAQBgt9vr0v7s7CympqZwzz33YNeuXWhpaamLHARBEJWQo9gYY04AIhQlJZZSiabUOOdR9VpkjIU45z4rhc1mdna24c5esgLNWurs7KybDPF4HHNzc/je976Hvr4+bN68GYyxuslDEARRKjmKjXOeAJBQFVyp+DjnLkMdEmOs3woBifrQ2tqK2267DVeuXMGLL76ICxcuYO/evVi/fn29RSMIgijIiqMiVbelmWWXYoy5OedxY+LCwoJl8zcrqmv6AmwTCUvksJqlecUVOddWH1ckACxOvIa5Fy6jA8Ad6zkupWaRiH8Hm7rbsWvrOrS2NN707FKa479+MoEr0/Mllyn3nF1j/nR6CQBgsymu2vXpSWxbfB7zrAsAcIPdwAybgVKEA+DK/7n6k7aBcxvSHMq/S8o7TXNgDnNo5W3gaRsW5zrAGMA5A+cM4Dbl96UWLC20ocW+oMqlWtRaPgAcTGkay2nQ7nGG+Rsb0WKfA2P5X4Q1RxHX9kBjvVW12VKcDdZKyAEOMM7BOMDSSu2MG9LVbLa0oWWu5Vu+1vIxACydBuMA1x9o+X5Gu1kPxfLd1+9lPX1WHqNs2fkAgGm/mGTJqEeto212CQsdy1McVv91WBHur7kts5FhovDOnz+PY8eOAVBCPOt1CGD7NwZhuzZel7aL0V5vAQC03tiP9tfO6Ne7AdzM7Rgf34NnljZhj13CttZLJQ0YtcRdbwEKcGXWgSdfeh9+NDFQb1EIor7YASxlJ35xt1XVW6HYHAXuCdkJe/futWwdm91ur3weauaS8u/r3gXYarucj3OOZ1+ScWN2wfy++m8pOkO+odRRjoIpxUr5WfomTM+Ze6PnOceL028BAHSz19DGGi+AR9xahsuUAYtYxKstF7Ckfto445hD+c+1ZWkB3+noxs9al7+ebF3aBr5ox5L0FqQndi5nti0CtrTylZlxYL4DsC2CdcwCjIOzJdhgQ3q2E7auG7C1z+p5mWIGgC+1AkutsHVOq8+iWIb6H496zYxf+7P+5TNdaNlwJfe1pNPomF2ALc0hTN4AAwdLKz/rrs9jrrNVsTzSigXSMbOAtA1I22zouj6HdIsNnCkWScfsAhZbbGhdSpf9TlczHAxpG9CS5phvU8YZzhi4TbFxOGMAA7puzOH6hg79vtI/DJxpBjbTrbS22QUstLVgya5ZPKoFrve5bj/lpmlGO5bb0KrIGBYMA4qebpY/oxzL+Ierv/Ks+jTa5hYx19FqbORcTqYKqfkC7dizFzDz5TFL6rKnLuDfXqmsrqPzS+i0AW//7icwxzsskadUnv/ZFcx3XkV6/bWatqvD0khvvAq22ArH+nbFzaUOftrfrnN2CYnOO9Rr5U9Ud1cxZSBzpIHt82lcaWW41AYs2tjy3746cE5em8Omje1oa7XpH4B5+w0wMLQs2XUfCc/wp2hpho+alg8cN+YWsWfLemgDNlcHaAaA2YC+bRvQ1d4CzrnuAPzR9Zewq3MLWphNT9fq4+A4eenfAezL+8rsrBUtzAYbGGxMcRleX5rBL/W+FQvpJbx5462wgeH76UXcv/GNeNfsRrRcZZi+OouJC1N46oln9Lq27tqEh3/3XdjQs66sblsx6TTw/NPA9DXg0itA6jVg/Hlg4xwwNwN8/7+Acy8AG7qB2RlgoXSXbtm0dwCd6wBbC2CzLf/b0qJ04vwckHoVuPVu5V5rK9Ci/bQA4z8GbncBrfbln8lXgW07gfXdSn5bCxY4B2wtsF+/AmzfBXR0KeVtLYZ/1Tpnp4F1G4GOzuV0tR60tgJLS0p5my1T5px/bUrZ9d1AnSKbVxszMzPA439vWX3VVGyCWeJIchLPPvGCJQ3c1zOJ/xqtrK4jqjfohy9fwUy6thZHun0G07/4NcBWn3kHIxfzpO97eSd+tvPlgmVfAvBcmmHX1W5su7EO5zZewYX115e/JapYqb4ZB9rn7dDURNtCK7rm2vT726Y24gfnVcMGDIwz1chh+CnOgXGGHZM9SDOONOPou7gZqQ038Kt4K2wc2GTvhtixDeDA1Zevo7WtBR3tbeCcI53m4GmuKMY0x+z0PNK6BXIVaQAtAP4T38kr/87X34R3/trPVVepLSwAif8AfvBd4EcJoK0deDkJPPtUaeWvZVlvt94F2NsUU//+h5Tf7W3A1ASwQ1QVgF0ZxGemAcdmoF31pGzZDrR1KDK0dwLrNihKokYsqnPw9jpGGBO1x4q/sFGYuyMdAHKiM9x33oSHPlROwGV+brzyHH5xxx0VlbWP2wAOnP6Dd4C3dFkiT6m8OPcSPOdOYl1LB+7tvi3nfjqtDJY2W/UCNG4szWGRL+HODbsBqEpA9SEwABuvzOH1O95ouKfAGMvMy5T7tlmO+y7OgS1wLG7vAF/Xgsycy2UB4NJcCtvaHVjX0qFYWoZ6tWssAXhuAbihWWQMi9+4Yfm72HRtQ8Z1CrL+++LsImYxV7SOFnuLajEqz7cwtwjHtm5cl6exeYcDvdsF3H5PH/re9DrrBH/tAvCtU8DigmJdPREBXnimeLkN3cAb3wJcvgjc5gS23KxYM/Y2RUHdMaBYPm3t5fm4CaJBWLFi45zLjLEUY0zgnMuGW0J2RCQAvHnvJnzynbeutFkAwJkzl7B/f4V1hRmwCNy5swew11axsWsycA7Y07kNsf5Azv1GWMd25vIZ7L99f1ll+Js4Ll++jGQyie6ObvT19YFxm66oNV75ySWc/YdRpNNpZb6PczVSUInY4lyxilKXcud9NNo72/Qxd3Z6Hlte1wsAWJxfxNLiEna+/iZFWTKmKxtmU68ZcF2exp47dgAA0ktp9N4kGO4rebRyG3rWLd+zMdhsNjDGMDc/C5vNBqG3u6z3VDacA9LzwH9+Cxg5o7jMnsr5aGXS1q4ou/sfAgbeDtz0OiC9BOy7E+i7vbryEkSdKaTYTINCGGMigACAQwZFFgDgBRBU8zgBFPnkEc3A1cnrkH7wsqKUVNrSG/DKxdfwr184jflJDszaDXZbZQwcuFP//XW3bsetA3tWVJ8V2Kqx69jSkqK4xn8MfOmzwKuvAGNnC5d541uAex5QrK2WVuCDvwlsFKogHEGsDsx2HhEBeAAMAnAyxgIAkpzzsJpFhBJV7YAS0g/OeZgx5mWMebQ81d51hKgN16ZuQL58Ne/9rwa/gfl80Z22FvB1c0D7ItqW1sO2tPzntrS4hIcO7cemm3sMLjwGZlNcjmCKO7LV3oLuTRtM628aOAemrwPPjQCfeLBw3pt3A+/+ELCzD9h7h+I2JHchQWRgtvOIBMXyMt3rUXUv9pikh02yEw0I5xyXzk1g5nr+oJmpV6/gR0/9FP/4l6UZ3lt3bcJNezblpG/oWYfbfn43pHEJ69atw969e9HRUdso1IZlZhr47fcB34nl3nNsUaIW738I+PBvA90O4HYnKTGCKIGah/trB43u37+/Kfd5rDUv/fginvjSf2JxYbHkMpMX5KJ5lhzX8aN/WY6Z3LFva968PVu78Z5D+2ErsBtJ76ZevPzyyxgbG8PNN9+MnTt30ubKPxrLVGobe5SIwv/z/wHuf3f95CKIGkMHjVrEfHoJbQDufuq/Y7bGC7RfuP4y3vvU3dh1YxO+9OQ/59xfUoMtWkqIinzpx/kC9ktDC6DIZnLxAnq3bwdjwBvvvxVvuHfvitqx2WzYtWsXtm7dimQyiZGREezduxe9vb1rd3NlbV7SsQX4NwnoqvG6NoJoEKw+aLTmiq1RmF5oweXp3bh2fhpzrLb7Ht59ZRcGXlSCH166sDLFpPH2h+/BLc7dJedvtbdA2LIx7/0zZ85UxaLu6OjAG97wBkxNTWVsrtzVVdvI1LrywrPAk/8IxP5Bud79elJqBGEhNVdsP/zpSUS+9awldb328lZcnvt/Kyo79ezv4vLMdnzsB5aIUhHClo14z6H9Oelzc8q6qfb20naN7FjXji07HavK8unp6UF/fz9+9rOf4emnn8ZNN920Ns5+W1oCPnZ/5iLoDVVeLkAQa4yaK7Y3TP0YQ8kfW1LXmRv7sX/+TEVlA3P7AQBbdzvQ0lIfw9X14Buw67btOemNsI6tFthsNuzcuVN3T37ve9+DKIrYsmXLqlLSZZFeWlZqbz0AvGEAeN/H6isTQTQZNR/RLwm34Jk9r7emrlduwjM7KgsFT39XsQw++vvvh72d9nOrJ21tbTlnv+3bt6+5z35rtQN//c16S0EQTUnNFdu2fR/Em9511JK6ps6cwZsqnAf6ZuRvkF4qPZKQqD7d3d1wuVy4ePEinnnmGWzZsgW7d++GvVk2kr1xDfiHv6m3FATR9DTeaZHEmoYxhu3bt+PNb34zOOcYGRnBxYsXM3Y2WbX80+eBP31U+b2ria1RgqgzpNiIhsRut+OWW27BnXfeiYsXLyKRSODq1fw7oKwKbqjyv+le4E9P1lcWgmhiaq7YtAXaZ86cqXXTxCpkw4YNuPvuu3HzzTfjueeewwsvvID5+SqeE1YL3vx24L7BektBEA0DLdAm1hyMMWzbtg2bNm3CuXPnMDIygt27d2P79u3NGz1JEGsIqxdokyuSWDW0trZi7969uOuuu3D58mWMjo5CluV6i0UQRIOxanceuXLlir7ei1hbrFu3Dm9605swMTGB559/Ht3dytlvpS5oJwiiuVm1im1xcRE3btyoeK5uofsq0ktpnP2Ps2hpbazdLhYWlGNg6hnm3ug78DPGsHnzZjgcDrz00ksYHR3Fzp07sWPHjqqePF4xj/0REKUDMAiiFqxaxdbT04Nt27ZhYGCgom/q3/3iT7E4v4j7f/7+hlugvVZ2HrGClpYW7NmzB9u2bcNPf/pTXLx4Efv27YPDYXpObu35Thz41K8AE5eW03aI9ZOHINYAq1ax2Ww29Pb2YmJiAjfffHO9xSHqTGdnJ+68805MTk7ixRdfxLp169DX11f/LwffeWJZqbV3AF8dBfpur69MBNHkNKDPpnQ2b96My5cv11sMooHo7e3FwMAANmzYgEQigXPnzmFpaaneYgG/8YfA924Ae99Ah4USRJVZ1evYenp6cP369dW/romwFO3sN5fLhRs3bmBkZASXL1+u7+4l7R1AI879EUQDQOvYDLS0tMDhcGBiYgLbt+fukk+sbczOftu3b9/aOvuNIFYBtI4tC3JHEsXQzn5zOBx4+umnkUwmsbhYgw2wL70CXHyp+u0QBJHBqldsDocDV69e1UPkCcIM7ey3gYEBLCwsYGRkBK+++mp13JNf/3vgvbcDgzuBb6p7Qjb7AaoE0UCsesXW0tKCnp4eTE5O1lsUYhXQ1taGW2+9FbfffjtefvllPPfcc9Y38oU/A6Tnl6/3/wLw4Aesb4cgCFNWbbi/kc2bN+O1117Dtm3bqtrOJz7xCezYsaOqbRC1ZXx8HF/4whesqYxz4MXngOefVq7/PAI88D6gtSk+ZgSxamiKT1xvby9+8pOfYHFxEa1VHER27NhBGzg3GZb15+wM8L/+FPirI8tpu24hpUYQdaApPnWtra0QBAGTk5PYunVrvcUh1ho//SHwoTcDM9PLaQ99WFmzRhBEzWkKxQYsR0eSYiNqzos/UJRaqx3YthP4TBS47e56S0UQa5ZVvUDbSG9vL6amphpjlwlibeL+APBvSVJqBFEmtEA7D3a7Hd3d3ZicnMSWLVssr58gCIKoDrRAuwC0WJsgCILIa7ExxrwAUuqlyDkPFqtMLSMAkAEIpZSxkk2bNiGZTGJpaQkttCCWIAhiTWJqsWlKjXMe5ZxHAUQZY6FCFTHGhgGAcx7knIcBSIyxgOUSF8But2PDhg1IpVLFMxMEQRBNST5XpE9VaAAAzrkEoL9IXQFVoWllogC8KxexPDZt2oSJiYlaN0sQBEE0CDmKjTEmADA74jfFGHObVcIYc0JxP2Yj5StTLTZv3ozJyUmk0+laNksQBEE0CGZzbCKW59aMyDBXeADgKNBGRpmFhQXMzMyUJFyltLW14eLFi3A4ComlbH47MzOLxXQNdnonGpKV/D3Ozs4CAFrm59EGYHFpCQtV/tsmykPrI6KxsbqfzBRbIW0g5EkfzXNPzE4/f/48jh07BkAJ8VTDPC2lt7cXk5OTRRRbg/DTU8DkD+otBUEQRM05e/Yszp49qx0jtduqei1Zx8Y5lxljYcaYm3MeB3T3pJSdd+/evVXfb3HHjh0YGRlBe3s7bHlPLWYAgM7ODtjb7VWVJy/TrwJPPFyftgkAgN1+BJ2dnSuqo62tDQDQ2tKC1hXWRVSHlfYxUR0OHDiAAwcOYGZmBsFg8JxV9Zaj2IRCNznnPsbYMGNMS9LcmYkK5FoR7e3t6OrqgizLjW21Lap7C7Z1A3f9Tn1lWav8K+1UQxDNhpliG4W5O9KBIkoqe90aY0yEidVWC7TF2g2t2DTae4D+36+3FGuTfz1aedl0Gq2PHVXOXyMIomHIUWyqWzHFGBM457LhlqC5Gc1gjDk55wnjNYBRdalAzdm0aRMSiQRuueUWGKxIooFJpzk+/+9JXEhNF89cgO/9dALf/uEl9KxTXIScc3Aox6Vl//7fV3C8HnvxWdiNSq2XNuAmiEYgnysyAGUNWhDQlZSu1FRLLADgkEH5RRhjgwZFdhiArxpCl0JnZyc6OjogyzJ6enrqJUbT8NqVGfzSn5/Bq1eqF2V2ccraiMKpG/OW1pfDglr/zj7gd/4UuHewuu0RBFESpoqNcx5mjHkZYx41SeScG5WUCMANxT0pq2k+AE513ZoAwF8va01Dc0eSYls5T704ge+fm6pZe7/3gTtXVL7FZsMv3fM6dHe1gTGAMQYG5Pz+Z5/+45ULK/QCD75/5fUQBGEJeYNHjLuImNyLA+gxSWsoNm3ahO9///vYt28fuSMtwn3nTfjcx++pWv0tNoatAkWwEQRROU1z0KgZXV1dsNvtuHr1Krq7u1dc3yuTN/DUi9adHtBy/TIGAJyfuIG7PvYVy+qtBotLyoL2jrYWbHd01VkagiCI/NRcsWkHje7fvx/79++venuaO9IKxfbFsxJOXolZIJXCrvbX8NzdSiCDpjgaFQ4OvnkCG29rwdde/d+m9/OW5YWfrdDdgvXmuffSzGt4YnIM3a3r9Pq5+p8mj1bybpAlTxD1hg4aLZPNmzfj2WefRV9f34rdkTc7uiDu3WSRZMA2m7KVV+/6NqT+9pctq7caPHXlR7h/7FGEAYSfqbc01nE37qu3CASx5rH6oNGmdkUCwLp169DS0oJr165h48aNK6rro2/rw9E/eIdFkgG4Og58GdjQaQdaG/vM14lFGQCwrc2Be4Xb8uZjBSygQl8rCn3pKFyn+b0rizfwjl4nXtexRa+fGXJr10//1xMFpCIIYjXS9IoNWHZHrlSxEcBbhFvxtbuO1FsMy3gapNgIotlobDPBIjTFVmyuhyAIglj9rAnFtm7dOjDGcP369XqLQhAEQVSZNaHYGGO61UYQBEE0N2tCsQHkjiQIglgr1FyxaevYzpw5U9N2169fD845bty4UdN2CYIgiMLQOrYKYYxh06ZNmJiYwPr162vePkEQBGGO1evY1owrEgDNsxEEQawB1pRi27hxIxYWFjA9vbLzvgiCIIjGZU0pNoqOJAiCaH7WlGIDyB1JEATR7Kw5xdbd3Y35+XlwW7reohAEQRBVYM0pNi06ktsX6i0KQRAEUQXWnGIDFHdk2r5YbzEIgiCIKrBmFmgb6e7uBmxpckcSBEE0ALRA2wJsNhvYQit4G1ltzUrq0hXMz5K7mSBWA3TQqEWwBTt420y9xSCqwHP/+RP882NPlpZ5b3VlIQii9qxdxbbYArSnMTc3B3u7vd7iEABmb8zhq3/2DVxLrWw/z6uTy8cTbd3VWzDvK7i0orYIgmg81q5iAwPmWzA5OYn1G2nvyEbggvQafvbiq9ZUxoBf+h/vwK0DYsFsR4/+0Jr2CIJoGNasYgMANt+KiYkJ7Nqzq96iEAZ23LIN7/uNB1dUh729FV0bOi2SiCCI1cSaVmxYaMH1G9cxPz+Ptra2mjef5mnYALw8exlv+49frXn75fDS9dfwwA9uwy5sxDfG/r0qbVxVXZD2thZ0b9pQlTYIgmh+1rRiY2Do6enBxMQEtm/fXvP2fzY7gZ0AFvkSxmcae65n36WteODZ2wAAT+P5qrbVub6jqvUTBNHc1FyxaevY9u/fj/3799e6+Rw2bdqEy5cv10WxabSwFiR/7gt1a78UXn76Av736RFseV0vXA++oWrtMBvDPie5hgliLUHr2CzG0eNAUkpiYWEBdnt9oiMZALHrprq0XSrzbbMAAGHzBjgfvL3O0hAE0UzQQaMW09LSAofDgYmJiXqLQhAEQVjAmp5j09i0aRNeffVV3HRTba2m9BLHF597FJdu7IDte39b07bLZWmJth8jCGJ1kFexMca8AFLqpcg5DxarTC2jIQAIc87llQhYC3p7e/GTn/wEi4uLaG3Nr+vn0wu4sWjdbiWTqet4+eo+5WJm3rJ6q8nOW7bVWwSCIIiCmI7imlLjnEfVa5ExFuKc+/JVxBgbRpYiY4yFAOQt0yi0trZCEARMTk5i69atefM9+9xf4EtftS7IY/vVTgC/g3XtU/j1v3jUsnqrhc1mQ1sH7dJCEERjk8888XHOXdoF51xijPUXqWvAxKqTGWPCarDatJO1Cym2/rlr+PWr1yxrU57txQ+gRAJ2dLVbVi9BEMRaJkexMcYEAGb7EKUYY27OeTxPXaLJ/VWh1ADFHfniiy8Wdkfuegi4/z3WNSoDSAAtXeTeIwiCsAqzEVzE8tyaERnmCk/DDyDGGAtyzv2MMQ+AUHamhYUFzMw0wq76HAAwMzOLxbRyfE1nZycuXLiAzZs3mxfZ0g/c8evWifDaVQB/D9jIvVcvVvL3uDA/jw4A6XQacw3xN01kMzs7W28RiBKwup/MFJujQH4h3w3OeZwx5gIwps63DXLOE9n5zp8/j2PHjgFQ1i6o6xcagt7eXkxOTuZXbARBEIRlnD17FmfPnsXi4iLQiAu0GWMigIcB9AA4DMV683HOw8Z8e/fubZAF2gwA0NnZoR9bs2PHDrzyyitoa2tDS0tLPYUjaoTdbkdnZ2WbJTN1f1GbzVZxHURtoP5pTA4cOIADBw5gZmYGwWDwnFX1lrNAWyhy388593POZc65H4ALQIAx5q5Yuhpjt9uxceNGpFJmnliCIAhiNWCm2EZh7o50AMhxLQKAqrxixjTVDXkIwOAKZawpWnQkQRAEsTrJUWxqFGNKjY40IhSIiMxHAsBkZaLVh02bNiGVSiGdpp02CKKayLKMYDAIv9+fkS5JEvx+PxhjcLlcCAaDCAaD8Pl88Pl8iMfLG4bGx8fh8/n0esLhMBKJBBKJBKLRqN5eT08PBgczv4cnEgkMDQ2hp6dHl7Pc/NWikBxGwuEwGGP6u5MkCcFgED09Pfr7lSQpb/1m/TA0NIREwtTOaQw45zk/ALwAhg3XTgAhw7UIIAJF2WlpEZN6ho15OOc4cuQIbwQ+/bET/NiHH+Pzs/M59xKJBJ+YmMhJt1r2qVev8GMffoz/xSNftrReonRW0qcz3zvD+R3g/INvtk6gNUIsFuORSIR7vV7u9XpN84iiyAOBQE660+nkoVCopHb+7u/+jj/wwAN8amoqp31RFHkkEtHTAoEAFwTBtG4zOcrNXwrZcpZCIBDgAPKWDYVCXBnqM8n3fkvJl0wmOQCeTCbLlteM6elpDuAoN9FHlfyYzrFxJeBDZox51LB9N8/cdUQE4Eamy/IQYyzAGPOqP8MAonyVrGMzQu5IgqgubrcbHo8HgiAUzGd2//Tp0/D5fKZWhhFJkvDJT34SX/7yl3PqcbvdcLszp/8FQcCJEyfg8/kgy3LGPVHMXelUbv5iJBKJsq1RTQ6Px4NwOJxzL5FIoL+/2N4apbVhRBRFOJ1OBAKBFdddDfIGj3DOw5zzqPoTzLoX55z3cM4lQ5rMleCRsPoTNN5fTWzevBkTExPkjiSIBkQQBLjd7qKuPp/Phw984AN5lafPl7vbn8fjgdvtxtDQUEmylJu/Wvh8PoRCOcuGkUqlKlKyqx3a3d+E9vZ2dHV1QZZlOByFlvURRH3Z8Kt/X28RAADXvvihmrY3ODhoOpAbGR0dxXvf+968951Op+mgH4lEsGfPHkSjUXg8nqKylJu/GrjdbqRSKSQSCTidzqq3J0kSEokETpw4UfW2KqHm57FpJ2ifOXOm1k2XBbkjCaJxEQShoCtSluWSvpiaWXOCICAQCODQoUM5LsZ8dZSTv1p4vd4MZR+Px3PcrZUSi8UQjUYRDof1gJ+xsTHLlCidoF0jNm/ejLGxMdxyyy1gjNVbHIIwpdaWUqMgy3JBF5sgCBAEoeI1qV6vF5FIBIcOHUIkErE8fzXw+Xzo6+sraslWwsDAQFWtUatP0CZXZB46OjrQ0dEBWZbR09NTb3EIgjCQTCZ1a2FwcDDDeguFQnC73ejv78fTTz+dtw5ZljE6OprXqgmFQujr60M0Gi1JpnLzZ8/xac8Qi2UsCUYgECgaZAMsB3REo1G43e6K59bq6VK1ClJsBdDckaTYCKKxOHXqFE6fPg0gVxFohEIhuFwuHDt2zHRLrWKuOlEUdRdjKdF/5ebPtqwSiQQkSVqRUtGCSLQAm0ooFm26Gqj5HNtqYtOmTZiYmNDW5BEEUWPM5qyGhoZw+PDhovM7oijic5/7HD7ykY/k1KMN3kZLKJlM5tQxPDwMURRN5Sg3f7UwtuX1ehGPxzPSynHHSpKU94vCaoIstgJ0dXXBbrfjypUrJbkCCIIoDW3Nlua2CwaDcLvdcDqdkCRJ3xHk5MmTepnJyUnIsgyfz1eyNfL+978fd911F/x+P/r6+vTPsSiKumWk7bChrSHLtrYikUiGe7Hc/NVCkiQEAgGcOnUKk5OTuhxer1d/P/F4XJ/z03YMEUXR9P2OjIwgHo/r697M+mF4eLjqz2UJVq30LvVnNew8YmR8fJy/+OKLnHPaeaQZoZ1Hmpvp6Wk+PT1dbzFKYmxsLGMnlLVETXYeIZbR5tk4uSMJgqgiTqfTsvD8tQ6tYyvCunXr0NLSgmvXrtVbFIIgmpy1OuVB69jqAC3WJgiCqB5Wr2MjV2QJkGIjCIJYPZBiK4F169bR7iMEQRCrBFJsJcAYw+bNm+stBkEQBFECtI6tRLZu3YrnnnvO+vnBvcAELmXUu7CwAACw2+3WtkXk8Morr9RbBIIgLIYUW4msW7euJosuAWBmZgYATLcBIgiCIApDio0gKuFrj8P+j/+r3lIQBGECKTaCKJV0GvjMMPBUHHjhGbRo6eu76ykVQRBZ0AJtgiiVnzwLfOHPgRee0ZMWfvs48PuP1VEoglj9WL1Au+aKTVugvX///lo3TRArY1EJ6sHOPuCz/4iZJ17G4od/W7kmmppgMFhvEepCrZ6bFmgTRD2Yvg5cvqj8vrEHePB9gNBbV5FWM9oO+T09PRgcHMybLxwOgzEGn8+HeDwOSZIQDAbR09MDl8uFYDBoen6YVn9XVxfuu+8+BINBBINBfYf7RCJRsqzhcNj0jLREIoFgMIhoNIpoNIpgMKjv+F9NzN5BofSV4PF4VqdSt2o35VJ/Vtvu/vVgNe1Ivib4yQ84d3UoO/nfAc4f7uecUz9ZQSAQ4AD41NSU6f1QKMSVYSoTURR5IBAoWv+ePXv4sWPHMtKSySQHwJPJZNHyyWSSDw8Pm8rl8Xhy0oeHh0uSywryvQOn02kqczHyyT08PFzSu1oJtLs/QdSKl5PAH/068Mv9wNyskrZlO/Cej9RXriZCEAR4PB6Ew+Gce4lEQj8bbCV0d2cG94iiCKfTWfIp1z6fL0cuv9+PEydO5OQPBAIIhUI1sdwK0dtbvjdhZGTENP3w4cMlvatGgqIiCSIfX/0rIBJavv7lTwK/95f1k8cE9sQ76i0CAIC/44mKy/p8Pvh8vpxDLFOplCWKbSUkEgmIopiR5vf7cfDgwbw78Xs8Hvh8PtMTthsVv9+f954gCKbu3kaGFBtBZDP+ApD4D+Crn1Ou3/MR4OffrfwQluN2u5FKpZBIJOB0OqveniRJSCQSphZXdr5spQYop1IXsmAGBgb0eSnNuhMEQbf8YrEY+vr64PV69TKyLOP48eMYGBjAyMgIBgcHLT2bTZZlhMNh/XkkSdK/SGhzl9qcoSAIGbIBipVbq/6xAlJsBAEAM9PAP5wArqSAv/6jzHv9bwPe/cH6yFWElVhKjYTX60UoFEIopFjI8XgcbrcbsiyvuO4nn3wS27ZtQyqVgizLGBkZwdjYWNFBWpKkHKtMk8dM4WloZTRF4PP54Pf7IYoiRFFEf38/enp6MpSHy+XC2NiY7pp1uVw4ffp00fPZYrGYqdzZPPjggxn1RaNR+Hw+hEKhjPecbTVr9PX1QZIkUmz50Nax7d+/n0L+ifrzz18Axs4C//Kl5XB+jXf9MrB1B+D+pfrItobw+Xzo6+vTFZuVuFwu06jGYkiShL6+zKUcmmIo5JrT7mnKTyuTfS3LMgRBQDQahSAIGUqsv78fp06dyrGcshkcHMxRRidPnsy41rYCNNbv8XgwNDSEQCBQ0uGm1XZH0kGjBGEVC/PA0U8Ai4uZ6b9xFHhDP3D/Q3URay2iBXREo1G43e6CFlEhotFoRUosH2YWo9vtzhtoAQDJZBKiKGYojELPoykMY8DJ0NAQRFHE4OBghkLRLKxykCQJDocjJ11TVqVaYdU83dvqdWzkiiTWHt/4CnDyMWBuRlFqLS3AH4SA9k5g/y8A6zbUW8I1ieYaEwSh4vklK60Kh8NhGgASCATgcrl0iyubcDiMSCRScjuiKEKWZdNnNnM1losoikilUjnpsiybKtxsi7NQ3kbFsnB/xtjqeWpi7fFfTwD/433Ab/0i4P+QEhzyw1Hl3s4+4AMfBx76ECm1GmO0iLxeL+LxeEaa2YCcD0mSLFEEGprCycbpdCIUCuHQoUM593w+H7xeb46SKvQcHo8nx9UnSdKKlgxMTk5m1C/Lckb9mmVrdJNqz2oWNKNZoauFvBYbY8wLQOsNkXNebPl5iDEWADDKOZctko8gKuebJ4En/1n5/d++kns/+BVgy83AvjtrKxcBSZIQCARw6tQpTE5O6lGGRqUQj8d1y0fbMUQURUSjUUiSlDGXNDIygng8ri8PkCQJ0WgU4+PjiEajsNvteQMj8uF0OvNagF6vF/39/fD7/RgYGNDbHBoaylBqiUQCgUAAkiQhHA7j4MGDOH78OAAlxF4LKjl9+rQeFQmgoNWqPZv2DrQoRmN6PB5HMBjUn3lsbEyvXwuiMVqVTqcToiiarifU2lwtgSMAwDjnuYmqUuOcR9VrEYCfc+7LybxcZgqAYHJL5pz3aBdHjx7ljTDHFvhvf4PF+UUMP/5x2Nsb60BPOo/NIt62FUi9lpn2u38GvG4fsEME9t2xouqpnxqflfaRz+crOcCiWZFlGX6/vyqBPRozMzPo6ur6Q875USvqy2ex+TjnLu2Ccy4xxoqtlPRzzjPUvaoQhZWJSBAVsjCv/PsHIaBrPbB9F3D3W+srE7Gq8Pv9OH78+KrbecNKwuFwwQXcjUiOYmOMCQDMnKkpxpibc57j+FXLnDIp49SsPoKoCpwvRzXOzwJ/GwTkCeX6mqz8+44hoLvHtDhBFEIURfT29uZdrN3saGv5Vtuzm1lsIpbn1ozIMFd4MJtTY4x5sy04AFhYWNDdA/VFccHOzMxiMb1YJG9tmZ2drbcIqwPO0fab70HLyLfzZ2nvwGyaA1X4m6N+anys6KPf+q3fwmc+8xk8+uijFki0uvjKV76CRx99tOpjttWfJTPFlrvgYRmhlEpVF+So2b3z58/j2LFjAJS1C+r6BYKoCE2p8RblT5ktLSJ9mxOLv/CrAID06+8COmgOjFgZa1GpAdV/7rNnz+Ls2bNYVLwuu62qt1rr2Dz5oij37t3bIAu0GQCgs7Oj4YJHNCgooQiGwCf2/eVdQ2wA2mooBvVT40N91JgcOHAABw4cwMzMDILB4Dmr6i1HsQmlZGKMOQHQCYzEypmfU3bXT11eTgsfq588BEGsCswU2yjM3ZEOAKUcO+sDMLYSoYg1ijwJvHZh+fr0PwJ/daR4Odr6iiAIAzmKjXMuM8ZSjDEhKyhEMIuINMENwLrl/8TaIHUZOLALmM0zSf1Jw477zp8D3vz22shFEMSqI58rMgDACyAI6O5FXampwSEBAIdMIiJFKBGUBFE6l15WlFpbu7KAWqOtHXjk08C91p1NRRBEc2Oq2DjnYcaYlzGmbZMtZu06IkKxzBzIVWKS+kMQ5dN3O3CqFI83QRCEOXmDR8zWoBnuxQGYrnjlnPeZpRNrlGtXgPRSZhrnwEs/zYhqxPiPaysXQRBNCx00SqyM8ReUIA+ezr134o+Vk6nLgVl24ARB1A3jBsRriUqfmw4aJRqLP/4N4LtPFs+3McvAvzoFCL3A6/YupzEb8MuftFY+ouHRdvrv6+uDIAhwOBz6Fk6pVAputxuSJCEUCiEYDMLpdOLhhx8GoBzPIkkSfD6fvhu+Me9dd90Fj8cDu92un62WvQO/JElwuVw4ePAg+vr6MDk5iXA4DLfbjYGBAUxOTiIajcLv9xc90RpQ9lY0O+w0kUggHo/rz6btmF/p2XOlou36f/z4cYiiiIcffhjDw8N501eCx+OpSLlZfdAoOOc1/Tly5AhvBD79sRP82Icf4/Oz8/UWJYfp6Wk+PT1dbzFK4+F+zu8A55/6KOefPZz78/d/yfnSUr2lrAqrqp8alEgkwt1uN5+amspIj8ViXBRFHolEMtJFUeShUCgjbWpqigPgsVgsJ++xY8dy+sjpdGbUEYvFctrJri+ZTPJAIFD0eZLJJB8eHs5JD4VC3OPx5KQPDw+XVK8ViKJo2pbT6TSVuRj55B4eHubJZLKsuqanpzmAo9wiPUMnaBOFmb6Re/SLkZ+NK/9+8JPAHQO1kYloCiRJwqFDhzA+Pp5zLIzb7Ta1ZMyOj9HOLguFQjlluru7c/KfPn0aPT09cLvd+gGbZhaWEVEUSzq6JhQKwefLPN0rkUjA7/djfHw8J79mqdbCcitEb2/5e2qMjIyYph8+fLjqx9wUgxQbkZ8b14B37lEWThONyV+xekug8Bu55zoWw+fz4eDBg3kVxtDQkOkJ1maMjo7i8OHDJeXVFKHf70ckEil55/pS8iUSiZx8fr+/4HN6PB74fD7dVboaKHSMTfZp4PWAFNta5NIrwP/90eIK69wLwJy66/bNu/Pn29FHp1ATZROPxwt+q3e73UUVmzY/d/jw4bLmdQYHB/W2Sz0ZuphFle9om3g8XvA8t4GBAQSDyta6mnUnCIJu+cViMfT19WXM78myrJ+IPTIygsHBQUstPlmWEQ6HM+YDtfcbj8chSRISiQSCwaB+grcRURSRSCTqduo2Kba1yHeeKC3gQ+P+h4DP/Wv15CEqpwJLqRHQFJbDUegwEXPX49jYGKLR5WMetaCTcqiGVaGdXWZEe85C1p5WRlMEPp8Pfr8foihCFEX09/ejp6cnQ3m4XC6MjY1BEAR4PB64XC6cPn266HuIxXI3hTJ7Dw8++GBGfdFoFD6fT3f3as+V78tEX1+fHhxTD0ixrXbiXwM+9Sv5t6IyQ1s/9vb3Ar9xtHBexgDx9orFIwgzBEGAIAhIpXKPfgyHM5fQ9vf3ZwyQLpcrZ05scHAQY2NjJc/ryLJs+eGZkiShry9zGa+mGAopUe2eJo9WJvtalmUIgoBoNKq/P43+/n6cOnWqaNTm4OBgjjI6efJkxrX2pcFYv8fjwdDQEAKBQElfIurtjiTFttr57pPlrxUDAHsbMOgBbr3LcpEIohT6+/sRi8VyBmOv1wtZltHT04NAIFDSt36fz4ehoaGSFVsymayKNWHmOnW73XkDLTRZsoNTCildTWHE48tb9w4NDUEURQwODmYoFLOAmmJIkmRqSWvKqtT3Vq4VbSW0QLtZ+L/+J/DB3yyvjI0WQxP1IxQKweVymc5NaRZJqVaVmeVXiFOnTuH06dNllSmGw+EwDQAJBAJwuVy6xZVNOBxGJBIpuR0tktNMYZm5GstFFEXT95nPys22OAvlzYfVC7RrPrJpC7RJqVkMsymKqpwfgqgjoijixIkTptGPiYT5fqH5gklCoZCpG+7KlSs5aUNDQzh8+LDlFpumcLJxOp0IhUI4dOhQzj2fzwev15ujpAopao/Hk+PqkyQpw4Irl8nJ5UAyj8cDWZYz6o9Go3q7QOazmn0x0azQUrF6gTa5IutBOg0E/w8l6tCEtiV1b8WWluJ1/ee3LBSMIGqLx+OB0+mE3+/PCAIRRRHj4+P64KrtkiFJEiKRiD6oTk5OIpFIwO1265GHxrzafJHdbsfk5CRkWc7YpcSIFgmoWV2BQACJRAIej6ekQdrpdOadV/J6vejv74ff78fAwIAuZ/YuKIlEAoFAAJIkIRwO4+DBgzh+/DgAJcReCyo5ffq0HhUJLC9hMMP4Pk6ePKlHMRrT4/F4xo4hY2Njev2pVAqyLGdYlU6nE6Io5syHGtusV+AIADDOaxtVdfToUd4IW2oFfi2ExUWO4bvOwW6rcWTZ+PPAmX+xts7Pfg148P3W1kkUZGZGCdjp7OyssyREPmrdRz6fr+QAi2ZFluWyF2jPzMygq6vrDznnR62QYe1abPNzgK0N+OJnAL5QPzke+7ecpLn5OQBAe1t7aXVs7AHufLOVUhEEUQF+vx/Hjx8vuG6t2QmHwwUXcNeCtavYNHy/D3S01b5dxoD9vwiIt+bcSqvfMkGWAEGsKkRRRG9vb97F2s2Otpav3s9Oiu3Dvw0IG+stBUEQTcLw8PCaPbYmGo02xHNTaBxBEITFNMLgXg8a5blrrti0dWxnzpypddMEQRBEA7L6Dxq9eTuODv+ucjF9vdbNEwRBEA3G6l/HduI48P8dr3mzOdz5P+stAUEQBFEFaq/Y7Hagsw5RiPno6Ki3BARBEISF1F6xHfoU0AALtPHf/gaYX1TC7gmCIIimgaIiCYIgiKaCFBtBEATRVJBiIwiCKEIwGKy3CKueWr5DUmwEQdQcSZLg9/vR09ODwcHBvPnC4TAYY/D5fIjH45AkCcFgED09PXC5XAgGg6Y76mv1d3V14b777kMwGEQwGNQPJM13LE4+GbQTu7V6GWN6+8a6e3p69BMFyiUej8PlcmFoaKii8tnIsoyhoSGwAnEE+fL4fD74fD5L5NDweDy1U26c85r+fPSjH+VHjhzh3/72t3k9+fTHTvBjH36Mz8/O11UOM6anp/n09HS9xSCKQP20cgKBAAfAp6amTO+HQiGuDFOZiKLIA4FA0fr37NnDjx07lpGWTCY5AJ5MJouWTyaTfHh4uOT2x8bGSpIrH6FQiHs8norLm2H2/orlicViPBaLWSoH55wPDw+bvvdvfvObHMDnuUV6hg4aJQiibgiCAI/HY3quVyKRQH9//4rb6O7uzrgWRRFOp7OkHfhDoVBZlovT6VzRkTUOh6Pislbidrvznu+2Eg4fPmz63lf/Am2CIKzjzgZZrvKDys801Nxe2fsMplIpSxTbSkgkEiXtVK+dMA2g7jI3ErIsZyj67JO/qwUpNoIg6orb7UYqlUIikajJqcuSJCGRSODEiRNF85Wi1GRZxsmTJ3XFpj1DIpGA3++HIAi61ZdIJPTTrhOJBFKpFMbGxjIO5ZRlWZ+nS6VSAJQTuI33tdOtR0ZGMDg4mGFdaaeROxyOvNZjoTya3AAQi8VMnyMWi6Gvry9DLkmSEAqFdLn6+vogiiIkScrIJ4pi1fs6r2JjjHkBpDRZOOclzfoxxoYByFpZznllM6kEQRRnBZZSI+H1ehEKhfQBPh6Pw+12Q5blFdf95JNPYtu2bUilUpBlGSMjIxgbGys6sGpni+UjFosBACYnJxGPx3PuO51O+Hw++P1+iKIIURTR39+Pnp4exGIxXREODg5mWHySJOm/A4pFGw6HdeXgcrkwNjamu3FdLhdOnz4NQRAwODiIQCCgP5uZdVQsj9PphN/v112GhZ7DqLAGBwcRi8UgiiIEQYDf78fY2FhO+319fZAkqfaKTVNqmlJijImMsRDnvKCzmTEWAzDEOZfV6ynGWFy7JgiCMMPn86Gvry/DcrEKl8uVoShKRZIk9PX15b0/ODiou097e3tN82iKUbP8sq+1NM0yA5Az4A8NDWFoaAherxfRaBSCIGQo3P7+fpw6dQr9/f05CiPb4kwkEkXzlPMcRldjKpXS5whFUcz7paQW7sh8wSM+o6XFOZcAFHQcq5ZaJEuJuUipEQRRDC2gIxqNQpblik9grjTUPh+lWoxGxZktg9mzGINEigWMGJWEphDi8bj+MzQ0BLfbjdHR0aKBK6XkKSRHIbxerx4EFAqFCgbnrCTAphRyLDbGmADA7AlSjDE35zzX5lY4DGCPMUFViBksLCxgZmamAlGtRnHhzMzMYjG9WGdZMpmdna23CEQJUD+tnPn5eX08+NjHPobHHnsMnZ2deOCBBzAzM6Pfyx4zOOemY8kLL7yQkcY5x+LiYkVjzvr163Pqy9f+TTfdpP9uLDM3N4d0Op1Tx8zMDNrb2wEAi4uL+nuYn5/H0tJSRv5Lly5hz549mJmZwY4dOzA1NYW3vvWtOTLdfPPNkCTJVF4trZQ8ZnKX8hw7d+7EAw88gK9//et45JFHIAiCaTuXL1/Wn0fD6s+SmcUmYnluzYgMc4WnKUMBgIMx5mGMuRljw2p6BufPn8exY8dw7Ngx7XA5giDWKFeuXNF///jHP44nn3wyI21qaqrkusbHx/Hkk09aJtvu3bvLnuOTZTlnXsnoZjQj+xnHx8czrh9//HE8+uijAID3v//96O7uzsijPfcDDzyA3bt34+mnn9bvGX8HUFKefBR7jqeffho9PT144IEHClpkkiRh9+7dAJQDRo8dO4ZPf/rTQJUPGi1kFwt50vuhKD7BMC83CiACIGNbgb179+JoI+zuDyVMurOzA/Z2e51lMaezs7PeIhAlQP1UPpIkIRAI4NSpU7h69arutvJ6vXj3u9+Nzs5OxONxRCIRAMAjjzyCoaEhiKKIaDSK8fFxfO1rX4Pdrnx2R0ZGEI/H0d/fj87OTkiShGg0inPnzuGf/umf0NnZmbOcoBj33Xcfjhw5ktG/WuRfdvsAkEwmcerUKRw8eBCdnZ1IJBL47Gc/i3PnzuFLX/oSDh48iOPHlbMojx49Cr/fj3g8jmeeeQbnz5/Hrbfeii1btuDxxx/H17/+db29d73rXRmuzm9/+9t6VCSguPUeeuihjHsXLlzIUC6PPPIIAoEABEEomkeSJHz+859HIpHAl770JfT39xd9DlEUcc899+D222/X6xNFET6fLyPABABeeukl3HfffQCAAwcO4MCBA5iZmUEwGDxXVgcVInvFNgA3gKRJegTAsNkqb7UMh6LYjOljAJzGtCNHjqxo5bpV0M4jxEqhfmp8VtpHXq83764oxDJmO65MTU1xp9PJx8bGMtK8Xm9O+enpaQ7gKK/DziNCgXtaaL9skm798nWCIIga4Pf7deuEyM/o6GhOcIkgCDmL1cPhsL5GrpqYuSJHYe6OdADIt3NoodhNuUyZCIIgGgJRFNHb21vyYu21ihYRGQwGM5YCDA0NZayXEwShJu8xR7FxzmXGWIoxJmRZYALPExGplkkwxkSeGQkpQlGUBEEQq5Lh4WEEg8Gy5+jWGtlzadlEo9GavcN8rsgAAF1KxpgTQNxwLTLGIllRj8cB+LPKSJzz0s+HIAiCaEBIqa2cWr5D051HOOdhxpiXMaaF4og8c9cREcrcmQOqq5FzHmWMaQu1AaCXc57/oCWCIAiCqAJ594rknOeeI7F8Lw6gxySd9oUkCIIg6krNz2M7d+4cjh49ijNnztS6aYIgCKIBUTfr2G1VfTU/tkY7aJQgCIIgAOsPGq25xUYQBEEQ1YQUG0EQBNFUkGIjCIIgmgpSbARBEE1OMBistwg1laHmwSMEQRCSJMHlcuHgwYPo6+vD5OQkwuEw3G43BgYGMDk5iWg0Cr/fX3RHi2oRjUYxMjKin0SwWrfUCofDpieIa8+lnRJu3NtRO2U7Go3i+PHjEEURDz/8MDwej+l7kGUZx48f108S1+pKpVJwu5Xtgj0eT+12cLFqN+VSf2h3/+LQrvGrA+qnyonFYjwSiWSkAeCxWEy/TiaTOTvGl0ulfTQ1NcUFQeCccx6JRHgymVyRHPUimUzy4eHhnPRIJMLdbnfOyQWxWIyLopjRN6IoFu0Hj8eTUZe2s392Hw8PD5u+y3ru7k8QBGEJsiybWhFGRFEseGBlNRkdHdWtl3xWymogFArB5/NlpEmShEOHDiESieS8X7fbrVtY5ZBIJDLqEgRBP2PPyOHDh03Trabmrkhtgfb+/fuxf//+WjdPEE3FH3/kr+stAgDg977862XlL1VRrFaF0igkEomcd+jz+XDw4MG8Xxp8Ph8kqdCBLblIkoREIqHv5A8oSjKRyNwqWBAE07ppgTZBEKse4wBYDJfLhf7+fgwODuLkyZP6XE8ikUAqlYIsyxgZGcHg4KBubSQSCfj9fmzYsAEf//jH0d7ejlgshr6+vow5u2AwCKfTCVmWEYvF4Pf7IcsyIpEIJElCMBiE2+3W84TDYV1RSJKkzxfF43H4/f4cOUVRhN/vhyAIuuWkWTfawJ9KpTA2NoZQKKTLpc1ZDQwMZDxbvnbyzaGZfTEYHR3F0NBQwb4p9wvF8PAwXC4XvF6vLqsgCKb9LIpijhK0eoE2zbHRHBtRIdRP1oKsOTaNUCjERVHkU1NTfGxsTD+ROXsOR5sT04hEInzPnj38hz/8IedcmfdRhrzleo3lI5GIXncsFuNutzujPqfTmTGPFIlEMk6DzidnJBLhoijqc0uaHMZndbvdOfNaxraMbedrJ5tYLJYzv6a1nT33VYhS5tg0uZxOJwfAAZielM0554FAIKd9mmMjCGJN4XAo5x5rFoD2TT8SieRYKrIs679rrrY9e/ZkXGt5NGsqHA5DkiR4PJ68lmQ0Gs2oA1Dm3sLhsF5fPjm1MpoVlH2tpaVSKb0tQRAy2urv78epU6cKtpONJEl6xKOxHWNbVuL1ejE2NgbOOSKRCMLhMMLh3L3087kjrYQUG0EQDY/Z4O1wOBAMBhEOhxGPK8dFZg/YmlIzw+12IxQKIRaLweVyweVyZShGI5Ik6QrFSPYgnU/JmLn2jPUZf9fqi8fj+s/Q0FBGUEeprlyz5+nv78fY2FjBMtr7LISm7GVZzlFUHo8HoVAIkUjEtGy1g4JIsREEsSpxuVxwu93wer0Zg34+5ZRNPB6H2+1GJBLB1NQU+vv7TS0MQFFMZlaOLMuWB7iIoghZlvUIRe2n3HYcDgcmJydz0kOhEE6dOpX3PcXjcT0itBCaMkulUqaKsL+/31SBybJs+iXBSkixEQSx6tCCLjTLxThIGwfZQi63RCKRkTc7LN6Ix+PJsUyi0Sg8Hk9J1kcx15/xvlansS1JkkqyooxoCtIs/cSJExgaGsq5r7VZ7JkkSUIsFtOv/X5/jtV28uRJ03eaTCarHu1KO48QBFE3tEjDZDIJAAgEAkgkEvrasXg8jlAopEcoer1efW7p4MGDelQjAJw4cQKBQAA+nw+JRAKBQADnzp3D448/jo985CM4fvw4AGUQ1iIVJUnSXWpalKNWdnR0NKPNsbExPVJRi8bUXG355NTqkiQJ4XAYBw8ezJEjHo8jkUjoUYxutxunT5/W2wKgR1Hma8cMp9OZdy5Lm0/0+/3o6+vLmPfT5i21dyNJEk6ePKmXHRkZybDqHA6H3m/xeByyLGNychIDAwOma+K0XU2qCeOcV7WBbD7yoV/he/fsw7333ou3vOUtNW3byF8+8ncAgOHHPw57u71ucpgxMzMDAOjs7KyzJEQhqJ8an7XeRz6fD4FAoG4L3bORZRl+vz9jaQMAfOtb38I73/nOL3DOf82KdmpusV14bgq32bZg9HwSo19N1rp5giCINYPf78fx48drsttHKYTDYfj9/px0q9ex1VyxtXe2YWPv+lo3a8qu27Y3nLVGEARhFaIoore3N+9i7VoiSRIEQaiJHDVXbPe86434raMfqXWzBEEQa5Lh4eHa7apfgGg0WjMZKCqSIAiiyam3Uqu1DKTYCIIgiKaCFBtBEATRVJBiIwiCIJoKUmwEQRBEU1FzxaYdNHrmzJlaN00QBEE0IHTQKEEQBNFUWL1Am1yRBEEQRFOR12JjjHkBaFtOi5zzYKGKGGMeAA8DOA5ABuABIHPOzc+BIAiCIIgqYGqxaUqNcx7lnEcBRBljIbO8WTgBjKk/vaTUCIIgiFqTzxXpUxUaAIBzLgEoevIc57yPc8445z2c89ydLomSUSdTiQaH+qnxoT5aNey2qqIcxcYYEwCY7VKZYozlHq5DVAX6MK4OqJ8aH+qjVcNuqyoym2MTsTy3ZkSGucLTURWfoOZ1ms3LjY+P62ckrZTvfOc7uPfee6tSppR8hfLku2eWnp02OzsLu91u2XuqhErerZV1WdVPlfRRvnvN3E/V7KNS8lr1WcpOb6Y+qrSu1TLmWUnOQaOqcgpxzvuy0iMARvIFkTDGnFCCRSTDdYBzPpiV7zsA5tTLc1hZiOfuCsqXWqaUfIXy5Ltnll5qWi2xsv1K6iq1TLF8he6Xe6/UtFpiVfuV1FNOmWJ5C93Pd6/U9GJtVxsr26+krlLLlJKvUJ5898zStbTdWLbU2jnnlnwDsGwdG+c8kX3NGOtnjDmN96wSnFBQg3oiACQoc6M0t9nAMMZEAG4KrGo81MhuCYpnqmgkOFEfVONLBNAHIGn2WSpHsQkVyKAFnSSKZSQqxgFFsY0CGKqzLERx/ADo6PgGQ40tCKieqgRjLMkYi2oeKKIxUL8YQlNmjLEpxthotmFlFhU5CmWwzMaBPAqKMSYyxqZWJjJRISfVKNRBzrlcb2GI/Kju+bF6y0HkwjmXs6dfSKk1JE4APsN1HCYR+zkWG+dcZoylGGNC1kApcM7jBRo8bpImqg0T1UM0BO3AuEyDaDgcUAKzhDrLQRRAXcdLLv0GhHMeZYwZdYoIxTOYQT5XZACAF0AQ0L9p6pWp5mAAwCH1m47EGJONFaj+6lNr+VuP6t44CGCQc57jJix3d5c8hLUvIIyxGGMsTpZbedSinxhjbs55XP1cEGVSo8+SNn9jFhVOlEAt+skw3olQNhLJMZ5MFRvnPMwY8xo+hCLn3Gj+iQDcUL6BysYy6n1BTTOWWVOoXwa0pRM5yySMu7uo1yJjLKS9M/Xd51teEdd8yllKTILSL2S1lUgt+kn9sNNgWSG1+iwBgDZIMsbGGGPkASmDWvaTih954gpywv0Ja1E7+wTn3JWVPlZKWpG63QCGDH8YAeSJEiIKU+V+Gsayu2QQyhfCUBHXPpFFlfvIC8Bl+CxFAEgUZVw+1ewnQ7lhGLxV2dDu/nXAwt1dJADGPTzdAE6tQDTCgFX9xDkPGvZdHYOyHpSUmgVY/FmKGK5FACdXIBphwModrdT8UYNLMqd8zc9jIwCsYHcXI+rcpkf1NYsA/DS/ZimW9JOG+k12EICgzoXSMpiVY9VnKa5+ljR3WIj6x1Is6Sf1MxSBohC16P0Hs/ORYqsPZsspNIRyKqI5gKpiWT8B+iYGtNbQWuiztDqwpJ/Uz1BPsXzkiiQIgiCaClJsjYVQbwGIkhDqLQBRFKHeAhAlIVSjUlJs9aHs3V2IukD91PhQH60OatpPpNjqgBrgkVIjhYwU292FqCHUT40P9dHqoNb9RIqt+uSbNNV2dwGQu7sLUXOonxof6qPVQd37iRZoVwk1BN8DJbzbDWV7sozF01ZtA0RUDvVT40N9tDpopH4ixUYQBEE0FeSKJAiCIJoKUmwEQRBEU0GKjSAIgmgqSLERBEEQTQUpNoIgCKKpIMVGEARBNBWk2AiCIIimgo6tISxFPcXbDcAJIAzlvCUNJ4B+KCcTFzw1V13sGQLg5pyz6kib0V4AyuJSEZlyC1B2Ujhp5bEm2mLWUheolpt/pRR4H4DyTujsP6JhoQXahOWouwsEOOc55yapA3SMc95XYl28FopNbauQ3DEACc6538K2/NnvgTEmcs6lUvNXk3zvQ90K6TSABys9jDPfcxKEFZArkqgp6mDWyAc6mp3yCwB+AMPqoL5iOOfhPErKU2b+apPzPlRlFoai3CrF9DkJwgpIsRH1IGayy3dDY7BM3FVuarDK9VvFCABBtcArYbU8J7EKIcVG1ISsATDf2UwNi0ERV819xhjzoPqK0ypEQLfAy2KVPSexCqHgEaJWOKEqBTXoQFYHOEBRcn2lzF+pZWT1UoDyzV8PZMjaPXwAQMiiuZyDUIJedDcqY8wNZYBPqc8gGc+WyiermjcjMEbNO6D+HlDLJDnnYbNAGsbYMACfWtchTS7D/JekpiesfieqkvcBGMpzP2+/FnpOQ55q9SGxVuCc0w/9WPoD5cylKcO1AGAsK48byrEV2rUHSlBJdl08q4w7634IymGFADAMYDjrflK7X6Lcyaw0QU2PmcgbyMo7DMBbiqzZz1YoLd89tY2kSb5AlkwVvROtH7VnUZ95GMq5WmKeMmX3q8k7rLgP6Yd+OOdksRFVQzB8IxehWGxGtG/7PgDgnEcZY5EidWp1GA8njAC6FRHguRGUcSjWVhilIaoWg0YKQJwbLAqVEwD2GBM450HG2BRj7FQhWa2Ccx5njDkYY06eGZ2YBCx7JymuWqFqfW6oFlceKulXWCgvQZBiI6qGzDNdUMNZ9wNQrKGMMowxgedfHxUFMMYYG4SiJOKGQdejls+eu3EAKLhmzkTuggOo2kYqj5wSlME/r6wWE4aiRHwG2U6p99yw5p0A0F3IUcaYDGAMQM6yCFTWrxqWykusXUixEbUiY70T51xijDlVhSdDUQhCoQrUMnsAHIYykIcYY2HOuTbXlDJRHtVQJiIyFyzn3FctlXyyWkkIipLR6hUN76Aq70S1FAXGmDu77kr61UAt+5BoYkixETUhe7BSB75BzvmgIU0uVIdhIPWr1wKAiGqtSahdpGWxwVoqJCsvcQcTNRBEKmTpqIpkVH0HcWRGbVb7nTiRpXQq7FctsKiWfUg0MRTuT9SLAJatDA0BgEP9xi+YlBk0LhtQB3w/gAGDSzJnXZVVi6oNjKpyZsioXmuDfV5Zy2hHLMF9ByhWmw9KsIquaKr8TmQAZgvGK+lXkXMu17gPiSaGFBtRcwyDW8qQpn1rFwA4Cgzo2UsCRCgRiwBwCMrAamzLjcJuw7IxKKnDWbcOI3MPxUKy5kMqd9GzagH2w9zaWek7yWdBxdU2tTo9ZfZrvuesSR8SzQ3tFUlYiuqKehjLmyAnucnGvarrbBDKQC9BGbhENW0EypycH0rIeRiKVdIPxVrS5rgEQB/YtXrdhjpkKK68omugTOQO8SL7IKptaQO3Nj+krSfz5pNVHdCNz2Zch+dU5RhRZU8Uym+QJQQlotBsn8my34ka0aopHgnKJtAJw30BSmRoTH2usJpesF955nq7jOdcibwEYYQUG0EQBNFUkCuSIAiCaCpIsREEQRBNBSk2giAIoqkgxUYQBEE0FaTYCIIgiKbi/wddo7IwDiC7TgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 504x311.489 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import scienceplots # used by plt.style\n",
    "\n",
    "from src.plots import set_size, plot_roc_curve\n",
    "\n",
    "import scienceplots\n",
    "plt.style.use(['science', 'no-latex'])\n",
    "plt.rc('text', usetex=True)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=set_size())\n",
    "\n",
    "# make axins to show xlim 3e-6, 2e-5 and ylim 0.94, 1.02\n",
    "axin = ax.inset_axes([0.12, 0.45, 0.3, 0.33])\n",
    "\n",
    "to_skip = [x for x in y_preds.keys() if 'tabular' in x]\n",
    "to_keep = {\n",
    "    # \"_tabular_log_reg_onehot\": 'LogR (One-Hot)',\n",
    "    'cnn': '1D-CNN + MLP',\n",
    "    '_tabular_mlp_onehot': 'MLP (One-Hot)',\n",
    "    '_tabular_xgb_onehot': 'GBDT (One-Hot)',\n",
    "    'mlp_seq': 'MLP (Embedding)',\n",
    "    # 'neurlux': '1D-CNN + LSTM\\n+ Attention + MLP',\n",
    "    'cls_transformer': 'Transformer (CLS)',\n",
    "    # 'mean_transformer': 'Transformer\\n(Mean Pooling)',\n",
    "    #'_tabular_mlp_minhash': 'MLP (Minhash)',\n",
    "    # 'lstm': 'LSTM + MLP',\n",
    "    # 'cnn_lstm': '1D-CNN + LSTM\\n+ MLP',\n",
    "    #'attpool_transformer': 'Transformer\\n(Attent. Pooling)',\n",
    "}\n",
    "for name in to_keep.keys():\n",
    "    y_pred_proba = y_preds[name]\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "    name = to_keep[name]\n",
    "    plot_roc_curve(fpr, tpr, None, model_name=name, ax=ax, semilogx=True, xlim=[2e-6,1e-2], ylim=[0.5,1.05])\n",
    "    plot_roc_curve(fpr, tpr, None, model_name='', ax=axin, semilogx=True, xlim=None, ylim=None)\n",
    "\n",
    "# Create a mapping from labels to handles\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "label_to_handle = {label: handle for handle, label in zip(handles, labels)}\n",
    "\n",
    "# labels for ROC curve\n",
    "ax.set_xlabel(\"False Positive Rate\", fontsize=20)\n",
    "#ax.set_ylabel(\"True Positive Rate\", fontsize=18)\n",
    "ax.set_title(\"Test set ROC curves\", fontsize=18)\n",
    "\n",
    "# ticklbel fontsizes to 18 as well\n",
    "ax.tick_params(axis='both', which='major', labelsize=18)\n",
    "\n",
    "# Order the handles based on the order of labels in to_keep.values()\n",
    "new_handles = [label_to_handle[label] for label in to_keep.values()]\n",
    "new_labels = list(to_keep.values())\n",
    "ax.grid(linewidth=0.2)\n",
    "ax.legend(new_handles, new_labels, ncol=1, fontsize=16, bbox_to_anchor=(1.03, 0), loc='lower right')\n",
    "\n",
    "axin.set_xlim([3e-6, 2e-5])\n",
    "axin.set_ylim([0.95, 1.01])\n",
    "ax.indicate_inset_zoom(axin)\n",
    "\n",
    "axin.set_yticks([])\n",
    "axin.set_xticklabels([])\n",
    "axin.set_yticklabels([])\n",
    "axin.set_xticks([], minor=True)\n",
    "axin.xaxis.set_ticks_position('none') \n",
    "\n",
    "# save as pdf in \"/img\"\n",
    "fig.savefig(f\"img/roc_ablation_models.pdf\", bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>TPR at FPR=10^-7</th>\n",
       "      <th>TPR at FPR=10^-6</th>\n",
       "      <th>TPR at FPR=10^-5</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>_tabular_mlp_minhash</td>\n",
       "      <td>0.696005</td>\n",
       "      <td>0.696005</td>\n",
       "      <td>0.8573</td>\n",
       "      <td>0.983713</td>\n",
       "      <td>0.983972</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.968034</td>\n",
       "      <td>0.999908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>_tabular_rf_minhash</td>\n",
       "      <td>0.612703</td>\n",
       "      <td>0.612703</td>\n",
       "      <td>0.638888</td>\n",
       "      <td>0.990571</td>\n",
       "      <td>0.990481</td>\n",
       "      <td>0.999948</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.981318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>_tabular_xgb_minhash</td>\n",
       "      <td>0.247022</td>\n",
       "      <td>0.247022</td>\n",
       "      <td>0.418617</td>\n",
       "      <td>0.999404</td>\n",
       "      <td>0.999404</td>\n",
       "      <td>0.999944</td>\n",
       "      <td>0.998928</td>\n",
       "      <td>0.999881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>_tabular_log_reg_minhash</td>\n",
       "      <td>0.417413</td>\n",
       "      <td>0.417413</td>\n",
       "      <td>0.629707</td>\n",
       "      <td>0.945132</td>\n",
       "      <td>0.947946</td>\n",
       "      <td>0.999818</td>\n",
       "      <td>0.896669</td>\n",
       "      <td>0.999133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>_tabular_mlp_onehot</td>\n",
       "      <td>0.969684</td>\n",
       "      <td>0.969684</td>\n",
       "      <td>0.992317</td>\n",
       "      <td>0.997217</td>\n",
       "      <td>0.997224</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.994525</td>\n",
       "      <td>0.999923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>_tabular_rf_onehot</td>\n",
       "      <td>0.643993</td>\n",
       "      <td>0.643993</td>\n",
       "      <td>0.840696</td>\n",
       "      <td>0.984538</td>\n",
       "      <td>0.984296</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.969547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>_tabular_xgb_onehot</td>\n",
       "      <td>0.969335</td>\n",
       "      <td>0.969335</td>\n",
       "      <td>0.999426</td>\n",
       "      <td>0.99984</td>\n",
       "      <td>0.99984</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999792</td>\n",
       "      <td>0.999889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>_tabular_log_reg_onehot</td>\n",
       "      <td>0.991381</td>\n",
       "      <td>0.991381</td>\n",
       "      <td>0.997805</td>\n",
       "      <td>0.999374</td>\n",
       "      <td>0.999375</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998843</td>\n",
       "      <td>0.999906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>mlp_seq</td>\n",
       "      <td>0.601787</td>\n",
       "      <td>0.601787</td>\n",
       "      <td>0.640653</td>\n",
       "      <td>0.950122</td>\n",
       "      <td>0.952488</td>\n",
       "      <td>0.999958</td>\n",
       "      <td>0.90508</td>\n",
       "      <td>0.999883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>attpool_transformer</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.975607</td>\n",
       "      <td>0.999875</td>\n",
       "      <td>0.951344</td>\n",
       "      <td>0.999861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>cls_transformer</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.97399</td>\n",
       "      <td>0.996579</td>\n",
       "      <td>0.99659</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.993308</td>\n",
       "      <td>0.999872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>mean_transformer</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.885327</td>\n",
       "      <td>0.98777</td>\n",
       "      <td>0.987916</td>\n",
       "      <td>0.999988</td>\n",
       "      <td>0.975951</td>\n",
       "      <td>0.999878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>neurlux</td>\n",
       "      <td>0.710317</td>\n",
       "      <td>0.710317</td>\n",
       "      <td>0.841636</td>\n",
       "      <td>0.900207</td>\n",
       "      <td>0.909263</td>\n",
       "      <td>0.999957</td>\n",
       "      <td>0.818531</td>\n",
       "      <td>0.99999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>cnn</td>\n",
       "      <td>0.993019</td>\n",
       "      <td>0.993019</td>\n",
       "      <td>0.995856</td>\n",
       "      <td>0.972873</td>\n",
       "      <td>0.97359</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.947179</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>lstm</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.887761</td>\n",
       "      <td>0.95041</td>\n",
       "      <td>0.952753</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.905518</td>\n",
       "      <td>0.999986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>cnn_lstm</td>\n",
       "      <td>0.556033</td>\n",
       "      <td>0.556033</td>\n",
       "      <td>0.696733</td>\n",
       "      <td>0.801853</td>\n",
       "      <td>0.834624</td>\n",
       "      <td>0.995315</td>\n",
       "      <td>0.66925</td>\n",
       "      <td>0.999987</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Model  TPR at FPR=10^-7  TPR at FPR=10^-6  \\\n",
       "0       _tabular_mlp_minhash          0.696005          0.696005   \n",
       "1        _tabular_rf_minhash          0.612703          0.612703   \n",
       "2       _tabular_xgb_minhash          0.247022          0.247022   \n",
       "3   _tabular_log_reg_minhash          0.417413          0.417413   \n",
       "4        _tabular_mlp_onehot          0.969684          0.969684   \n",
       "5         _tabular_rf_onehot          0.643993          0.643993   \n",
       "6        _tabular_xgb_onehot          0.969335          0.969335   \n",
       "7    _tabular_log_reg_onehot          0.991381          0.991381   \n",
       "8                    mlp_seq          0.601787          0.601787   \n",
       "9        attpool_transformer          0.000000          0.000000   \n",
       "10           cls_transformer          0.000000          0.000000   \n",
       "11          mean_transformer          0.000000          0.000000   \n",
       "12                   neurlux          0.710317          0.710317   \n",
       "13                       cnn          0.993019          0.993019   \n",
       "14                      lstm          0.000000          0.000000   \n",
       "15                  cnn_lstm          0.556033          0.556033   \n",
       "\n",
       "   TPR at FPR=10^-5  F1-Score  Accuracy       AUC    Recall Precision  \n",
       "0            0.8573  0.983713  0.983972  0.999989  0.968034  0.999908  \n",
       "1          0.638888  0.990571  0.990481  0.999948       1.0  0.981318  \n",
       "2          0.418617  0.999404  0.999404  0.999944  0.998928  0.999881  \n",
       "3          0.629707  0.945132  0.947946  0.999818  0.896669  0.999133  \n",
       "4          0.992317  0.997217  0.997224  0.999999  0.994525  0.999923  \n",
       "5          0.840696  0.984538  0.984296  0.999982       1.0  0.969547  \n",
       "6          0.999426   0.99984   0.99984       1.0  0.999792  0.999889  \n",
       "7          0.997805  0.999374  0.999375       1.0  0.998843  0.999906  \n",
       "8          0.640653  0.950122  0.952488  0.999958   0.90508  0.999883  \n",
       "9               0.0     0.975  0.975607  0.999875  0.951344  0.999861  \n",
       "10          0.97399  0.996579   0.99659  0.999996  0.993308  0.999872  \n",
       "11         0.885327   0.98777  0.987916  0.999988  0.975951  0.999878  \n",
       "12         0.841636  0.900207  0.909263  0.999957  0.818531   0.99999  \n",
       "13         0.995856  0.972873   0.97359       1.0  0.947179       1.0  \n",
       "14         0.887761   0.95041  0.952753  0.999983  0.905518  0.999986  \n",
       "15         0.696733  0.801853  0.834624  0.995315   0.66925  0.999987  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score, accuracy_score, confusion_matrix\n",
    "\n",
    "def get_tpr_at_fpr(predicted_logits, true_labels, fprNeeded=1e-5):\n",
    "    predicted_probs = torch.sigmoid(predicted_logits).cpu().detach().numpy()\n",
    "    fpr, tpr, _ = roc_curve(true_labels, predicted_probs)\n",
    "    if all(np.isnan(fpr)):\n",
    "        return np.nan#, np.nan\n",
    "    else:\n",
    "        tpr_at_fpr = tpr[fpr <= fprNeeded][-1]\n",
    "        return tpr_at_fpr\n",
    "\n",
    "results_df = pd.DataFrame(columns=['Model', 'TPR at FPR=10^-5', 'F1-Score', 'Precision', 'Recall', 'AUC', 'Accuracy'])\n",
    "\n",
    "\n",
    "# Loop through each key-value pair in your dictionary, compute the required metrics, and append them to results_df\n",
    "for model_name, predictions in y_preds.items():\n",
    "    predicted_probs = torch.sigmoid(torch.tensor(predictions)).cpu().detach().numpy()\n",
    "    binary_preds = (predicted_probs > 0.6).astype(int)  # Convert probabilities to binary labels with a 0.5 threshold\n",
    "    \n",
    "    auc = roc_auc_score(y_test, predicted_probs)\n",
    "    f1 = f1_score(y_test, binary_preds)\n",
    "    precision = precision_score(y_test, binary_preds)\n",
    "    recall = recall_score(y_test, binary_preds)\n",
    "    accuracy = accuracy_score(y_test, binary_preds)\n",
    "    tpr_at_fpr_1e5 = get_tpr_at_fpr(torch.tensor(predictions), y_test, fprNeeded=1e-5)\n",
    "    tpr_at_fpr_1e6 = get_tpr_at_fpr(torch.tensor(predictions), y_test, fprNeeded=1e-6)\n",
    "    tpr_at_fpr_1e7 = get_tpr_at_fpr(torch.tensor(predictions), y_test, fprNeeded=1e-7)\n",
    "    \n",
    "    # Append results to dataframe\n",
    "    new_row = pd.DataFrame({\n",
    "        'Model': [model_name],\n",
    "        'TPR at FPR=10^-7': [tpr_at_fpr_1e7],\n",
    "        'TPR at FPR=10^-6': [tpr_at_fpr_1e6],\n",
    "        'TPR at FPR=10^-5': [tpr_at_fpr_1e5],\n",
    "        'F1-Score': [f1],\n",
    "        'Precision': [precision],\n",
    "        'Recall': [recall],\n",
    "        'Accuracy': [accuracy],\n",
    "        'AUC': [auc]\n",
    "    })\n",
    "    results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
    "\n",
    "# Output the results\n",
    "results_df[['Model', 'TPR at FPR=10^-7', 'TPR at FPR=10^-6', 'TPR at FPR=10^-5', 'F1-Score', 'Accuracy', 'AUC', 'Recall', 'Precision']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import scienceplots\n",
    "plt.style.use(['science', 'no-latex'])\n",
    "plt.rc('text', usetex=True)\n",
    "\n",
    "from src.plots import set_size\n",
    "\n",
    "df_dict = {}\n",
    "LOGDIR = 'logs_models'\n",
    "\n",
    "# key_extractor = lambda x: x.split('_')[1:]\n",
    "\n",
    "for subfolder in os.listdir(LOGDIR):\n",
    "    subfolder_path = os.path.join(LOGDIR, subfolder)\n",
    "    csv_file_path = os.path.join(subfolder_path, 'version_0', 'metrics.csv')\n",
    "    if os.path.exists(csv_file_path):\n",
    "        df = pd.read_csv(csv_file_path)\n",
    "        encoder = ' '.join(subfolder.split('_')[:-1]).title()\n",
    "        df_dict[encoder] = df\n",
    "\n",
    "\n",
    "def extract_metric_values(df_dict, metric_name, operation='last'):\n",
    "    \"\"\"\n",
    "    Extracts specified metric values (either last or max) from nested DataFrames in df_dict.\n",
    "    \n",
    "    Parameters:\n",
    "        df_dict (defaultdict(dict)): Nested dictionary of DataFrames keyed by tokenizer and vocab_size.\n",
    "        metric_name (str): The name of the metric to extract.\n",
    "        operation (str): The operation to perform ('last' or 'max').\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: DataFrame containing the extracted metric values, indexed by vocab_size and columns by tokenizer.\n",
    "    \"\"\"\n",
    "    # Initialize an empty dictionary to temporarily store the extracted values\n",
    "    extracted_values_temp = {}\n",
    "    \n",
    "    # Loop through the nested DataFrames\n",
    "    for encoder, df in df_dict.items():\n",
    "        if metric_name in df.columns:\n",
    "            if operation == 'last':\n",
    "                # Extract the last value of the specified metric\n",
    "                last_value = df[metric_name].dropna().iloc[-1]\n",
    "                extracted_values_temp[encoder] = last_value\n",
    "                \n",
    "            elif operation == 'max':\n",
    "                # Extract the maximum value of the specified metric\n",
    "                max_value = df[metric_name].dropna().max()\n",
    "                extracted_values_temp[encoder] = max_value\n",
    "            else:\n",
    "                print(f\"Invalid operation '{operation}' specified. Skipping {encoder}.\")\n",
    "        else:\n",
    "            print(f\"Metric '{metric_name}' not found in DataFrame for {encoder}. Skipping.\")\n",
    "                \n",
    "    # Convert the nested dictionary to a DataFrame, using 'metric_name' as value for index\n",
    "    extracted_values_df = pd.DataFrame.from_dict(extracted_values_temp, orient='index', columns=[metric_name]).transpose()\n",
    "\n",
    "    # sort index by vocab_size\n",
    "    extracted_values_df.sort_index(inplace=True)\n",
    "\n",
    "    return extracted_values_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>val_tpr</th>\n",
       "      <th>val_f1</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Attpool Transformer</th>\n",
       "      <td>0.967858</td>\n",
       "      <td>0.982970</td>\n",
       "      <td>0.983254</td>\n",
       "      <td>0.999406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cls Transformer</th>\n",
       "      <td>0.997018</td>\n",
       "      <td>0.995994</td>\n",
       "      <td>0.996010</td>\n",
       "      <td>0.999996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cnn</th>\n",
       "      <td>0.999910</td>\n",
       "      <td>0.974444</td>\n",
       "      <td>0.975081</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cnn Lstm</th>\n",
       "      <td>0.780494</td>\n",
       "      <td>0.642088</td>\n",
       "      <td>0.736428</td>\n",
       "      <td>0.996596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lstm</th>\n",
       "      <td>0.972996</td>\n",
       "      <td>0.940016</td>\n",
       "      <td>0.943411</td>\n",
       "      <td>0.999938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean Transformer</th>\n",
       "      <td>0.967348</td>\n",
       "      <td>0.994659</td>\n",
       "      <td>0.994687</td>\n",
       "      <td>0.999963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mlp Seq</th>\n",
       "      <td>0.969886</td>\n",
       "      <td>0.917868</td>\n",
       "      <td>0.924095</td>\n",
       "      <td>0.999945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neurlux</th>\n",
       "      <td>0.968056</td>\n",
       "      <td>0.900832</td>\n",
       "      <td>0.909776</td>\n",
       "      <td>0.999922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tabular Mlp Minhash</th>\n",
       "      <td>0.993898</td>\n",
       "      <td>0.986445</td>\n",
       "      <td>0.986625</td>\n",
       "      <td>0.999988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tabular Mlp Onehot</th>\n",
       "      <td>0.999303</td>\n",
       "      <td>0.993978</td>\n",
       "      <td>0.994014</td>\n",
       "      <td>0.999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Log Reg Minhash</th>\n",
       "      <td>0.778231</td>\n",
       "      <td>0.925402</td>\n",
       "      <td>0.930557</td>\n",
       "      <td>0.999818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Log Reg Onehot</th>\n",
       "      <td>0.998843</td>\n",
       "      <td>0.999268</td>\n",
       "      <td>0.999268</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rf Minhash</th>\n",
       "      <td>0.790049</td>\n",
       "      <td>0.995738</td>\n",
       "      <td>0.995720</td>\n",
       "      <td>0.999948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rf Onehot</th>\n",
       "      <td>0.952684</td>\n",
       "      <td>0.993455</td>\n",
       "      <td>0.993412</td>\n",
       "      <td>0.999982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Xgb Minhash</th>\n",
       "      <td>0.963397</td>\n",
       "      <td>0.999381</td>\n",
       "      <td>0.999381</td>\n",
       "      <td>0.999944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Xgb Onehot</th>\n",
       "      <td>0.999426</td>\n",
       "      <td>0.999657</td>\n",
       "      <td>0.999658</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       val_tpr    val_f1   val_acc   val_auc\n",
       "Attpool Transformer   0.967858  0.982970  0.983254  0.999406\n",
       "Cls Transformer       0.997018  0.995994  0.996010  0.999996\n",
       "Cnn                   0.999910  0.974444  0.975081  1.000000\n",
       "Cnn Lstm              0.780494  0.642088  0.736428  0.996596\n",
       "Lstm                  0.972996  0.940016  0.943411  0.999938\n",
       "Mean Transformer      0.967348  0.994659  0.994687  0.999963\n",
       "Mlp Seq               0.969886  0.917868  0.924095  0.999945\n",
       "Neurlux               0.968056  0.900832  0.909776  0.999922\n",
       " Tabular Mlp Minhash  0.993898  0.986445  0.986625  0.999988\n",
       " Tabular Mlp Onehot   0.999303  0.993978  0.994014  0.999999\n",
       "Log Reg Minhash       0.778231  0.925402  0.930557  0.999818\n",
       "Log Reg Onehot        0.998843  0.999268  0.999268  1.000000\n",
       "Rf Minhash            0.790049  0.995738  0.995720  0.999948\n",
       "Rf Onehot             0.952684  0.993455  0.993412  0.999982\n",
       "Xgb Minhash           0.963397  0.999381  0.999381  0.999944\n",
       "Xgb Onehot            0.999426  0.999657  0.999658  1.000000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = ['val_tpr', 'val_f1', 'val_acc', 'val_auc']\n",
    "df = pd.DataFrame()\n",
    "for metric in metrics:\n",
    "    df1 = extract_metric_values(df_dict, metric, operation='last')\n",
    "    df = pd.concat([df, df1], axis=0)\n",
    "\n",
    "tabular_df_dict = {}\n",
    "for subfolder in os.listdir(LOGDIR):\n",
    "    subfolder_path = os.path.join(LOGDIR, subfolder)\n",
    "    csv_file_path = os.path.join(subfolder_path, 'metrics.csv')\n",
    "    if os.path.exists(csv_file_path):\n",
    "        ldf = pd.read_csv(csv_file_path)\n",
    "        encoder = ' '.join(subfolder.split('_')[2:]).title()\n",
    "        tabular_df_dict[encoder] = ldf\n",
    "\n",
    "col_map = dict(zip(['tpr', 'f1', 'acc', 'auc'], ['val_tpr', 'val_f1', 'val_acc', 'val_auc']))\n",
    "\n",
    "# Iterate over each item in the dictionary, map the columns, and concatenate to the initial dataframe\n",
    "for model_name, ldf in tabular_df_dict.items():\n",
    "    # Map columns\n",
    "    ldf = ldf.rename(columns=col_map)\n",
    "    # Transpose the dataframe so that metrics are in the columns and model names are in the index\n",
    "    ldf = ldf.T\n",
    "    # Rename the columns of df to match the model name\n",
    "    ldf.columns = [model_name]\n",
    "    # Concatenate along columns axis\n",
    "    df = pd.concat([df, ldf], axis=1)\n",
    "\n",
    "df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>val_tpr</th>\n",
       "      <th>val_f1</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Attpool Transformer</th>\n",
       "      <td>0.983769</td>\n",
       "      <td>0.999551</td>\n",
       "      <td>0.999551</td>\n",
       "      <td>0.999963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cls Transformer</th>\n",
       "      <td>0.997021</td>\n",
       "      <td>0.999889</td>\n",
       "      <td>0.999889</td>\n",
       "      <td>0.999996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cnn</th>\n",
       "      <td>0.999910</td>\n",
       "      <td>0.999949</td>\n",
       "      <td>0.999949</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cnn Lstm</th>\n",
       "      <td>0.916991</td>\n",
       "      <td>0.986644</td>\n",
       "      <td>0.986585</td>\n",
       "      <td>0.997550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lstm</th>\n",
       "      <td>0.992145</td>\n",
       "      <td>0.967622</td>\n",
       "      <td>0.968636</td>\n",
       "      <td>0.999983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean Transformer</th>\n",
       "      <td>0.992789</td>\n",
       "      <td>0.999902</td>\n",
       "      <td>0.999902</td>\n",
       "      <td>0.999988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mlp Seq</th>\n",
       "      <td>0.980032</td>\n",
       "      <td>0.990541</td>\n",
       "      <td>0.990622</td>\n",
       "      <td>0.999957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neurlux</th>\n",
       "      <td>0.980555</td>\n",
       "      <td>0.985019</td>\n",
       "      <td>0.984945</td>\n",
       "      <td>0.999957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tabular Mlp Minhash</th>\n",
       "      <td>0.994517</td>\n",
       "      <td>0.999298</td>\n",
       "      <td>0.999298</td>\n",
       "      <td>0.999989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tabular Mlp Onehot</th>\n",
       "      <td>0.999554</td>\n",
       "      <td>0.999777</td>\n",
       "      <td>0.999777</td>\n",
       "      <td>0.999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Log Reg Minhash</th>\n",
       "      <td>0.778231</td>\n",
       "      <td>0.925402</td>\n",
       "      <td>0.930557</td>\n",
       "      <td>0.999818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Log Reg Onehot</th>\n",
       "      <td>0.998843</td>\n",
       "      <td>0.999268</td>\n",
       "      <td>0.999268</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rf Minhash</th>\n",
       "      <td>0.790049</td>\n",
       "      <td>0.995738</td>\n",
       "      <td>0.995720</td>\n",
       "      <td>0.999948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rf Onehot</th>\n",
       "      <td>0.952684</td>\n",
       "      <td>0.993455</td>\n",
       "      <td>0.993412</td>\n",
       "      <td>0.999982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Xgb Minhash</th>\n",
       "      <td>0.963397</td>\n",
       "      <td>0.999381</td>\n",
       "      <td>0.999381</td>\n",
       "      <td>0.999944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Xgb Onehot</th>\n",
       "      <td>0.999426</td>\n",
       "      <td>0.999657</td>\n",
       "      <td>0.999658</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       val_tpr    val_f1   val_acc   val_auc\n",
       "Attpool Transformer   0.983769  0.999551  0.999551  0.999963\n",
       "Cls Transformer       0.997021  0.999889  0.999889  0.999996\n",
       "Cnn                   0.999910  0.999949  0.999949  1.000000\n",
       "Cnn Lstm              0.916991  0.986644  0.986585  0.997550\n",
       "Lstm                  0.992145  0.967622  0.968636  0.999983\n",
       "Mean Transformer      0.992789  0.999902  0.999902  0.999988\n",
       "Mlp Seq               0.980032  0.990541  0.990622  0.999957\n",
       "Neurlux               0.980555  0.985019  0.984945  0.999957\n",
       " Tabular Mlp Minhash  0.994517  0.999298  0.999298  0.999989\n",
       " Tabular Mlp Onehot   0.999554  0.999777  0.999777  0.999999\n",
       "Log Reg Minhash       0.778231  0.925402  0.930557  0.999818\n",
       "Log Reg Onehot        0.998843  0.999268  0.999268  1.000000\n",
       "Rf Minhash            0.790049  0.995738  0.995720  0.999948\n",
       "Rf Onehot             0.952684  0.993455  0.993412  0.999982\n",
       "Xgb Minhash           0.963397  0.999381  0.999381  0.999944\n",
       "Xgb Onehot            0.999426  0.999657  0.999658  1.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = ['val_tpr', 'val_f1', 'val_acc', 'val_auc']\n",
    "df = pd.DataFrame()\n",
    "for metric in metrics:\n",
    "    df1 = extract_metric_values(df_dict, metric, operation='max')\n",
    "    df = pd.concat([df, df1], axis=0)\n",
    "\n",
    "tabular_df_dict = {}\n",
    "for subfolder in os.listdir(LOGDIR):\n",
    "    subfolder_path = os.path.join(LOGDIR, subfolder)\n",
    "    csv_file_path = os.path.join(subfolder_path, 'metrics.csv')\n",
    "    if os.path.exists(csv_file_path):\n",
    "        ldf = pd.read_csv(csv_file_path)\n",
    "        encoder = ' '.join(subfolder.split('_')[2:]).title()\n",
    "        tabular_df_dict[encoder] = ldf\n",
    "\n",
    "col_map = dict(zip(['tpr', 'f1', 'acc', 'auc'], ['val_tpr', 'val_f1', 'val_acc', 'val_auc']))\n",
    "\n",
    "# Iterate over each item in the dictionary, map the columns, and concatenate to the initial dataframe\n",
    "for model_name, ldf in tabular_df_dict.items():\n",
    "    # Map columns\n",
    "    ldf = ldf.rename(columns=col_map)\n",
    "    # Transpose the dataframe so that metrics are in the columns and model names are in the index\n",
    "    ldf = ldf.T\n",
    "    # Rename the columns of df to match the model name\n",
    "    ldf.columns = [model_name]\n",
    "    # Concatenate along columns axis\n",
    "    df = pd.concat([df, ldf], axis=1)\n",
    "\n",
    "df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
