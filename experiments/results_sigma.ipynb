{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, roc_auc_score, roc_curve, auc\n",
    "\n",
    "LIMIT = None\n",
    "SEED = 33\n",
    "ROOT = \"..\"\n",
    "\n",
    "import sys\n",
    "sys.path.append(ROOT)\n",
    "from src.data_utils import load_data\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def get_tpr_at_fpr(predicted_probs, true_labels, fprNeeded=1e-5):\n",
    "    # if isinstance(predicted_logits, torch.Tensor):\n",
    "    #     predicted_probs = torch.sigmoid(predicted_logits).cpu().detach().numpy()\n",
    "    # else:\n",
    "    #     predicted_probs = sigmoid(predicted_logits)\n",
    "    \n",
    "    if isinstance(true_labels, torch.Tensor):\n",
    "        true_labels = true_labels.cpu().detach().numpy()\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(true_labels, predicted_probs)\n",
    "    if all(np.isnan(fpr)):\n",
    "        return np.nan#, np.nan\n",
    "    else:\n",
    "        tpr_at_fpr = tpr[fpr <= fprNeeded][-1]\n",
    "        #threshold_at_fpr = thresholds[fpr <= fprNeeded][-1]\n",
    "        return tpr_at_fpr#, threshold_at_fpr\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_cmds:  50\n"
     ]
    }
   ],
   "source": [
    "# sigma_yml_path = os.path.join(ROOT, \"data\", \"rvrs_sigma.yml\")\n",
    "sigma_rule_folder = os.path.join(ROOT, \"data\", \"signatures\")\n",
    "sigma_rule_yamls = [os.path.join(sigma_rule_folder, f) for f in os.listdir(sigma_rule_folder) if f.endswith(\".yaml\")]\n",
    "\n",
    "*_, X_train_malicious_cmd, _, X_test_malicious_cmd, _ = load_data(ROOT, seed=33, limit=100)\n",
    "\n",
    "print('X_train_cmds: ', len(X_train_malicious_cmd))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_sigma(X_cmds, y, sigma_yml, verbose=False):\n",
    "    with open(sigma_yml, \"r\") as f:\n",
    "        sigma = yaml.load(f, Loader=yaml.FullLoader)\n",
    "    patterns = sigma['detection']['keywords']\n",
    "    \n",
    "    y_pred = []\n",
    "    for i, cmd in enumerate(X_cmds):\n",
    "        # match if pattern in cmd\n",
    "        for pattern in patterns:\n",
    "            if pattern in cmd:\n",
    "                if verbose:\n",
    "                    print(f\"[!] True label: {y[i]} | Found '{pattern}' in '{cmd}'\")\n",
    "                y_pred.append(1)\n",
    "                break\n",
    "        else:\n",
    "            y_pred.append(0)\n",
    "        \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'keywords'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m y_train_pred \u001b[38;5;241m=\u001b[39m \u001b[43mapply_sigma\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_malicious_cmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_train_malicious_cmd\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma_rule_yamls\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 4\u001b[0m, in \u001b[0;36mapply_sigma\u001b[0;34m(X_cmds, y, sigma_yml, verbose)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(sigma_yml, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      3\u001b[0m     sigma \u001b[38;5;241m=\u001b[39m yaml\u001b[38;5;241m.\u001b[39mload(f, Loader\u001b[38;5;241m=\u001b[39myaml\u001b[38;5;241m.\u001b[39mFullLoader)\n\u001b[0;32m----> 4\u001b[0m patterns \u001b[38;5;241m=\u001b[39m \u001b[43msigma\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdetection\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mkeywords\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      6\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, cmd \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(X_cmds):\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m# match if pattern in cmd\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'keywords'"
     ]
    }
   ],
   "source": [
    "y_train_pred = apply_sigma(X_train_malicious_cmd, [1] * len(X_train_malicious_cmd), sigma_rule_yamls[0], verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP 8974\n",
      "FP 0\n"
     ]
    }
   ],
   "source": [
    "mask = y_train == 1\n",
    "true_positives = np.array(y_train_pred)[mask]\n",
    "false_positives = np.array(y_train_pred)[~mask]\n",
    "print(\"TP\", np.sum(true_positives))\n",
    "print(\"FP\", np.sum(false_positives))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TPR at FPR=1e-5: 3.3673%\n",
      "F1 score: 6.5153%\n",
      "Accuracy: 51.6848%\n",
      "AUC: 51.6837%\n"
     ]
    }
   ],
   "source": [
    "tpr = get_tpr_at_fpr(y_train_pred, y_train, fprNeeded=1e-5)\n",
    "f1 = f1_score(y_train, y_train_pred)\n",
    "acc = accuracy_score(y_train, y_train_pred)\n",
    "auc = roc_auc_score(y_train, y_train_pred)\n",
    "\n",
    "print('TPR at FPR=1e-5: {:.4f}%'.format(tpr*100))\n",
    "print('F1 score: {:.4f}%'.format(f1*100))\n",
    "print('Accuracy: {:.4f}%'.format(acc*100))\n",
    "print('AUC: {:.4f}%'.format(auc*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
