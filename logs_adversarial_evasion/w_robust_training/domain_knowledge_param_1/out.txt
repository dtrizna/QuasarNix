C:\Users\dtrizna\Code\Synapse\Linux>python3 adversarial_evasion.py
[!] Script start time: Sat Jan 27 10:46:01 2024
Python implementation: CPython
Python version       : 3.9.13
IPython version      : 8.11.0

torch    : 2.0.1+cu117
lightning: 1.8.6
sklearn  : 0.0.post1

Global seed set to 33
Sizes of train and test sets: 533014, 470129
[*] Subsampling malicious test set to 5000 samples...
[*] Constructing adversarial test set with attack's payload size 0.05...
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 5000/5000 [00:00<00:00, 289645.88it/s]
[*] Constructing adversarial test set with attack's payload size 0.1...
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 5000/5000 [00:00<00:00, 195105.69it/s]
[*] Constructing adversarial test set with attack's payload size 0.3...
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 5000/5000 [00:00<00:00, 109370.22it/s] 
[*] Constructing adversarial test set with attack's payload size 0.5...
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 5000/5000 [00:00<00:00, 110766.44it/s] 
[*] Constructing adversarial test set with attack's payload size 0.7...
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 5000/5000 [00:00<00:00, 95939.54it/s] 
[*] Constructing adversarial test set with attack's payload size 0.9...
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 5000/5000 [00:00<00:00, 93338.67it/s]
[*] Constructing adversarial test set with attack's payload size 1...
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 5000/5000 [00:00<00:00, 75302.23it/s] 
[*] Creating robust training set: applying attack with highest parameter...
100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 266501/266501 [00:02<00:00, 102401.09it/s] 
[!!!] Starting attack against 'cnn' model...
[*] Building vocab and encoding...
[!] Training original model 'cnn_orig' started: Sat Jan 27 10:46:49 2024
[!] Scheduler: onecycle | Scheduler step budget: 20830
GPU available: True (cuda), used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
C:\Users\dtrizna\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\LocalCache\local-packages\Python39\site-packages\lightning\pytorch\trainer\setup.py:175: PossibleUserWarning: GPU available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='gpu', devices=1)`.
  rank_zero_warn(
[*] Training 'cnn_orig' model...
[!] Setting up onecycle scheduler with step budget 20830

   | Name            | Type              | Params
-------------------------------------------------------
0  | model           | CNN1DGroupedModel | 301 K
1  | loss            | BCEWithLogitsLoss | 0
2  | train_acc       | BinaryAccuracy    | 0
3  | train_f1        | BinaryF1Score     | 0
4  | train_auc       | BinaryAUROC       | 0
5  | train_recall    | BinaryRecall      | 0
6  | train_precision | BinaryPrecision   | 0
7  | val_acc         | BinaryAccuracy    | 0
8  | val_f1          | BinaryF1Score     | 0
9  | val_auc         | BinaryAUROC       | 0
10 | val_recall      | BinaryRecall      | 0
11 | val_precision   | BinaryPrecision   | 0
-------------------------------------------------------
301 K     Trainable params
0         Non-trainable params
301 K     Total params
1.205     Total estimated model params size (MB)
Epoch 0:  50%|▍| 2878/5757 [05:52<05:52,  8.16it/s, loss=0.0114, v_num=0, train_loss=0.0151, memory=0.000, val_f1=0.995, val_tpr=0.978, val_acc=0.9Metric val_tpr improved. New best score: 0.978                                                                                                       
Epoch 0: 100%|▉| 5756/5757 [11:28<00:00,  8.36it/s, loss=0.00106, v_num=0, train_loss=0.000318, memory=0.000, val_f1=1.000, val_tpr=0.999, val_acc=Metric val_tpr improved by 0.021 >= min_delta = 0.0001. New best score: 0.999
Epoch 0: 100%|█| 5757/5757 [11:28<00:00,  8.36it/s, loss=0.00104, v_num=0, train_loss=4.76e-5, memory=0.000, val_f1=1.000, val_tpr=0.999, val_acc=1
Epoch 1:  50%|▍| 2878/5757 [05:37<05:37,  8.54it/s, loss=0.000193, v_num=0, train_loss=1.47e-5, memory=0.000, val_f1=1.000, val_tpr=0.999, val_acc=Metric val_tpr improved by 0.000 >= min_delta = 0.0001. New best score: 0.999
Epoch 1: 100%|█| 5757/5757 [11:27<00:00,  8.38it/s, loss=3.77e-05, v_num=0, train_loss=1.28e-6, memory=0.000, val_f1=1.000, val_tpr=0.999, val_acc=
Epoch 2: 100%|▉| 5756/5757 [12:12<00:00,  7.86it/s, loss=0.000948, v_num=0, train_loss=0.0102, memory=0.000, val_f1=0.910, val_tpr=0.999, val_acc=0Metric val_tpr improved by 0.000 >= min_delta = 0.0001. New best score: 0.999                                                                        
Epoch 2: 100%|█| 5757/5757 [12:12<00:00,  7.86it/s, loss=0.000948, v_num=0, train_loss=1.28e-6, memory=0.000, val_f1=0.910, val_tpr=0.999, val_acc=
Epoch 3:  50%|▍| 2878/5757 [06:14<06:14,  7.68it/s, loss=0.000127, v_num=0, train_loss=4.59e-6, memory=0.000, val_f1=0.999, val_tpr=1.000, val_acc=Metric val_tpr improved by 0.000 >= min_delta = 0.0001. New best score: 1.000                                                                        
Epoch 3: 100%|▉| 5756/5757 [12:38<00:00,  7.59it/s, loss=1.09e-06, v_num=0, train_loss=4e-8, memory=0.000, val_f1=1.000, val_tpr=1.000, val_acc=1.0Metric val_tpr improved by 0.000 >= min_delta = 0.0001. New best score: 1.000                                                                        
Epoch 3: 100%|█| 5757/5757 [12:38<00:00,  7.59it/s, loss=1.09e-06, v_num=0, train_loss=0.000, memory=0.000, val_f1=1.000, val_tpr=1.000, val_acc=1.
Epoch 4:  50%|▍| 2878/5757 [06:27<06:27,  7.42it/s, loss=2.17e-06, v_num=0, train_loss=1.4e-9, memory=0.000, val_f1=0.960, val_tpr=1.000, val_acc=0Metric val_tpr improved by 0.000 >= min_delta = 0.0001. New best score: 1.000                                                                        
Epoch 4: 100%|█| 5757/5757 [12:59<00:00,  7.39it/s, loss=1.55e-06, v_num=0, train_loss=0.000, memory=0.000, val_f1=0.984, val_tpr=1.000, val_acc=0.
Epoch 5: 100%|█| 5757/5757 [13:14<00:00,  7.24it/s, loss=5.89e-07, v_num=0, train_loss=0.000, memory=0.000, val_f1=0.997, val_tpr=1.000, val_acc=0. 
Epoch 6: 100%|▉| 5756/5757 [13:44<00:00,  6.98it/s, loss=5.08e-06, v_num=0, train_loss=1.86e-9, memory=0.000, val_f1=0.986, val_tpr=1.000, val_acc=Monitored metric val_tpr did not improve in the last 5 records. Best score: 1.000. Signaling Trainer to stop.                                        
Epoch 6: 100%|▉| 5756/5757 [13:44<00:00,  6.98it/s, loss=5.08e-06, v_num=0, train_loss=1.86e-9, memory=0.000, val_f1=0.986, val_tpr=1.000, val_acc=
Epoch 6: 100%|▉| 5756/5757 [13:44<00:00,  6.98it/s, loss=5.08e-06, v_num=0, train_loss=1.86e-9, memory=0.000, val_f1=0.986, val_tpr=1.000, val_acc=
[!] Training of 'cnn_orig' ended:  Sat Jan 27 12:14:52 2024  | Took: 5283.45 seconds
C:\Users\dtrizna\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\LocalCache\local-packages\Python39\site-packages\lightning\pytorch\trainer\connectors\data_connector.py:224: PossibleUserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 14.45it/s]
[!] Orig train | Orig test |  Evasive: 130
[!] Orig train | Orig test | Accuracy: 0.974
C:\Users\dtrizna\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\LocalCache\local-packages\Python39\site-packages\lightning\pytorch\trainer\connectors\data_connector.py:224: PossibleUserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 14.67it/s]
[!] Orig train | Adv test | Payload 0.05 |  Evasive: 262
[!] Orig train | Adv test | Payload 0.05 | Accuracy: 0.948
C:\Users\dtrizna\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\LocalCache\local-packages\Python39\site-packages\lightning\pytorch\trainer\connectors\data_connector.py:224: PossibleUserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 14.35it/s]
[!] Orig train | Adv test | Payload 0.1 |  Evasive: 409
[!] Orig train | Adv test | Payload 0.1 | Accuracy: 0.918
C:\Users\dtrizna\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\LocalCache\local-packages\Python39\site-packages\lightning\pytorch\trainer\connectors\data_connector.py:224: PossibleUserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 14.14it/s]
[!] Orig train | Adv test | Payload 0.3 |  Evasive: 914
[!] Orig train | Adv test | Payload 0.3 | Accuracy: 0.817
C:\Users\dtrizna\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\LocalCache\local-packages\Python39\site-packages\lightning\pytorch\trainer\connectors\data_connector.py:224: PossibleUserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 13.79it/s]
[!] Orig train | Adv test | Payload 0.5 |  Evasive: 1495
[!] Orig train | Adv test | Payload 0.5 | Accuracy: 0.701
C:\Users\dtrizna\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\LocalCache\local-packages\Python39\site-packages\lightning\pytorch\trainer\connectors\data_connector.py:224: PossibleUserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 14.46it/s]
[!] Orig train | Adv test | Payload 0.7 |  Evasive: 2115
[!] Orig train | Adv test | Payload 0.7 | Accuracy: 0.577
C:\Users\dtrizna\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\LocalCache\local-packages\Python39\site-packages\lightning\pytorch\trainer\connectors\data_connector.py:224: PossibleUserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 14.31it/s]
[!] Orig train | Adv test | Payload 0.9 |  Evasive: 2889
[!] Orig train | Adv test | Payload 0.9 | Accuracy: 0.422
C:\Users\dtrizna\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\LocalCache\local-packages\Python39\site-packages\lightning\pytorch\trainer\connectors\data_connector.py:224: PossibleUserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 14.54it/s]
[!] Orig train | Adv test | Payload 1 |  Evasive: 3333
[!] Orig train | Adv test | Payload 1 | Accuracy: 0.333
[!] Training of adversarial model 'cnn_adv' started: Sat Jan 27 12:17:39 2024
GPU available: True (cuda), used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
C:\Users\dtrizna\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\LocalCache\local-packages\Python39\site-packages\lightning\pytorch\trainer\setup.py:175: PossibleUserWarning: GPU available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='gpu', devices=1)`.
  rank_zero_warn(
[*] Training 'cnn_adv' model...

   | Name            | Type              | Params
-------------------------------------------------------
0  | model           | CNN1DGroupedModel | 301 K
1  | loss            | BCEWithLogitsLoss | 0
2  | train_acc       | BinaryAccuracy    | 0
3  | train_f1        | BinaryF1Score     | 0
4  | train_auc       | BinaryAUROC       | 0
5  | train_recall    | BinaryRecall      | 0
6  | train_precision | BinaryPrecision   | 0
7  | val_acc         | BinaryAccuracy    | 0
8  | val_f1          | BinaryF1Score     | 0
9  | val_auc         | BinaryAUROC       | 0
10 | val_recall      | BinaryRecall      | 0
11 | val_precision   | BinaryPrecision   | 0
-------------------------------------------------------
301 K     Trainable params
0         Non-trainable params
301 K     Total params
1.205     Total estimated model params size (MB)
Epoch 0:  50%|▍| 2878/5757 [06:01<06:01,  7.97it/s, loss=0.00019, v_num=0, train_loss=9.41e-5, memory=0.000, val_f1=0.912, val_tpr=0.989, val_acc=0Metric val_tpr improved. New best score: 0.989
Epoch 0: 100%|█| 5757/5757 [12:01<00:00,  7.98it/s, loss=0.000149, v_num=0, train_loss=2.17e-8, memory=0.000, val_f1=0.757, val_tpr=0.984, val_acc=
Epoch 1: 100%|█| 5757/5757 [12:29<00:00,  7.68it/s, loss=3.12e-05, v_num=0, train_loss=0.000, memory=0.000, val_f1=0.798, val_tpr=0.916, val_acc=0.
Epoch 2: 100%|▉| 5756/5757 [12:47<00:00,  7.50it/s, loss=6.75e-06, v_num=0, train_loss=7.45e-9, memory=0.000, val_f1=0.817, val_tpr=0.973, val_acc=Monitored metric val_tpr did not improve in the last 5 records. Best score: 0.989. Signaling Trainer to stop.                                        
Epoch 2: 100%|▉| 5756/5757 [12:47<00:00,  7.50it/s, loss=6.75e-06, v_num=0, train_loss=7.45e-9, memory=0.000, val_f1=0.817, val_tpr=0.973, val_acc=
Epoch 2: 100%|▉| 5756/5757 [12:48<00:00,  7.49it/s, loss=6.75e-06, v_num=0, train_loss=7.45e-9, memory=0.000, val_f1=0.817, val_tpr=0.973, val_acc=
[!] Training of 'cnn_adv' ended:  Sat Jan 27 12:55:13 2024  | Took: 2253.55 seconds
C:\Users\dtrizna\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\LocalCache\local-packages\Python39\site-packages\lightning\pytorch\trainer\connectors\data_connector.py:224: PossibleUserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 14.25it/s]
[!] Adv train | Orig test |  Evasive: 1491
[!] Adv train | Orig test | Accuracy: 0.702
C:\Users\dtrizna\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\LocalCache\local-packages\Python39\site-packages\lightning\pytorch\trainer\connectors\data_connector.py:224: PossibleUserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 13.81it/s]
[!] Adv train | Adv test | Payload 0.05 |  Evasive: 1454
[!] Adv train | Adv test | Payload 0.05 | Accuracy: 0.709
C:\Users\dtrizna\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\LocalCache\local-packages\Python39\site-packages\lightning\pytorch\trainer\connectors\data_connector.py:224: PossibleUserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 14.36it/s]
[!] Adv train | Adv test | Payload 0.1 |  Evasive: 1418
[!] Adv train | Adv test | Payload 0.1 | Accuracy: 0.716
C:\Users\dtrizna\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\LocalCache\local-packages\Python39\site-packages\lightning\pytorch\trainer\connectors\data_connector.py:224: PossibleUserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 14.55it/s]
[!] Adv train | Adv test | Payload 0.3 |  Evasive: 1246
[!] Adv train | Adv test | Payload 0.3 | Accuracy: 0.751
C:\Users\dtrizna\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\LocalCache\local-packages\Python39\site-packages\lightning\pytorch\trainer\connectors\data_connector.py:224: PossibleUserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 14.64it/s]
[!] Adv train | Adv test | Payload 0.5 |  Evasive: 1038
[!] Adv train | Adv test | Payload 0.5 | Accuracy: 0.792
C:\Users\dtrizna\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\LocalCache\local-packages\Python39\site-packages\lightning\pytorch\trainer\connectors\data_connector.py:224: PossibleUserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 15.05it/s]
[!] Adv train | Adv test | Payload 0.7 |  Evasive: 831
[!] Adv train | Adv test | Payload 0.7 | Accuracy: 0.834
C:\Users\dtrizna\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\LocalCache\local-packages\Python39\site-packages\lightning\pytorch\trainer\connectors\data_connector.py:224: PossibleUserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 14.96it/s]
[!] Adv train | Adv test | Payload 0.9 |  Evasive: 685
[!] Adv train | Adv test | Payload 0.9 | Accuracy: 0.863
C:\Users\dtrizna\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\LocalCache\local-packages\Python39\site-packages\lightning\pytorch\trainer\connectors\data_connector.py:224: PossibleUserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 15.08it/s]
[!] Adv train | Adv test | Payload 1 |  Evasive: 569
[!] Adv train | Adv test | Payload 1 | Accuracy: 0.886
[!!!] Starting attack against 'mlp_onehot' model...
[*] Fitting One-Hot encoder...
[!] Fitting One-Hot encoder took: 7.89s
[!] Training original model 'mlp_onehot_orig' started: Sat Jan 27 12:58:55 2024
[!] Scheduler: onecycle | Scheduler step budget: 20830
GPU available: True (cuda), used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
C:\Users\dtrizna\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\LocalCache\local-packages\Python39\site-packages\lightning\pytorch\trainer\setup.py:175: PossibleUserWarning: GPU available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='gpu', devices=1)`.
  rank_zero_warn(
[*] Training 'mlp_onehot_orig' model...
[!] Setting up onecycle scheduler with step budget 20830

   | Name            | Type              | Params
-------------------------------------------------------
0  | model           | SimpleMLP         | 264 K
1  | loss            | BCEWithLogitsLoss | 0
2  | train_acc       | BinaryAccuracy    | 0
3  | train_f1        | BinaryF1Score     | 0
4  | train_auc       | BinaryAUROC       | 0
5  | train_recall    | BinaryRecall      | 0
6  | train_precision | BinaryPrecision   | 0
7  | val_acc         | BinaryAccuracy    | 0
8  | val_f1          | BinaryF1Score     | 0
9  | val_auc         | BinaryAUROC       | 0
10 | val_recall      | BinaryRecall      | 0
11 | val_precision   | BinaryPrecision   | 0
-------------------------------------------------------
264 K     Trainable params
0         Non-trainable params
264 K     Total params
1.057     Total estimated model params size (MB)
Epoch 0:  50%|▍| 2878/5757 [01:33<01:33, 30.69it/s, loss=0.0499, v_num=0, train_loss=0.0498, memory=0.000, val_f1=0.999, val_tpr=0.999, val_acc=0.9Metric val_tpr improved. New best score: 0.999
Epoch 0: 100%|▉| 5756/5757 [02:32<00:00, 37.84it/s, loss=0.00245, v_num=0, train_loss=0.004, memory=0.000, val_f1=1.000, val_tpr=1.000, val_acc=1.0Metric val_tpr improved by 0.001 >= min_delta = 0.0001. New best score: 1.000
Epoch 0: 100%|█| 5757/5757 [02:32<00:00, 37.80it/s, loss=0.00241, v_num=0, train_loss=0.00115, memory=0.000, val_f1=1.000, val_tpr=1.000, val_acc=1
Epoch 1: 100%|█| 5757/5757 [02:23<00:00, 40.24it/s, loss=0.000112, v_num=0, train_loss=6.63e-6, memory=0.000, val_f1=0.999, val_tpr=1.000, val_acc=
Epoch 2: 100%|█| 5757/5757 [02:55<00:00, 32.89it/s, loss=2.89e-05, v_num=0, train_loss=5.42e-9, memory=0.000, val_f1=0.997, val_tpr=1.000, val_acc=
Epoch 3:  50%|▍| 2878/5757 [01:39<01:39, 28.84it/s, loss=2.25e-05, v_num=0, train_loss=5.52e-6, memory=0.000, val_f1=0.982, val_tpr=0.999, val_acc=Monitored metric val_tpr did not improve in the last 5 records. Best score: 1.000. Signaling Trainer to stop.
Epoch 3:  50%|▍| 2878/5757 [01:39<01:39, 28.80it/s, loss=2.25e-05, v_num=0, train_loss=5.52e-6, memory=0.000, val_f1=0.982, val_tpr=0.999, val_acc=
Epoch 3:  50%|▍| 2878/5757 [01:40<01:40, 28.78it/s, loss=2.25e-05, v_num=0, train_loss=5.52e-6, memory=0.000, val_f1=0.982, val_tpr=0.999, val_acc=
[!] Training of 'mlp_onehot_orig' ended:  Sat Jan 27 13:09:52 2024  | Took: 657.10 seconds
C:\Users\dtrizna\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\LocalCache\local-packages\Python39\site-packages\lightning\pytorch\trainer\connectors\data_connector.py:224: PossibleUserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 40.43it/s]
[!] Orig train | Orig test |  Evasive: 166
[!] Orig train | Orig test | Accuracy: 0.967
C:\Users\dtrizna\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\LocalCache\local-packages\Python39\site-packages\lightning\pytorch\trainer\connectors\data_connector.py:224: PossibleUserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 41.51it/s]
[!] Orig train | Adv test | Payload 0.05 |  Evasive: 235
[!] Orig train | Adv test | Payload 0.05 | Accuracy: 0.953
C:\Users\dtrizna\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\LocalCache\local-packages\Python39\site-packages\lightning\pytorch\trainer\connectors\data_connector.py:224: PossibleUserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 40.31it/s]
[!] Orig train | Adv test | Payload 0.1 |  Evasive: 329
[!] Orig train | Adv test | Payload 0.1 | Accuracy: 0.934
C:\Users\dtrizna\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\LocalCache\local-packages\Python39\site-packages\lightning\pytorch\trainer\connectors\data_connector.py:224: PossibleUserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 41.70it/s]
[!] Orig train | Adv test | Payload 0.3 |  Evasive: 649
[!] Orig train | Adv test | Payload 0.3 | Accuracy: 0.870
C:\Users\dtrizna\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\LocalCache\local-packages\Python39\site-packages\lightning\pytorch\trainer\connectors\data_connector.py:224: PossibleUserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 39.40it/s]
[!] Orig train | Adv test | Payload 0.5 |  Evasive: 1009
[!] Orig train | Adv test | Payload 0.5 | Accuracy: 0.798
C:\Users\dtrizna\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\LocalCache\local-packages\Python39\site-packages\lightning\pytorch\trainer\connectors\data_connector.py:224: PossibleUserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 39.39it/s]
[!] Orig train | Adv test | Payload 0.7 |  Evasive: 1378
[!] Orig train | Adv test | Payload 0.7 | Accuracy: 0.724
C:\Users\dtrizna\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\LocalCache\local-packages\Python39\site-packages\lightning\pytorch\trainer\connectors\data_connector.py:224: PossibleUserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 43.21it/s]
[!] Orig train | Adv test | Payload 0.9 |  Evasive: 1680
[!] Orig train | Adv test | Payload 0.9 | Accuracy: 0.664
C:\Users\dtrizna\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\LocalCache\local-packages\Python39\site-packages\lightning\pytorch\trainer\connectors\data_connector.py:224: PossibleUserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 40.52it/s]
[!] Orig train | Adv test | Payload 1 |  Evasive: 1841
[!] Orig train | Adv test | Payload 1 | Accuracy: 0.632
[!] Training of adversarial model 'mlp_onehot_adv' started: Sat Jan 27 13:12:09 2024
GPU available: True (cuda), used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
C:\Users\dtrizna\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\LocalCache\local-packages\Python39\site-packages\lightning\pytorch\trainer\setup.py:175: PossibleUserWarning: GPU available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='gpu', devices=1)`.
  rank_zero_warn(
[*] Training 'mlp_onehot_adv' model...

   | Name            | Type              | Params
-------------------------------------------------------
0  | model           | SimpleMLP         | 264 K
1  | loss            | BCEWithLogitsLoss | 0
2  | train_acc       | BinaryAccuracy    | 0
3  | train_f1        | BinaryF1Score     | 0
4  | train_auc       | BinaryAUROC       | 0
5  | train_recall    | BinaryRecall      | 0
6  | train_precision | BinaryPrecision   | 0
7  | val_acc         | BinaryAccuracy    | 0
8  | val_f1          | BinaryF1Score     | 0
9  | val_auc         | BinaryAUROC       | 0
10 | val_recall      | BinaryRecall      | 0
11 | val_precision   | BinaryPrecision   | 0
-------------------------------------------------------
264 K     Trainable params
0         Non-trainable params
264 K     Total params
1.057     Total estimated model params size (MB)
Epoch 0:  50%|▍| 2878/5757 [02:05<02:05, 23.01it/s, loss=0.000297, v_num=0, train_loss=0.000247, memory=0.000, val_f1=0.962, val_tpr=0.987, val_accMetric val_tpr improved. New best score: 0.987
Epoch 0: 100%|▉| 5756/5757 [03:02<00:00, 31.52it/s, loss=0.000146, v_num=0, train_loss=0.000111, memory=0.000, val_f1=0.952, val_tpr=0.990, val_accMetric val_tpr improved by 0.003 >= min_delta = 0.0001. New best score: 0.990
Epoch 0: 100%|█| 5757/5757 [03:02<00:00, 31.50it/s, loss=0.000122, v_num=0, train_loss=0.000413, memory=0.000, val_f1=0.952, val_tpr=0.990, val_acc
Epoch 1: 100%|█| 5757/5757 [02:15<00:00, 42.43it/s, loss=0.000329, v_num=0, train_loss=1.96e-5, memory=0.000, val_f1=0.922, val_tpr=0.984, val_acc=
Epoch 2: 100%|█| 5757/5757 [02:53<00:00, 33.12it/s, loss=1.45e-05, v_num=0, train_loss=5.42e-9, memory=0.000, val_f1=0.941, val_tpr=0.986, val_acc=
Epoch 3:  50%|▍| 2878/5757 [01:33<01:33, 30.65it/s, loss=0.000149, v_num=0, train_loss=1.3e-8, memory=0.000, val_f1=0.923, val_tpr=0.984, val_acc=0Monitored metric val_tpr did not improve in the last 5 records. Best score: 0.990. Signaling Trainer to stop.
Epoch 3:  50%|▍| 2878/5757 [01:34<01:34, 30.61it/s, loss=0.000149, v_num=0, train_loss=1.3e-8, memory=0.000, val_f1=0.923, val_tpr=0.984, val_acc=0
Epoch 3:  50%|▍| 2878/5757 [01:34<01:34, 30.59it/s, loss=0.000149, v_num=0, train_loss=1.3e-8, memory=0.000, val_f1=0.923, val_tpr=0.984, val_acc=0
[!] Training of 'mlp_onehot_adv' ended:  Sat Jan 27 13:22:48 2024  | Took: 639.10 seconds
C:\Users\dtrizna\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\LocalCache\local-packages\Python39\site-packages\lightning\pytorch\trainer\connectors\data_connector.py:224: PossibleUserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 42.28it/s]
[!] Adv train | Orig test |  Evasive: 714
[!] Adv train | Orig test | Accuracy: 0.857
C:\Users\dtrizna\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\LocalCache\local-packages\Python39\site-packages\lightning\pytorch\trainer\connectors\data_connector.py:224: PossibleUserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 42.28it/s]
[!] Adv train | Adv test | Payload 0.05 |  Evasive: 712
[!] Adv train | Adv test | Payload 0.05 | Accuracy: 0.858
C:\Users\dtrizna\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\LocalCache\local-packages\Python39\site-packages\lightning\pytorch\trainer\connectors\data_connector.py:224: PossibleUserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 43.43it/s]
[!] Adv train | Adv test | Payload 0.1 |  Evasive: 698
[!] Adv train | Adv test | Payload 0.1 | Accuracy: 0.860
C:\Users\dtrizna\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\LocalCache\local-packages\Python39\site-packages\lightning\pytorch\trainer\connectors\data_connector.py:224: PossibleUserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 44.05it/s]
[!] Adv train | Adv test | Payload 0.3 |  Evasive: 685
[!] Adv train | Adv test | Payload 0.3 | Accuracy: 0.863
C:\Users\dtrizna\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\LocalCache\local-packages\Python39\site-packages\lightning\pytorch\trainer\connectors\data_connector.py:224: PossibleUserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 46.65it/s]
[!] Adv train | Adv test | Payload 0.5 |  Evasive: 629
[!] Adv train | Adv test | Payload 0.5 | Accuracy: 0.874
C:\Users\dtrizna\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\LocalCache\local-packages\Python39\site-packages\lightning\pytorch\trainer\connectors\data_connector.py:224: PossibleUserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 45.39it/s]
[!] Adv train | Adv test | Payload 0.7 |  Evasive: 625
[!] Adv train | Adv test | Payload 0.7 | Accuracy: 0.875
C:\Users\dtrizna\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\LocalCache\local-packages\Python39\site-packages\lightning\pytorch\trainer\connectors\data_connector.py:224: PossibleUserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 43.62it/s]
[!] Adv train | Adv test | Payload 0.9 |  Evasive: 583
[!] Adv train | Adv test | Payload 0.9 | Accuracy: 0.883
C:\Users\dtrizna\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\LocalCache\local-packages\Python39\site-packages\lightning\pytorch\trainer\connectors\data_connector.py:224: PossibleUserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 40.68it/s]
[!] Adv train | Adv test | Payload 1 |  Evasive: 553
[!] Adv train | Adv test | Payload 1 | Accuracy: 0.889
[!!!] Starting attack against 'mean_transformer' model...
[!] Loading vocab from 'logs_adversarial_evasion\w_robust_training\domain_knowledge\wordpunct_vocab_4096.json'...
[!] Training original model 'mean_transformer_orig' started: Sat Jan 27 13:25:00 2024
[!] Scheduler: onecycle | Scheduler step budget: 20830
GPU available: True (cuda), used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
C:\Users\dtrizna\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\LocalCache\local-packages\Python39\site-packages\lightning\pytorch\trainer\setup.py:175: PossibleUserWarning: GPU available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='gpu', devices=1)`.
  rank_zero_warn(
[*] Training 'mean_transformer_orig' model...
[!] Setting up onecycle scheduler with step budget 20830

   | Name            | Type                   | Params
------------------------------------------------------------
0  | model           | MeanTransformerEncoder | 335 K
1  | loss            | BCEWithLogitsLoss      | 0
2  | train_acc       | BinaryAccuracy         | 0
3  | train_f1        | BinaryF1Score          | 0
4  | train_auc       | BinaryAUROC            | 0
5  | train_recall    | BinaryRecall           | 0
6  | train_precision | BinaryPrecision        | 0
7  | val_acc         | BinaryAccuracy         | 0
8  | val_f1          | BinaryF1Score          | 0
9  | val_auc         | BinaryAUROC            | 0
10 | val_recall      | BinaryRecall           | 0
11 | val_precision   | BinaryPrecision        | 0
------------------------------------------------------------
335 K     Trainable params
0         Non-trainable params
335 K     Total params
1.341     Total estimated model params size (MB)
Epoch 0:  50%|▍| 2878/5757 [1:01:57<1:01:58,  1.29s/it, loss=0.0442, v_num=0, train_loss=0.0641, memory=0.000, val_f1=0.919, val_tpr=0.156, val_accMetric val_tpr improved. New best score: 0.156
Epoch 0: 100%|▉| 5756/5757 [1:58:11<00:01,  1.23s/it, loss=0.0151, v_num=0, train_loss=0.00353, memory=0.000, val_f1=0.929, val_tpr=0.919, val_acc=Metric val_tpr improved by 0.763 >= min_delta = 0.0001. New best score: 0.919
Epoch 0: 100%|█| 5757/5757 [1:58:12<00:00,  1.23s/it, loss=0.015, v_num=0, train_loss=0.00334, memory=0.000, val_f1=0.929, val_tpr=0.919, val_acc=0
Epoch 1:   0%| | 8/5757 [00:26<5:16:28,  3.30s/it, loss=0.0118, v_num=0, train_loss=0.0174, memory=0.000, val_f1=0.929, val_tpr=0.919, val_acc=0.92