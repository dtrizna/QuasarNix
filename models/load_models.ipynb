{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "import pickle\n",
    "\n",
    "SEED = 33\n",
    "VOCAB_SIZE = 4096\n",
    "EMBEDDED_DIM = 64\n",
    "DROPOUT = 0.5\n",
    "\n",
    "def lit_ckpt_to_torch(ckpt):\n",
    "    \"\"\"\n",
    "    Convert a lightning checkpoint to a torch state dict\n",
    "    \"\"\"\n",
    "    state_dict = torch.load(ckpt, map_location='cpu')['state_dict']\n",
    "    \n",
    "    for k, v in dict(state_dict).items():\n",
    "        # lightning introduced model. prefix\n",
    "        if k.startswith('model.'):\n",
    "            state_dict[k[len('model.'):]] = v\n",
    "            del state_dict[k]\n",
    "\n",
    "    return state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model_path_orig = './quasarnix_data_train_xgb_orig.pickle'\n",
    "xgb_model_path_adv = './quasarnix_data_train_xgb_adv.pickle'\n",
    "xgb_model_path_full = './quasarnix_data_full_xgb_adv.pickle'\n",
    "\n",
    "mlp_model_path_orig = './quasarnix_data_train_mlp_orig.torch'\n",
    "mlp_model_path_adv = './quasarnix_data_train_mlp_adv.torch'\n",
    "mlp_model_path_full = './quasarnix_data_full_mlp_adv.torch'\n",
    "\n",
    "cnn_model_path_orig = './quasarnix_data_train_cnn_orig.torch'\n",
    "cnn_model_path_adv = './quasarnix_data_train_cnn_adv.torch'\n",
    "cnn_model_path_full = './quasarnix_data_full_cnn_adv.torch'\n",
    "\n",
    "transformer_model_path_orig = './quasarnix_data_train_transformer_orig.torch'\n",
    "transformer_model_path_adv = './quasarnix_data_train_transformer_adv.torch'\n",
    "transformer_model_path_full = './quasarnix_data_full_transformer_adv.torch'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosted Decision Trees (GBDT) with XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n",
       "              importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=10, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=33,\n",
       "              reg_alpha=0, reg_lambda=1, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n",
       "              importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=10, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=33,\n",
       "              reg_alpha=0, reg_lambda=1, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
       "              importance_type=None, interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=10, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints='()', n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor='auto', random_state=33,\n",
       "              reg_alpha=0, reg_lambda=1, ...)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_orig = XGBClassifier(n_estimators=100, max_depth=10, random_state=SEED)\n",
    "\n",
    "with open(xgb_model_path_orig, 'rb') as f:\n",
    "    xgb_orig = pickle.load(f)\n",
    "\n",
    "xgb_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n",
       "              importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=10, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=33,\n",
       "              reg_alpha=0, reg_lambda=1, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n",
       "              importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=10, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=33,\n",
       "              reg_alpha=0, reg_lambda=1, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
       "              importance_type=None, interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=10, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints='()', n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor='auto', random_state=33,\n",
       "              reg_alpha=0, reg_lambda=1, ...)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adv\n",
    "with open(xgb_model_path_adv, 'rb') as f:\n",
    "    xgb_adv = pickle.load(f)\n",
    "\n",
    "xgb_adv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabular Fully Connected Neural Network (aka MLP) with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class SimpleMLP(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, hidden_dim=[32], dropout=None):\n",
    "        if isinstance(hidden_dim, int):\n",
    "            hidden_dim = [hidden_dim]\n",
    "        \n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        prev_dim = input_dim\n",
    "        \n",
    "        # Dynamically create hidden layers based on hidden_dim\n",
    "        for h_dim in hidden_dim:\n",
    "            layers.append(nn.Linear(prev_dim, h_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            if dropout:\n",
    "                layers.append(nn.Dropout(dropout))\n",
    "            prev_dim = h_dim\n",
    "        \n",
    "        layers.append(nn.Linear(prev_dim, output_dim))\n",
    "        self.model = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "mlp_orig = SimpleMLP(\n",
    "    input_dim=VOCAB_SIZE,\n",
    "    output_dim=1,\n",
    "    hidden_dim=[64, 32],\n",
    "    dropout=DROPOUT\n",
    ") # 264 K params\n",
    "\n",
    "# mlp_state_dict_orig = lit_ckpt_to_torch(mlp_model_path_orig)\n",
    "# mlp_orig.load_state_dict(mlp_state_dict_orig)\n",
    "# torch.save(mlp_orig.state_dict(), mlp_model_path_orig.replace('.ckpt', '.torch'))\n",
    "\n",
    "mlp_orig.load_state_dict(torch.load(mlp_model_path_orig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_adv = SimpleMLP(\n",
    "    input_dim=VOCAB_SIZE,\n",
    "    output_dim=1,\n",
    "    hidden_dim=[64, 32],\n",
    "    dropout=DROPOUT\n",
    ") # 264 K params\n",
    "\n",
    "# mlp_state_dict_adv = lit_ckpt_to_torch(mlp_model_path_adv)\n",
    "# mlp_adv.load_state_dict(mlp_state_dict_adv)\n",
    "# torch.save(mlp_adv.state_dict(), mlp_model_path_adv.replace('.ckpt', '.torch'))\n",
    "\n",
    "mlp_adv.load_state_dict(torch.load(mlp_model_path_adv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1D Convolutional Neural Network with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CNN1DGroupedModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_channels, kernel_sizes, mlp_hidden_dims, output_dim, dropout=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.grouped_convs = nn.ModuleList([nn.Conv1d(embed_dim, num_channels, kernel) for kernel in kernel_sizes])\n",
    "        \n",
    "        mlp_input_dim = num_channels * len(kernel_sizes)\n",
    "        self.mlp = SimpleMLP(input_dim=mlp_input_dim, output_dim=output_dim, hidden_dim=mlp_hidden_dims, dropout=dropout)\n",
    "\n",
    "    @staticmethod\n",
    "    def conv_and_pool(x, conv):\n",
    "        conv_out = conv(x)\n",
    "        pooled = F.max_pool1d(conv_out, conv_out.size(2)).squeeze(2)\n",
    "        return pooled\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x).transpose(1, 2)\n",
    "        conv_outputs = [self.conv_and_pool(x, conv) for conv in self.grouped_convs]\n",
    "\n",
    "        x = torch.cat(conv_outputs, dim=1)\n",
    "        return self.mlp(x)\n",
    "\n",
    "\n",
    "cnn_orig = CNN1DGroupedModel(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    embed_dim=EMBEDDED_DIM,\n",
    "    num_channels=32,\n",
    "    kernel_sizes=[2, 3, 4, 5],\n",
    "    mlp_hidden_dims=[64, 32],\n",
    "    output_dim=1,\n",
    "    dropout=DROPOUT\n",
    ") # 301 K params\n",
    "\n",
    "# cnn_state_dict_orig = lit_ckpt_to_torch(cnn_model_path_orig)\n",
    "# cnn_orig.load_state_dict(torch.load(cnn_model_path_orig))\n",
    "# torch.save(cnn_orig.state_dict(), cnn_model_path_orig.replace('.ckpt', '.torch'))\n",
    "\n",
    "cnn_orig.load_state_dict(torch.load(cnn_model_path_orig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_adv = CNN1DGroupedModel(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    embed_dim=EMBEDDED_DIM,\n",
    "    num_channels=32,\n",
    "    kernel_sizes=[2, 3, 4, 5],\n",
    "    mlp_hidden_dims=[64, 32],\n",
    "    output_dim=1,\n",
    "    dropout=DROPOUT\n",
    ") # 301 K params\n",
    "\n",
    "# cnn_state_dict_adv = lit_ckpt_to_torch(cnn_model_path_adv)\n",
    "# cnn_adv.load_state_dict(cnn_state_dict_adv)\n",
    "# torch.save(cnn_adv.state_dict(), cnn_model_path_adv.replace('.ckpt', '.torch'))\n",
    "\n",
    "cnn_adv.load_state_dict(torch.load(cnn_model_path_adv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer Encoder for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        # Initialize pe with shape [1, max_len, d_model] for broadcasting\n",
    "        pe = torch.zeros(1, max_len, d_model)\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe[0, :, 0::2] = torch.sin(position * div_term)\n",
    "        pe[0, :, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor, shape [batch_size, seq_len, embedding_dim]\n",
    "        \"\"\"\n",
    "        # Use broadcasting to add positional encoding\n",
    "        x = x + self.pe[:, :x.size(1), :]\n",
    "        return self.dropout(x)\n",
    "\n",
    "class BaseTransformerEncoder(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, nhead, num_layers, dim_feedforward, max_len, dropout=None):\n",
    "        super(BaseTransformerEncoder, self).__init__()\n",
    "        \n",
    "        assert d_model % nhead == 0, \"nheads must divide evenly into d_model\"\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout, max_len=max_len)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model, nhead, dim_feedforward, dropout, norm_first=True, batch_first=True)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers)\n",
    "\n",
    "    def encode(self, src, src_mask=None, src_key_padding_mask=None):\n",
    "        src = self.embedding(src) * math.sqrt(self.embedding.embedding_dim)\n",
    "        src = self.pos_encoder(src)\n",
    "        return self.transformer_encoder(src, mask=src_mask, src_key_padding_mask=src_key_padding_mask)\n",
    "\n",
    "class CLSTransformerEncoder(BaseTransformerEncoder):\n",
    "    def __init__(self, mlp_hidden_dims, output_dim, *args, **kwargs):\n",
    "        kwargs[\"max_len\"] += 1 # to account for CLS token\n",
    "        super(CLSTransformerEncoder, self).__init__(*args, **kwargs)\n",
    "        self.cls_token = nn.Parameter(torch.randn(1, 1, self.embedding.embedding_dim))\n",
    "        self.decoder = SimpleMLP(input_dim=self.embedding.embedding_dim, output_dim=output_dim, hidden_dim=mlp_hidden_dims, dropout=kwargs.get(\"dropout\"))\n",
    "\n",
    "    def forward(self, src, src_mask=None, src_key_padding_mask=None):\n",
    "        # Embed the src token indices\n",
    "        src = self.embedding(src) * math.sqrt(self.embedding.embedding_dim)\n",
    "        \n",
    "        # Repeat the cls_token for every item in the batch and concatenate it to src\n",
    "        cls_tokens = self.cls_token.repeat(src.size(0), 1, 1)\n",
    "        src = torch.cat([cls_tokens, src], dim=1)\n",
    "        \n",
    "        # Add positional encoding\n",
    "        src = self.pos_encoder(src)\n",
    "        \n",
    "        # Pass through transformer encoder\n",
    "        output = self.transformer_encoder(src, mask=src_mask, src_key_padding_mask=src_key_padding_mask)\n",
    "        \n",
    "        # Extract the encoding corresponding to the cls_token\n",
    "        output = output[:, 0, :]  # [B, E]\n",
    "        \n",
    "        return self.decoder(output)\n",
    "\n",
    "\n",
    "class MeanTransformerEncoder(BaseTransformerEncoder):\n",
    "    def __init__(self, mlp_hidden_dims, output_dim, *args, **kwargs):\n",
    "        super(MeanTransformerEncoder, self).__init__(*args, **kwargs)\n",
    "        self.decoder = SimpleMLP(input_dim=self.embedding.embedding_dim, output_dim=output_dim, hidden_dim=mlp_hidden_dims, dropout=kwargs.get(\"dropout\"))\n",
    "\n",
    "    def forward(self, src, src_mask=None, src_key_padding_mask=None):\n",
    "        output = self.encode(src, src_mask, src_key_padding_mask)\n",
    "        output = output.mean(dim=1)\n",
    "        return self.decoder(output)\n",
    "\n",
    "\n",
    "transformer_orig = CLSTransformerEncoder(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    d_model=EMBEDDED_DIM,\n",
    "    nhead=4,\n",
    "    num_layers=2,\n",
    "    dim_feedforward=128,\n",
    "    max_len=256,\n",
    "    dropout=DROPOUT,\n",
    "    mlp_hidden_dims=[64, 32],\n",
    "    output_dim=1\n",
    ") #  335 K params\n",
    "\n",
    "# transformer_state_dict_orig = lit_ckpt_to_torch(transformer_model_path_orig)\n",
    "# transformer_orig.load_state_dict(transformer_state_dict_orig)\n",
    "# torch.save(transformer_orig.state_dict(), transformer_model_path_orig.replace('.ckpt', '.torch'))\n",
    "\n",
    "transformer_orig.load_state_dict(torch.load(transformer_model_path_orig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer_adv = CLSTransformerEncoder(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    d_model=EMBEDDED_DIM,\n",
    "    nhead=4,\n",
    "    num_layers=2,\n",
    "    dim_feedforward=128,\n",
    "    max_len=256,\n",
    "    dropout=DROPOUT,\n",
    "    mlp_hidden_dims=[64, 32],\n",
    "    output_dim=1\n",
    ") #  335 K params\n",
    "\n",
    "# transformer_state_dict_adv = lit_ckpt_to_torch(transformer_model_path_adv)\n",
    "# transformer_adv.load_state_dict(transformer_state_dict_adv)\n",
    "# torch.save(transformer_adv.state_dict(), transformer_model_path_adv.replace('.ckpt', '.torch'))\n",
    "\n",
    "transformer_adv.load_state_dict(torch.load(transformer_model_path_adv))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
