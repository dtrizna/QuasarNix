{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sizes of train and test sets: 533014, 470129\n",
      "[*] Loading predictions...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    train_base_parquet_file = [x for x in os.listdir(os.path.join(ROOT,'data/train_baseline.parquet/')) if x.endswith('.parquet')][0]\n",
    "    test_base_parquet_file = [x for x in os.listdir(os.path.join(ROOT,'data/test_baseline.parquet/')) if x.endswith('.parquet')][0]\n",
    "    train_rvrs_parquet_file = [x for x in os.listdir(os.path.join(ROOT,'data/train_rvrs.parquet/')) if x.endswith('.parquet')][0]\n",
    "    test_rvrs_parquet_file = [x for x in os.listdir(os.path.join(ROOT,'data/test_rvrs.parquet/')) if x.endswith('.parquet')][0]\n",
    "\n",
    "    # load as dataframes\n",
    "    train_baseline_df = pd.read_parquet(os.path.join(ROOT,'data/train_baseline.parquet/', train_base_parquet_file))\n",
    "    test_baseline_df = pd.read_parquet(os.path.join(ROOT,'data/test_baseline.parquet/', test_base_parquet_file))\n",
    "    train_malicious_df = pd.read_parquet(os.path.join(ROOT,'data/train_rvrs.parquet/', train_rvrs_parquet_file))\n",
    "    test_malicious_df = pd.read_parquet(os.path.join(ROOT,'data/test_rvrs.parquet/', test_rvrs_parquet_file))\n",
    "\n",
    "    X_train_non_shuffled = train_baseline_df['cmd'].values.tolist() + train_malicious_df['cmd'].values.tolist()\n",
    "    y_train = np.array([0] * len(train_baseline_df) + [1] * len(train_malicious_df), dtype=np.int8)\n",
    "    X_train_cmds, y_train = shuffle(X_train_non_shuffled, y_train, random_state=SEED)\n",
    "\n",
    "    X_test_non_shuffled = test_baseline_df['cmd'].values.tolist() + test_malicious_df['cmd'].values.tolist()\n",
    "    y_test = np.array([0] * len(test_baseline_df) + [1] * len(test_malicious_df), dtype=np.int8)\n",
    "    X_test_cmds, y_test = shuffle(X_test_non_shuffled, y_test, random_state=SEED)\n",
    "\n",
    "    # ===========================================\n",
    "    # DATASET LIMITS FOR TESTING\n",
    "    # ===========================================\n",
    "    X_train_cmds = X_train_cmds[:LIMIT]\n",
    "    y_train = y_train[:LIMIT]\n",
    "    \n",
    "    X_test_cmds = X_test_cmds[:LIMIT]\n",
    "    y_test = y_test[:LIMIT]\n",
    "\n",
    "    return X_train_cmds, y_train, X_test_cmds, y_test\n",
    "\n",
    "SEED = 33\n",
    "\n",
    "VOCAB_SIZE = 4096\n",
    "EMBEDDED_DIM = 64\n",
    "MAX_LEN = 128\n",
    "BATCH_SIZE = 1024\n",
    "DROPOUT = 0.5\n",
    "LIMIT = None\n",
    "DATALOADER_WORKERS = 4\n",
    "\n",
    "\n",
    "# ===========================================\n",
    "# LOADING DATA\n",
    "# ===========================================\n",
    "\n",
    "ROOT = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "X_train_cmds, y_train, X_test_cmds, y_test = load_data()\n",
    "print(f\"Sizes of train and test sets: {len(X_train_cmds)}, {len(X_test_cmds)}\")\n",
    "\n",
    "LOGS_FOLDER = \"logs_models\"\n",
    "y_preds_pickle = os.path.join(LOGS_FOLDER, \"y_preds.pickle\")\n",
    "if os.path.exists(y_preds_pickle):\n",
    "    print(\"[*] Loading predictions...\")\n",
    "    with open(y_preds_pickle, \"rb\") as f:\n",
    "        y_preds = pickle.load(f)\n",
    "else:\n",
    "    y_preds = {}\n",
    "\n",
    "    from watermark import watermark\n",
    "\n",
    "    print(watermark(packages=\"torch,lightning,sklearn\", python=True))\n",
    "    print(f\"[!] Script start time: {time.ctime()}\")\n",
    "\n",
    "    # encoders\n",
    "    from sklearn.feature_extraction.text import HashingVectorizer\n",
    "\n",
    "    # tokenizers\n",
    "    from nltk.tokenize import wordpunct_tokenize, WhitespaceTokenizer\n",
    "    whitespace_tokenize = WhitespaceTokenizer().tokenize\n",
    "\n",
    "    # modeling\n",
    "    import lightning as L\n",
    "    from lightning.pytorch.loggers import CSVLogger, TensorBoardLogger\n",
    "    from lightning.pytorch.callbacks import ModelCheckpoint, EarlyStopping\n",
    "    from lightning.lite.utilities.seed import seed_everything\n",
    "\n",
    "    # import random forest, xgboost, and logistic regression\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from xgboost import XGBClassifier\n",
    "\n",
    "    from src.models import *\n",
    "    from src.lit_utils import LitProgressBar\n",
    "    from src.preprocessors import CommandTokenizer, OneHotCustomVectorizer\n",
    "    from src.data_utils import create_dataloader\n",
    "\n",
    "    from typing import List\n",
    "    from torch.utils.data import DataLoader\n",
    "\n",
    "    def sigmoid(x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def get_tpr_at_fpr(predicted_logits, true_labels, fprNeeded=1e-4):\n",
    "        if isinstance(predicted_logits, torch.Tensor):\n",
    "            predicted_probs = torch.sigmoid(predicted_logits).cpu().detach().numpy()\n",
    "        else:\n",
    "            predicted_probs = sigmoid(predicted_logits)\n",
    "        \n",
    "        if isinstance(true_labels, torch.Tensor):\n",
    "            true_labels = true_labels.cpu().detach().numpy()\n",
    "        \n",
    "        fpr, tpr, thresholds = roc_curve(true_labels, predicted_probs)\n",
    "        if all(np.isnan(fpr)):\n",
    "            return np.nan#, np.nan\n",
    "        else:\n",
    "            tpr_at_fpr = tpr[fpr <= fprNeeded][-1]\n",
    "            #threshold_at_fpr = thresholds[fpr <= fprNeeded][-1]\n",
    "            return tpr_at_fpr#, threshold_at_fpr\n",
    "\n",
    "\n",
    "    def commands_to_loader(cmd: List[str], tokenizer: CommandTokenizer, y: np.ndarray = None) -> DataLoader:\n",
    "        \"\"\"Convert a list of commands to a DataLoader.\"\"\"\n",
    "        tokens = tokenizer.tokenize(cmd)\n",
    "        ints = tokenizer.encode(tokens)\n",
    "        padded = tokenizer.pad(ints, MAX_LEN)\n",
    "        if y is None:\n",
    "            loader = create_dataloader(padded, batch_size=BATCH_SIZE, workers=DATALOADER_WORKERS)\n",
    "        else:\n",
    "            loader = create_dataloader(padded, y, batch_size=BATCH_SIZE, workers=DATALOADER_WORKERS)\n",
    "        return loader\n",
    "\n",
    "\n",
    "    def configure_trainer():\n",
    "        \"\"\"Configure the PyTorch Lightning Trainer.\"\"\"\n",
    "\n",
    "        trainer = L.Trainer(\n",
    "            num_sanity_val_steps=0,\n",
    "            max_epochs=1,\n",
    "            accelerator=\"gpu\",\n",
    "            devices=1,\n",
    "            callbacks=[LitProgressBar()],\n",
    "            logger=TensorBoardLogger(\"logs_temp_results_roc_ablation_models\", name=\"my_model\"),\n",
    "            val_check_interval=0.5,\n",
    "            log_every_n_steps=10,\n",
    "        )\n",
    "        return trainer\n",
    "\n",
    "\n",
    "    def load_lit_model(model_file, pytorch_model, name, log_folder):\n",
    "        lightning_model = PyTorchLightningModel.load_from_checkpoint(checkpoint_path=model_file, model=pytorch_model)\n",
    "        trainer = configure_trainer()\n",
    "        return trainer, lightning_model\n",
    "\n",
    "    seed_everything(SEED)\n",
    "    TOKENIZER = wordpunct_tokenize\n",
    "\n",
    "    # =============================================\n",
    "    # PREPING DATA\n",
    "    # =============================================\n",
    "    tokenizer = CommandTokenizer(tokenizer_fn=TOKENIZER, vocab_size=VOCAB_SIZE)\n",
    "\n",
    "    # ========== EMBEDDING ==========\n",
    "    vocab_file = os.path.join(LOGS_FOLDER, f\"wordpunct_vocab_{VOCAB_SIZE}.json\")\n",
    "    if os.path.exists(vocab_file):\n",
    "        print(\"[*] Loading vocab...\")\n",
    "        tokenizer.load_vocab(vocab_file)\n",
    "    else:\n",
    "        print(\"[*] Building vocab and encoding...\")\n",
    "        X_train_tokens = tokenizer.tokenize(X_train_cmds)\n",
    "        tokenizer.build_vocab(X_train_tokens)\n",
    "        tokenizer.dump_vocab(vocab_file)\n",
    "\n",
    "    # creating dataloaders\n",
    "    # X_train_loader = commands_to_loader(X_train_cmds, tokenizer, y_train)\n",
    "    X_test_loader = commands_to_loader(X_test_cmds, tokenizer, y_test)\n",
    "\n",
    "    # ========== MIN-HASH TABULAR ENCODING ==========\n",
    "    minhash_vectorizer_file = os.path.join(LOGS_FOLDER, f\"minhash_vectorizer_{VOCAB_SIZE}.pkl\")\n",
    "    if os.path.exists(minhash_vectorizer_file):\n",
    "        print(\"[*] Loading MinHash vectorizer...\")\n",
    "        minhash = pickle.load(open(minhash_vectorizer_file, \"rb\"))\n",
    "    else:\n",
    "        minhash = HashingVectorizer(n_features=VOCAB_SIZE, tokenizer=TOKENIZER, token_pattern=None)\n",
    "        print(\"[*] Fitting MinHash encoder...\")\n",
    "        minhash.fit(X_train_cmds)\n",
    "        \n",
    "        with open(minhash_vectorizer_file, \"wb\") as f:\n",
    "            pickle.dump(minhash, f)\n",
    "\n",
    "    # X_train_minhash = minhash.transform(X_train_cmds)\n",
    "    X_test_minhash = minhash.transform(X_test_cmds)\n",
    "\n",
    "    # ========== ONE-HOT TABULAR ENCODING ===========\n",
    "    oh_vectorizer_file = os.path.join(LOGS_FOLDER, f\"onehot_vectorizer_{VOCAB_SIZE}.pkl\")\n",
    "    if os.path.exists(oh_vectorizer_file):\n",
    "        print(\"[*] Loading One-Hot vectorizer...\")\n",
    "        oh = pickle.load(open(oh_vectorizer_file, \"rb\"))\n",
    "    else:\n",
    "        oh = OneHotCustomVectorizer(tokenizer=TOKENIZER, max_features=VOCAB_SIZE)\n",
    "        print(\"[*] Fitting One-Hot encoder...\")\n",
    "        oh.fit(X_train_cmds)\n",
    "\n",
    "        with open(oh_vectorizer_file, \"wb\") as f:\n",
    "            pickle.dump(oh, f)\n",
    "\n",
    "    # X_train_onehot = oh.transform(X_train_cmds)\n",
    "    X_test_onehot = oh.transform(X_test_cmds)\n",
    "\n",
    "    # =============================================\n",
    "    # DEFINING MODELS\n",
    "    # =============================================\n",
    "    print(f\"[*] Defining models...\")\n",
    "\n",
    "    # sequence models\n",
    "    mlp_seq_model = SimpleMLPWithEmbedding(vocab_size=VOCAB_SIZE, embedding_dim=EMBEDDED_DIM, output_dim=1, hidden_dim=[256, 64, 32], use_positional_encoding=False, max_len=MAX_LEN, dropout=DROPOUT) # 297 K params\n",
    "    cnn_model = CNN1DGroupedModel(vocab_size=VOCAB_SIZE, embed_dim=EMBEDDED_DIM, num_channels=32, kernel_sizes=[2, 3, 4, 5], mlp_hidden_dims=[64, 32], output_dim=1, dropout=DROPOUT) # 301 K params\n",
    "    lstm_model = BiLSTMModel(vocab_size=VOCAB_SIZE, embed_dim=EMBEDDED_DIM, hidden_dim=32, mlp_hidden_dims=[64, 32], output_dim=1, dropout=DROPOUT) # 318 K params\n",
    "    cnn_lstm_model = CNN1D_BiLSTM_Model(vocab_size=VOCAB_SIZE, embed_dim=EMBEDDED_DIM, num_channels=32, kernel_size=3, lstm_hidden_dim=32, mlp_hidden_dims=[64, 32], output_dim=1, dropout=DROPOUT) # 316 K params\n",
    "    mean_transformer_model = MeanTransformerEncoder(vocab_size=VOCAB_SIZE, d_model=EMBEDDED_DIM, nhead=4, num_layers=2, dim_feedforward=128, max_len=MAX_LEN, dropout=DROPOUT, mlp_hidden_dims=[64,32], output_dim=1) # 335 K params\n",
    "    cls_transformer_model = CLSTransformerEncoder(vocab_size=VOCAB_SIZE, d_model=EMBEDDED_DIM, nhead=4, num_layers=2, dim_feedforward=128, max_len=MAX_LEN, dropout=DROPOUT, mlp_hidden_dims=[64,32], output_dim=1) #  335 K params\n",
    "    attpool_transformer_model = AttentionPoolingTransformerEncoder(vocab_size=VOCAB_SIZE, d_model=EMBEDDED_DIM, nhead=4, num_layers=2, dim_feedforward=128, max_len=MAX_LEN, dropout=DROPOUT, mlp_hidden_dims=[64,32], output_dim=1) #  335 K params\n",
    "    neurlux = NeurLuxModel(vocab_size=VOCAB_SIZE, embed_dim=EMBEDDED_DIM, max_len=MAX_LEN, hidden_dim=32, output_dim=1, dropout=DROPOUT) # 402 K params\n",
    "\n",
    "    # tabular models\n",
    "    rf_model_minhash = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=SEED)\n",
    "    xgb_model_minhash = XGBClassifier(n_estimators=100, max_depth=10, random_state=SEED)\n",
    "    log_reg_minhash = LogisticRegression(random_state=SEED)\n",
    "    mlp_tab_model_minhash = SimpleMLP(input_dim=VOCAB_SIZE, output_dim=1, hidden_dim=[64, 32], dropout=DROPOUT) # 264 K params\n",
    "    rf_model_onehot = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=SEED)\n",
    "    xgb_model_onehot = XGBClassifier(n_estimators=100, max_depth=10, random_state=SEED)\n",
    "    log_reg_onehot = LogisticRegression(random_state=SEED)\n",
    "    mlp_tab_model_onehot = SimpleMLP(input_dim=VOCAB_SIZE, output_dim=1, hidden_dim=[64, 32], dropout=DROPOUT) # 264 K params\n",
    "\n",
    "    models = {\n",
    "        \"_tabular_mlp_minhash\": mlp_tab_model_minhash,\n",
    "        \"_tabular_rf_minhash\": rf_model_minhash,\n",
    "        \"_tabular_xgb_minhash\": xgb_model_minhash,\n",
    "        \"_tabular_log_reg_minhash\": log_reg_minhash,\n",
    "        \"_tabular_mlp_onehot\": mlp_tab_model_onehot,\n",
    "        \"_tabular_rf_onehot\": rf_model_onehot,\n",
    "        \"_tabular_xgb_onehot\": xgb_model_onehot,\n",
    "        \"_tabular_log_reg_onehot\": log_reg_onehot,\n",
    "        \"mlp_seq\": mlp_seq_model,\n",
    "        \"attpool_transformer\": attpool_transformer_model,\n",
    "        \"cls_transformer\": cls_transformer_model,\n",
    "        \"mean_transformer\": mean_transformer_model,\n",
    "        \"neurlux\": neurlux,\n",
    "        \"cnn\": cnn_model,\n",
    "        \"lstm\": lstm_model,\n",
    "        \"cnn_lstm\": cnn_lstm_model,\n",
    "    }\n",
    "\n",
    "    for name, model in models.items():\n",
    "        if name in y_preds:\n",
    "            print(f\"[*] Model {name} already predicted\")\n",
    "            continue\n",
    "\n",
    "        if name.startswith(\"_tabular\") and \"mlp\" not in name:\n",
    "            \n",
    "            model_file = os.path.join(LOGS_FOLDER, name, \"model.pkl\")\n",
    "            print(f\"[*] Loading {name} from {model_file}...\")\n",
    "            with open(model_file, \"rb\") as f:\n",
    "                model = pickle.load(f)\n",
    "            \n",
    "            preprocessor = name.split(\"_\")[-1]\n",
    "            assert preprocessor in [\"onehot\", \"minhash\"]\n",
    "\n",
    "            if preprocessor == \"onehot\":\n",
    "                # x_train = X_train_onehot\n",
    "                x_test = X_test_onehot\n",
    "            \n",
    "            elif preprocessor == \"minhash\":\n",
    "                # x_train = X_train_minhash\n",
    "                x_test = X_test_minhash\n",
    "\n",
    "            print(f\"[*] Predicting with {name}...\")\n",
    "            y_test_preds = model.predict_proba(x_test)[:,1]\n",
    "            y_preds[name] = y_test_preds\n",
    "        \n",
    "        else:    \n",
    "            if \"tabular\" in name:\n",
    "                preprocessor = name.split(\"_\")[-1]\n",
    "                assert preprocessor in [\"onehot\", \"minhash\"]\n",
    "\n",
    "                if preprocessor == \"onehot\":\n",
    "                    # x_train = X_train_onehot\n",
    "                    x_test = X_test_onehot\n",
    "                \n",
    "                elif preprocessor == \"minhash\":\n",
    "                    # x_train = X_train_minhash\n",
    "                    x_test = X_test_minhash\n",
    "\n",
    "                # train_loader = create_dataloader(x_train, y_train, batch_size=BATCH_SIZE, workers=DATALOADER_WORKERS)\n",
    "                test_loader = create_dataloader(x_test, y_test, batch_size=BATCH_SIZE, workers=DATALOADER_WORKERS)\n",
    "            \n",
    "            else:\n",
    "                # train_loader = X_train_loader\n",
    "                test_loader = X_test_loader\n",
    "            \n",
    "            chkp_folder = os.path.join(LOGS_FOLDER, f\"{name}_csv\", \"version_0\", \"checkpoints\")\n",
    "            if not os.path.exists(chkp_folder):\n",
    "                print(f\"Model {name} not trained yet\")\n",
    "\n",
    "            best_model = [x for x in os.listdir(os.path.join(LOGS_FOLDER, f\"{name}_csv\", \"version_0\", \"checkpoints\")) if x.startswith(\"epoch\")][0]\n",
    "            best_model = os.path.join(chkp_folder, best_model)\n",
    "            print(\"Best model: \", best_model)\n",
    "            trainer, lightning_model = load_lit_model(best_model, model, name, LOGS_FOLDER)\n",
    "            print(f\"[*] Predicting with {name}...\")\n",
    "            y_pred_proba = trainer.predict(lightning_model, test_loader, return_predictions=True)\n",
    "            if isinstance(y_pred_proba, list):\n",
    "                y_pred_proba = np.vstack(y_pred_proba).squeeze()\n",
    "\n",
    "            y_preds[name] = y_pred_proba\n",
    "\n",
    "    with open(y_preds_pickle, \"wb\") as f:\n",
    "        pickle.dump(y_preds, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 504x311.489 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import scienceplots # used by plt.style\n",
    "\n",
    "from src.plots import set_size, plot_roc_curve\n",
    "\n",
    "import scienceplots\n",
    "plt.style.use(['science', 'no-latex'])\n",
    "plt.rc('text', usetex=True)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=set_size())\n",
    "\n",
    "to_skip = [x for x in y_preds.keys() if 'tabular' in x]\n",
    "to_keep = {\n",
    "    # \"_tabular_log_reg_onehot\": 'LogR (One-Hot)',\n",
    "    'cnn': '1D-CNN + MLP',\n",
    "    '_tabular_mlp_onehot': 'MLP (One-Hot)',\n",
    "    '_tabular_xgb_onehot': 'GBDT (One-Hot)',\n",
    "    'mlp_seq': 'MLP (Embedding)',\n",
    "    # 'neurlux': '1D-CNN + LSTM\\n+ Attention + MLP',\n",
    "    # 'cls_transformer': 'Transformer (CLS)',\n",
    "    'mean_transformer': 'Transformer\\n(Mean Pooling)',\n",
    "    #'_tabular_mlp_minhash': 'MLP (Minhash)',\n",
    "    # 'lstm': 'LSTM + MLP',\n",
    "    # 'cnn_lstm': '1D-CNN + LSTM\\n+ MLP',\n",
    "    #'attpool_transformer': 'Transformer\\n(Attent. Pooling)',\n",
    "}\n",
    "for name in to_keep.keys():\n",
    "    y_pred_proba = y_preds[name]\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "    name = to_keep[name]\n",
    "    plot_roc_curve(fpr, tpr, None, model_name=name, ax=ax, semilogx=True, xlim=[2e-6,1e-2], ylim=[0.6,1.05])\n",
    "\n",
    "# Create a mapping from labels to handles\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "label_to_handle = {label: handle for handle, label in zip(handles, labels)}\n",
    "\n",
    "# labels for ROC curve\n",
    "ax.set_xlabel(\"False Positive Rate\", fontsize=20)\n",
    "#ax.set_ylabel(\"True Positive Rate\", fontsize=18)\n",
    "ax.set_title(\"Test set ROC curves\", fontsize=18)\n",
    "\n",
    "# ticklbel fontsizes to 18 as well\n",
    "ax.tick_params(axis='both', which='major', labelsize=18)\n",
    "\n",
    "# Order the handles based on the order of labels in to_keep.values()\n",
    "new_handles = [label_to_handle[label] for label in to_keep.values()]\n",
    "new_labels = list(to_keep.values())\n",
    "ax.grid()\n",
    "_ = ax.legend(new_handles, new_labels, ncol=1, fontsize=16, bbox_to_anchor=(1.03, 0), loc='lower right')\n",
    "\n",
    "# save as pdf in \"/img\"\n",
    "fig.savefig(f\"img/roc_ablation_models.pdf\", bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>TPR at FPR=10^-4</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>_tabular_mlp_minhash</td>\n",
       "      <td>0.982039</td>\n",
       "      <td>0.985962</td>\n",
       "      <td>0.999899</td>\n",
       "      <td>0.972407</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.986155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>_tabular_rf_minhash</td>\n",
       "      <td>0.790049</td>\n",
       "      <td>0.666658</td>\n",
       "      <td>0.49999</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999948</td>\n",
       "      <td>0.49999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>_tabular_xgb_minhash</td>\n",
       "      <td>0.963397</td>\n",
       "      <td>0.66666</td>\n",
       "      <td>0.499993</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999944</td>\n",
       "      <td>0.499995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>_tabular_log_reg_minhash</td>\n",
       "      <td>0.778231</td>\n",
       "      <td>0.666658</td>\n",
       "      <td>0.49999</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999818</td>\n",
       "      <td>0.49999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>_tabular_mlp_onehot</td>\n",
       "      <td>0.997205</td>\n",
       "      <td>0.997621</td>\n",
       "      <td>0.999923</td>\n",
       "      <td>0.995329</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.997626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>_tabular_rf_onehot</td>\n",
       "      <td>0.952684</td>\n",
       "      <td>0.666658</td>\n",
       "      <td>0.49999</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>0.49999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>_tabular_xgb_onehot</td>\n",
       "      <td>0.999426</td>\n",
       "      <td>0.666666</td>\n",
       "      <td>0.499999</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>_tabular_log_reg_onehot</td>\n",
       "      <td>0.998843</td>\n",
       "      <td>0.666658</td>\n",
       "      <td>0.49999</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.49999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>mlp_seq</td>\n",
       "      <td>0.739207</td>\n",
       "      <td>0.951933</td>\n",
       "      <td>0.999883</td>\n",
       "      <td>0.908372</td>\n",
       "      <td>0.999958</td>\n",
       "      <td>0.954134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>attpool_transformer</td>\n",
       "      <td>0.910929</td>\n",
       "      <td>0.976357</td>\n",
       "      <td>0.999857</td>\n",
       "      <td>0.953935</td>\n",
       "      <td>0.999875</td>\n",
       "      <td>0.9769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>cls_transformer</td>\n",
       "      <td>0.991555</td>\n",
       "      <td>0.996874</td>\n",
       "      <td>0.999872</td>\n",
       "      <td>0.993895</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.996884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>mean_transformer</td>\n",
       "      <td>0.952314</td>\n",
       "      <td>0.988769</td>\n",
       "      <td>0.999878</td>\n",
       "      <td>0.977904</td>\n",
       "      <td>0.999988</td>\n",
       "      <td>0.988892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>neurlux</td>\n",
       "      <td>0.9089</td>\n",
       "      <td>0.902162</td>\n",
       "      <td>0.99999</td>\n",
       "      <td>0.821769</td>\n",
       "      <td>0.999957</td>\n",
       "      <td>0.910882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>cnn</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.974025</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.949366</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.974684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>lstm</td>\n",
       "      <td>0.991019</td>\n",
       "      <td>0.950764</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>0.90616</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.953075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>cnn_lstm</td>\n",
       "      <td>0.869433</td>\n",
       "      <td>0.815259</td>\n",
       "      <td>0.999988</td>\n",
       "      <td>0.688139</td>\n",
       "      <td>0.995315</td>\n",
       "      <td>0.844068</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Model TPR at FPR=10^-4  F1-Score Precision    Recall  \\\n",
       "0       _tabular_mlp_minhash         0.982039  0.985962  0.999899  0.972407   \n",
       "1        _tabular_rf_minhash         0.790049  0.666658   0.49999       1.0   \n",
       "2       _tabular_xgb_minhash         0.963397   0.66666  0.499993       1.0   \n",
       "3   _tabular_log_reg_minhash         0.778231  0.666658   0.49999       1.0   \n",
       "4        _tabular_mlp_onehot         0.997205  0.997621  0.999923  0.995329   \n",
       "5         _tabular_rf_onehot         0.952684  0.666658   0.49999       1.0   \n",
       "6        _tabular_xgb_onehot         0.999426  0.666666  0.499999       1.0   \n",
       "7    _tabular_log_reg_onehot         0.998843  0.666658   0.49999       1.0   \n",
       "8                    mlp_seq         0.739207  0.951933  0.999883  0.908372   \n",
       "9        attpool_transformer         0.910929  0.976357  0.999857  0.953935   \n",
       "10           cls_transformer         0.991555  0.996874  0.999872  0.993895   \n",
       "11          mean_transformer         0.952314  0.988769  0.999878  0.977904   \n",
       "12                   neurlux           0.9089  0.902162   0.99999  0.821769   \n",
       "13                       cnn              1.0  0.974025       1.0  0.949366   \n",
       "14                      lstm         0.991019  0.950764  0.999986   0.90616   \n",
       "15                  cnn_lstm         0.869433  0.815259  0.999988  0.688139   \n",
       "\n",
       "         AUC  Accuracy  \n",
       "0   0.999989  0.986155  \n",
       "1   0.999948   0.49999  \n",
       "2   0.999944  0.499995  \n",
       "3   0.999818   0.49999  \n",
       "4   0.999999  0.997626  \n",
       "5   0.999982   0.49999  \n",
       "6        1.0  0.500007  \n",
       "7        1.0   0.49999  \n",
       "8   0.999958  0.954134  \n",
       "9   0.999875    0.9769  \n",
       "10  0.999996  0.996884  \n",
       "11  0.999988  0.988892  \n",
       "12  0.999957  0.910882  \n",
       "13       1.0  0.974684  \n",
       "14  0.999983  0.953075  \n",
       "15  0.995315  0.844068  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score, accuracy_score, confusion_matrix\n",
    "\n",
    "def get_tpr_at_fpr(predicted_logits, true_labels, fprNeeded=1e-4):\n",
    "    predicted_probs = torch.sigmoid(predicted_logits).cpu().detach().numpy()\n",
    "    fpr, tpr, _ = roc_curve(true_labels, predicted_probs)\n",
    "    if all(np.isnan(fpr)):\n",
    "        return np.nan#, np.nan\n",
    "    else:\n",
    "        tpr_at_fpr = tpr[fpr <= fprNeeded][-1]\n",
    "        return tpr_at_fpr\n",
    "\n",
    "results_df = pd.DataFrame(columns=['Model', 'TPR at FPR=10^-4', 'F1-Score', 'Precision', 'Recall', 'AUC', 'Accuracy'])\n",
    "\n",
    "\n",
    "# Loop through each key-value pair in your dictionary, compute the required metrics, and append them to results_df\n",
    "for model_name, predictions in y_preds.items():\n",
    "    predicted_probs = torch.sigmoid(torch.tensor(predictions)).cpu().detach().numpy()\n",
    "    binary_preds = (predicted_probs > 0.5).astype(int)  # Convert probabilities to binary labels with a 0.5 threshold\n",
    "    \n",
    "    auc = roc_auc_score(y_test, predicted_probs)\n",
    "    f1 = f1_score(y_test, binary_preds)\n",
    "    precision = precision_score(y_test, binary_preds)\n",
    "    recall = recall_score(y_test, binary_preds)\n",
    "    accuracy = accuracy_score(y_test, binary_preds)\n",
    "    tpr_at_fpr_10e4 = get_tpr_at_fpr(torch.tensor(predictions), y_test)\n",
    "    \n",
    "    # Append results to dataframe\n",
    "    new_row = pd.DataFrame({\n",
    "        'Model': [model_name],\n",
    "        'TPR at FPR=10^-4': [tpr_at_fpr_10e4],\n",
    "        'F1-Score': [f1],\n",
    "        'Precision': [precision],\n",
    "        'Recall': [recall],\n",
    "        'Accuracy': [accuracy],\n",
    "        'AUC': [auc]\n",
    "    })\n",
    "    results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
    "\n",
    "# Output the results\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import scienceplots\n",
    "plt.style.use(['science', 'no-latex'])\n",
    "plt.rc('text', usetex=True)\n",
    "\n",
    "from src.plots import set_size\n",
    "\n",
    "df_dict = {}\n",
    "LOGDIR = 'logs_models'\n",
    "\n",
    "# key_extractor = lambda x: x.split('_')[1:]\n",
    "\n",
    "for subfolder in os.listdir(LOGDIR):\n",
    "    subfolder_path = os.path.join(LOGDIR, subfolder)\n",
    "    csv_file_path = os.path.join(subfolder_path, 'version_0', 'metrics.csv')\n",
    "    if os.path.exists(csv_file_path):\n",
    "        df = pd.read_csv(csv_file_path)\n",
    "        encoder = ' '.join(subfolder.split('_')[:-1]).title()\n",
    "        df_dict[encoder] = df\n",
    "\n",
    "\n",
    "def extract_metric_values(df_dict, metric_name, operation='last'):\n",
    "    \"\"\"\n",
    "    Extracts specified metric values (either last or max) from nested DataFrames in df_dict.\n",
    "    \n",
    "    Parameters:\n",
    "        df_dict (defaultdict(dict)): Nested dictionary of DataFrames keyed by tokenizer and vocab_size.\n",
    "        metric_name (str): The name of the metric to extract.\n",
    "        operation (str): The operation to perform ('last' or 'max').\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: DataFrame containing the extracted metric values, indexed by vocab_size and columns by tokenizer.\n",
    "    \"\"\"\n",
    "    # Initialize an empty dictionary to temporarily store the extracted values\n",
    "    extracted_values_temp = {}\n",
    "    \n",
    "    # Loop through the nested DataFrames\n",
    "    for encoder, df in df_dict.items():\n",
    "        if metric_name in df.columns:\n",
    "            if operation == 'last':\n",
    "                # Extract the last value of the specified metric\n",
    "                last_value = df[metric_name].dropna().iloc[-1]\n",
    "                extracted_values_temp[encoder] = last_value\n",
    "                \n",
    "            elif operation == 'max':\n",
    "                # Extract the maximum value of the specified metric\n",
    "                max_value = df[metric_name].dropna().max()\n",
    "                extracted_values_temp[encoder] = max_value\n",
    "            else:\n",
    "                print(f\"Invalid operation '{operation}' specified. Skipping {encoder}.\")\n",
    "        else:\n",
    "            print(f\"Metric '{metric_name}' not found in DataFrame for {encoder}. Skipping.\")\n",
    "                \n",
    "    # Convert the nested dictionary to a DataFrame, using 'metric_name' as value for index\n",
    "    extracted_values_df = pd.DataFrame.from_dict(extracted_values_temp, orient='index', columns=[metric_name]).transpose()\n",
    "\n",
    "    # sort index by vocab_size\n",
    "    extracted_values_df.sort_index(inplace=True)\n",
    "\n",
    "    return extracted_values_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>val_tpr</th>\n",
       "      <th>val_f1</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Attpool Transformer</th>\n",
       "      <td>0.967858</td>\n",
       "      <td>0.982970</td>\n",
       "      <td>0.983254</td>\n",
       "      <td>0.999406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cls Transformer</th>\n",
       "      <td>0.997018</td>\n",
       "      <td>0.995994</td>\n",
       "      <td>0.996010</td>\n",
       "      <td>0.999996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cnn</th>\n",
       "      <td>0.999910</td>\n",
       "      <td>0.974444</td>\n",
       "      <td>0.975081</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cnn Lstm</th>\n",
       "      <td>0.780494</td>\n",
       "      <td>0.642088</td>\n",
       "      <td>0.736428</td>\n",
       "      <td>0.996596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lstm</th>\n",
       "      <td>0.972996</td>\n",
       "      <td>0.940016</td>\n",
       "      <td>0.943411</td>\n",
       "      <td>0.999938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean Transformer</th>\n",
       "      <td>0.967348</td>\n",
       "      <td>0.994659</td>\n",
       "      <td>0.994687</td>\n",
       "      <td>0.999963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mlp Seq</th>\n",
       "      <td>0.969886</td>\n",
       "      <td>0.917868</td>\n",
       "      <td>0.924095</td>\n",
       "      <td>0.999945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neurlux</th>\n",
       "      <td>0.968056</td>\n",
       "      <td>0.900832</td>\n",
       "      <td>0.909776</td>\n",
       "      <td>0.999922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tabular Mlp Minhash</th>\n",
       "      <td>0.993898</td>\n",
       "      <td>0.986445</td>\n",
       "      <td>0.986625</td>\n",
       "      <td>0.999988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tabular Mlp Onehot</th>\n",
       "      <td>0.999303</td>\n",
       "      <td>0.993978</td>\n",
       "      <td>0.994014</td>\n",
       "      <td>0.999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Log Reg Minhash</th>\n",
       "      <td>0.778231</td>\n",
       "      <td>0.925402</td>\n",
       "      <td>0.930557</td>\n",
       "      <td>0.999818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Log Reg Onehot</th>\n",
       "      <td>0.998843</td>\n",
       "      <td>0.999268</td>\n",
       "      <td>0.999268</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rf Minhash</th>\n",
       "      <td>0.790049</td>\n",
       "      <td>0.995738</td>\n",
       "      <td>0.995720</td>\n",
       "      <td>0.999948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rf Onehot</th>\n",
       "      <td>0.952684</td>\n",
       "      <td>0.993455</td>\n",
       "      <td>0.993412</td>\n",
       "      <td>0.999982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Xgb Minhash</th>\n",
       "      <td>0.963397</td>\n",
       "      <td>0.999381</td>\n",
       "      <td>0.999381</td>\n",
       "      <td>0.999944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Xgb Onehot</th>\n",
       "      <td>0.999426</td>\n",
       "      <td>0.999657</td>\n",
       "      <td>0.999658</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       val_tpr    val_f1   val_acc   val_auc\n",
       "Attpool Transformer   0.967858  0.982970  0.983254  0.999406\n",
       "Cls Transformer       0.997018  0.995994  0.996010  0.999996\n",
       "Cnn                   0.999910  0.974444  0.975081  1.000000\n",
       "Cnn Lstm              0.780494  0.642088  0.736428  0.996596\n",
       "Lstm                  0.972996  0.940016  0.943411  0.999938\n",
       "Mean Transformer      0.967348  0.994659  0.994687  0.999963\n",
       "Mlp Seq               0.969886  0.917868  0.924095  0.999945\n",
       "Neurlux               0.968056  0.900832  0.909776  0.999922\n",
       " Tabular Mlp Minhash  0.993898  0.986445  0.986625  0.999988\n",
       " Tabular Mlp Onehot   0.999303  0.993978  0.994014  0.999999\n",
       "Log Reg Minhash       0.778231  0.925402  0.930557  0.999818\n",
       "Log Reg Onehot        0.998843  0.999268  0.999268  1.000000\n",
       "Rf Minhash            0.790049  0.995738  0.995720  0.999948\n",
       "Rf Onehot             0.952684  0.993455  0.993412  0.999982\n",
       "Xgb Minhash           0.963397  0.999381  0.999381  0.999944\n",
       "Xgb Onehot            0.999426  0.999657  0.999658  1.000000"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = ['val_tpr', 'val_f1', 'val_acc', 'val_auc']\n",
    "df = pd.DataFrame()\n",
    "for metric in metrics:\n",
    "    df1 = extract_metric_values(df_dict, metric, operation='last')\n",
    "    df = pd.concat([df, df1], axis=0)\n",
    "\n",
    "tabular_df_dict = {}\n",
    "for subfolder in os.listdir(LOGDIR):\n",
    "    subfolder_path = os.path.join(LOGDIR, subfolder)\n",
    "    csv_file_path = os.path.join(subfolder_path, 'metrics.csv')\n",
    "    if os.path.exists(csv_file_path):\n",
    "        ldf = pd.read_csv(csv_file_path)\n",
    "        encoder = ' '.join(subfolder.split('_')[2:]).title()\n",
    "        tabular_df_dict[encoder] = ldf\n",
    "\n",
    "col_map = dict(zip(['tpr', 'f1', 'acc', 'auc'], ['val_tpr', 'val_f1', 'val_acc', 'val_auc']))\n",
    "\n",
    "# Iterate over each item in the dictionary, map the columns, and concatenate to the initial dataframe\n",
    "for model_name, ldf in tabular_df_dict.items():\n",
    "    # Map columns\n",
    "    ldf = ldf.rename(columns=col_map)\n",
    "    # Transpose the dataframe so that metrics are in the columns and model names are in the index\n",
    "    ldf = ldf.T\n",
    "    # Rename the columns of df to match the model name\n",
    "    ldf.columns = [model_name]\n",
    "    # Concatenate along columns axis\n",
    "    df = pd.concat([df, ldf], axis=1)\n",
    "\n",
    "df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>val_tpr</th>\n",
       "      <th>val_f1</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Attpool Transformer</th>\n",
       "      <td>0.983769</td>\n",
       "      <td>0.999551</td>\n",
       "      <td>0.999551</td>\n",
       "      <td>0.999963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cls Transformer</th>\n",
       "      <td>0.997021</td>\n",
       "      <td>0.999889</td>\n",
       "      <td>0.999889</td>\n",
       "      <td>0.999996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cnn</th>\n",
       "      <td>0.999910</td>\n",
       "      <td>0.999949</td>\n",
       "      <td>0.999949</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cnn Lstm</th>\n",
       "      <td>0.916991</td>\n",
       "      <td>0.986644</td>\n",
       "      <td>0.986585</td>\n",
       "      <td>0.997550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lstm</th>\n",
       "      <td>0.992145</td>\n",
       "      <td>0.967622</td>\n",
       "      <td>0.968636</td>\n",
       "      <td>0.999983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean Transformer</th>\n",
       "      <td>0.992789</td>\n",
       "      <td>0.999902</td>\n",
       "      <td>0.999902</td>\n",
       "      <td>0.999988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mlp Seq</th>\n",
       "      <td>0.980032</td>\n",
       "      <td>0.990541</td>\n",
       "      <td>0.990622</td>\n",
       "      <td>0.999957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neurlux</th>\n",
       "      <td>0.980555</td>\n",
       "      <td>0.985019</td>\n",
       "      <td>0.984945</td>\n",
       "      <td>0.999957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tabular Mlp Minhash</th>\n",
       "      <td>0.994517</td>\n",
       "      <td>0.999298</td>\n",
       "      <td>0.999298</td>\n",
       "      <td>0.999989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tabular Mlp Onehot</th>\n",
       "      <td>0.999554</td>\n",
       "      <td>0.999777</td>\n",
       "      <td>0.999777</td>\n",
       "      <td>0.999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Log Reg Minhash</th>\n",
       "      <td>0.778231</td>\n",
       "      <td>0.925402</td>\n",
       "      <td>0.930557</td>\n",
       "      <td>0.999818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Log Reg Onehot</th>\n",
       "      <td>0.998843</td>\n",
       "      <td>0.999268</td>\n",
       "      <td>0.999268</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rf Minhash</th>\n",
       "      <td>0.790049</td>\n",
       "      <td>0.995738</td>\n",
       "      <td>0.995720</td>\n",
       "      <td>0.999948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rf Onehot</th>\n",
       "      <td>0.952684</td>\n",
       "      <td>0.993455</td>\n",
       "      <td>0.993412</td>\n",
       "      <td>0.999982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Xgb Minhash</th>\n",
       "      <td>0.963397</td>\n",
       "      <td>0.999381</td>\n",
       "      <td>0.999381</td>\n",
       "      <td>0.999944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Xgb Onehot</th>\n",
       "      <td>0.999426</td>\n",
       "      <td>0.999657</td>\n",
       "      <td>0.999658</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       val_tpr    val_f1   val_acc   val_auc\n",
       "Attpool Transformer   0.983769  0.999551  0.999551  0.999963\n",
       "Cls Transformer       0.997021  0.999889  0.999889  0.999996\n",
       "Cnn                   0.999910  0.999949  0.999949  1.000000\n",
       "Cnn Lstm              0.916991  0.986644  0.986585  0.997550\n",
       "Lstm                  0.992145  0.967622  0.968636  0.999983\n",
       "Mean Transformer      0.992789  0.999902  0.999902  0.999988\n",
       "Mlp Seq               0.980032  0.990541  0.990622  0.999957\n",
       "Neurlux               0.980555  0.985019  0.984945  0.999957\n",
       " Tabular Mlp Minhash  0.994517  0.999298  0.999298  0.999989\n",
       " Tabular Mlp Onehot   0.999554  0.999777  0.999777  0.999999\n",
       "Log Reg Minhash       0.778231  0.925402  0.930557  0.999818\n",
       "Log Reg Onehot        0.998843  0.999268  0.999268  1.000000\n",
       "Rf Minhash            0.790049  0.995738  0.995720  0.999948\n",
       "Rf Onehot             0.952684  0.993455  0.993412  0.999982\n",
       "Xgb Minhash           0.963397  0.999381  0.999381  0.999944\n",
       "Xgb Onehot            0.999426  0.999657  0.999658  1.000000"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = ['val_tpr', 'val_f1', 'val_acc', 'val_auc']\n",
    "df = pd.DataFrame()\n",
    "for metric in metrics:\n",
    "    df1 = extract_metric_values(df_dict, metric, operation='max')\n",
    "    df = pd.concat([df, df1], axis=0)\n",
    "\n",
    "tabular_df_dict = {}\n",
    "for subfolder in os.listdir(LOGDIR):\n",
    "    subfolder_path = os.path.join(LOGDIR, subfolder)\n",
    "    csv_file_path = os.path.join(subfolder_path, 'metrics.csv')\n",
    "    if os.path.exists(csv_file_path):\n",
    "        ldf = pd.read_csv(csv_file_path)\n",
    "        encoder = ' '.join(subfolder.split('_')[2:]).title()\n",
    "        tabular_df_dict[encoder] = ldf\n",
    "\n",
    "col_map = dict(zip(['tpr', 'f1', 'acc', 'auc'], ['val_tpr', 'val_f1', 'val_acc', 'val_auc']))\n",
    "\n",
    "# Iterate over each item in the dictionary, map the columns, and concatenate to the initial dataframe\n",
    "for model_name, ldf in tabular_df_dict.items():\n",
    "    # Map columns\n",
    "    ldf = ldf.rename(columns=col_map)\n",
    "    # Transpose the dataframe so that metrics are in the columns and model names are in the index\n",
    "    ldf = ldf.T\n",
    "    # Rename the columns of df to match the model name\n",
    "    ldf.columns = [model_name]\n",
    "    # Concatenate along columns axis\n",
    "    df = pd.concat([df, ldf], axis=1)\n",
    "\n",
    "df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
